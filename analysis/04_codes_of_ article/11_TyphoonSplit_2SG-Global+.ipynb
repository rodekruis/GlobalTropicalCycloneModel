{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a83e7e8-5a32-4877-bccf-a1f5398ee37d",
   "metadata": {},
   "source": [
    "# Typhoon's time split\n",
    "\n",
    "#### We split based on typhoons' time, the training list includes the oldest 70% of typhoons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b67bfdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f435bf7-203f-4fa6-8aa5-8dbcfe89e66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import imblearn\n",
    "import statsmodels.api as sm\n",
    "import statistics\n",
    "import warnings\n",
    "\n",
    "from math import sqrt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from collections import Counter\n",
    "from sty import fg, rs\n",
    "from itertools import chain\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import cm\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from utils import get_training_dataset, weight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5ba8b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e90a43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file and import to a df\n",
    "df = get_training_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0196b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df.at[i, \"typhoon_year\"] = str(df.loc[i][\"typhoon_year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "949ccf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"typhoon_name\"] = df[\"typhoon_name\"] + df[\"typhoon_year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37ca46cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace empty cells of RWI with mean value\n",
    "df[\"rwi\"].fillna(df[\"rwi\"].mean(), inplace=True)\n",
    "\n",
    "# Set any values >100% to 100%,\n",
    "for r in range(len(df)):\n",
    "    if df.loc[r, \"percent_houses_damaged\"] > 100:\n",
    "        df.at[r, \"percent_houses_damaged\"] = float(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbfdfa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df[(df[[\"wind_speed\"]] != 0).any(axis=1)]).reset_index(drop=True)\n",
    "df_data = df.drop(columns=[\"grid_point_id\", \"typhoon_year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea830051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>typhoon_name</th>\n",
       "      <th>typhoon_year</th>\n",
       "      <th>grid_point_id</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>track_distance</th>\n",
       "      <th>rainfall_max_6h</th>\n",
       "      <th>rainfall_max_24h</th>\n",
       "      <th>total_houses</th>\n",
       "      <th>rwi</th>\n",
       "      <th>strong_roof_strong_wall</th>\n",
       "      <th>...</th>\n",
       "      <th>std_tri</th>\n",
       "      <th>mean_elev</th>\n",
       "      <th>coast_length</th>\n",
       "      <th>with_coast</th>\n",
       "      <th>urban</th>\n",
       "      <th>rural</th>\n",
       "      <th>water</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>percent_houses_damaged</th>\n",
       "      <th>percent_houses_damaged_5years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DURIAN2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>8284</td>\n",
       "      <td>12.460039</td>\n",
       "      <td>275.018491</td>\n",
       "      <td>0.670833</td>\n",
       "      <td>0.313021</td>\n",
       "      <td>0.479848</td>\n",
       "      <td>-0.213039</td>\n",
       "      <td>31.336503</td>\n",
       "      <td>...</td>\n",
       "      <td>34.629550</td>\n",
       "      <td>42.218750</td>\n",
       "      <td>5303.659490</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DURIAN2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>8286</td>\n",
       "      <td>11.428974</td>\n",
       "      <td>297.027578</td>\n",
       "      <td>0.929167</td>\n",
       "      <td>0.343229</td>\n",
       "      <td>55.649739</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>23.447758</td>\n",
       "      <td>...</td>\n",
       "      <td>25.475388</td>\n",
       "      <td>72.283154</td>\n",
       "      <td>61015.543599</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.86</td>\n",
       "      <td>276.871504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DURIAN2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>8450</td>\n",
       "      <td>13.077471</td>\n",
       "      <td>262.598363</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.424479</td>\n",
       "      <td>8.157414</td>\n",
       "      <td>-0.636000</td>\n",
       "      <td>31.336503</td>\n",
       "      <td>...</td>\n",
       "      <td>54.353996</td>\n",
       "      <td>102.215198</td>\n",
       "      <td>66707.438070</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.89</td>\n",
       "      <td>448.539453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DURIAN2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>8451</td>\n",
       "      <td>12.511864</td>\n",
       "      <td>273.639330</td>\n",
       "      <td>0.568750</td>\n",
       "      <td>0.336979</td>\n",
       "      <td>88.292015</td>\n",
       "      <td>-0.227500</td>\n",
       "      <td>31.336503</td>\n",
       "      <td>...</td>\n",
       "      <td>31.814048</td>\n",
       "      <td>58.988877</td>\n",
       "      <td>53841.050168</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>2101.708435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DURIAN2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>8452</td>\n",
       "      <td>11.977511</td>\n",
       "      <td>284.680297</td>\n",
       "      <td>0.589583</td>\n",
       "      <td>0.290625</td>\n",
       "      <td>962.766739</td>\n",
       "      <td>-0.299667</td>\n",
       "      <td>23.546053</td>\n",
       "      <td>...</td>\n",
       "      <td>25.976413</td>\n",
       "      <td>111.386527</td>\n",
       "      <td>87378.257957</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.47</td>\n",
       "      <td>11632.726327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  typhoon_name typhoon_year  grid_point_id  wind_speed  track_distance  \\\n",
       "0   DURIAN2006         2006           8284   12.460039      275.018491   \n",
       "1   DURIAN2006         2006           8286   11.428974      297.027578   \n",
       "2   DURIAN2006         2006           8450   13.077471      262.598363   \n",
       "3   DURIAN2006         2006           8451   12.511864      273.639330   \n",
       "4   DURIAN2006         2006           8452   11.977511      284.680297   \n",
       "\n",
       "   rainfall_max_6h  rainfall_max_24h  total_houses       rwi  \\\n",
       "0         0.670833          0.313021      0.479848 -0.213039   \n",
       "1         0.929167          0.343229     55.649739  0.206000   \n",
       "2         0.716667          0.424479      8.157414 -0.636000   \n",
       "3         0.568750          0.336979     88.292015 -0.227500   \n",
       "4         0.589583          0.290625    962.766739 -0.299667   \n",
       "\n",
       "   strong_roof_strong_wall  ...    std_tri   mean_elev  coast_length  \\\n",
       "0                31.336503  ...  34.629550   42.218750   5303.659490   \n",
       "1                23.447758  ...  25.475388   72.283154  61015.543599   \n",
       "2                31.336503  ...  54.353996  102.215198  66707.438070   \n",
       "3                31.336503  ...  31.814048   58.988877  53841.050168   \n",
       "4                23.546053  ...  25.976413  111.386527  87378.257957   \n",
       "\n",
       "   with_coast  urban  rural  water     total_pop  percent_houses_damaged  \\\n",
       "0           1   0.00   0.00   1.00      0.000000                     0.0   \n",
       "1           1   0.00   0.14   0.86    276.871504                     0.0   \n",
       "2           1   0.00   0.11   0.89    448.539453                     0.0   \n",
       "3           1   0.00   0.12   0.88   2101.708435                     0.0   \n",
       "4           1   0.07   0.46   0.47  11632.726327                     0.0   \n",
       "\n",
       "   percent_houses_damaged_5years  \n",
       "0                            0.0  \n",
       "1                            0.0  \n",
       "2                            0.0  \n",
       "3                            0.0  \n",
       "4                            0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>typhoon_name</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>track_distance</th>\n",
       "      <th>rainfall_max_6h</th>\n",
       "      <th>rainfall_max_24h</th>\n",
       "      <th>total_houses</th>\n",
       "      <th>rwi</th>\n",
       "      <th>strong_roof_strong_wall</th>\n",
       "      <th>strong_roof_light_wall</th>\n",
       "      <th>strong_roof_salvage_wall</th>\n",
       "      <th>...</th>\n",
       "      <th>std_tri</th>\n",
       "      <th>mean_elev</th>\n",
       "      <th>coast_length</th>\n",
       "      <th>with_coast</th>\n",
       "      <th>urban</th>\n",
       "      <th>rural</th>\n",
       "      <th>water</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>percent_houses_damaged</th>\n",
       "      <th>percent_houses_damaged_5years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DURIAN2006</td>\n",
       "      <td>12.460039</td>\n",
       "      <td>275.018491</td>\n",
       "      <td>0.670833</td>\n",
       "      <td>0.313021</td>\n",
       "      <td>0.479848</td>\n",
       "      <td>-0.213039</td>\n",
       "      <td>31.336503</td>\n",
       "      <td>29.117802</td>\n",
       "      <td>0.042261</td>\n",
       "      <td>...</td>\n",
       "      <td>34.629550</td>\n",
       "      <td>42.218750</td>\n",
       "      <td>5303.659490</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DURIAN2006</td>\n",
       "      <td>11.428974</td>\n",
       "      <td>297.027578</td>\n",
       "      <td>0.929167</td>\n",
       "      <td>0.343229</td>\n",
       "      <td>55.649739</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>23.447758</td>\n",
       "      <td>23.591571</td>\n",
       "      <td>0.037516</td>\n",
       "      <td>...</td>\n",
       "      <td>25.475388</td>\n",
       "      <td>72.283154</td>\n",
       "      <td>61015.543599</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.86</td>\n",
       "      <td>276.871504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DURIAN2006</td>\n",
       "      <td>13.077471</td>\n",
       "      <td>262.598363</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.424479</td>\n",
       "      <td>8.157414</td>\n",
       "      <td>-0.636000</td>\n",
       "      <td>31.336503</td>\n",
       "      <td>29.117802</td>\n",
       "      <td>0.042261</td>\n",
       "      <td>...</td>\n",
       "      <td>54.353996</td>\n",
       "      <td>102.215198</td>\n",
       "      <td>66707.438070</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.89</td>\n",
       "      <td>448.539453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DURIAN2006</td>\n",
       "      <td>12.511864</td>\n",
       "      <td>273.639330</td>\n",
       "      <td>0.568750</td>\n",
       "      <td>0.336979</td>\n",
       "      <td>88.292015</td>\n",
       "      <td>-0.227500</td>\n",
       "      <td>31.336503</td>\n",
       "      <td>29.117802</td>\n",
       "      <td>0.042261</td>\n",
       "      <td>...</td>\n",
       "      <td>31.814048</td>\n",
       "      <td>58.988877</td>\n",
       "      <td>53841.050168</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>2101.708435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DURIAN2006</td>\n",
       "      <td>11.977511</td>\n",
       "      <td>284.680297</td>\n",
       "      <td>0.589583</td>\n",
       "      <td>0.290625</td>\n",
       "      <td>962.766739</td>\n",
       "      <td>-0.299667</td>\n",
       "      <td>23.546053</td>\n",
       "      <td>23.660429</td>\n",
       "      <td>0.037576</td>\n",
       "      <td>...</td>\n",
       "      <td>25.976413</td>\n",
       "      <td>111.386527</td>\n",
       "      <td>87378.257957</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.47</td>\n",
       "      <td>11632.726327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  typhoon_name  wind_speed  track_distance  rainfall_max_6h  rainfall_max_24h  \\\n",
       "0   DURIAN2006   12.460039      275.018491         0.670833          0.313021   \n",
       "1   DURIAN2006   11.428974      297.027578         0.929167          0.343229   \n",
       "2   DURIAN2006   13.077471      262.598363         0.716667          0.424479   \n",
       "3   DURIAN2006   12.511864      273.639330         0.568750          0.336979   \n",
       "4   DURIAN2006   11.977511      284.680297         0.589583          0.290625   \n",
       "\n",
       "   total_houses       rwi  strong_roof_strong_wall  strong_roof_light_wall  \\\n",
       "0      0.479848 -0.213039                31.336503               29.117802   \n",
       "1     55.649739  0.206000                23.447758               23.591571   \n",
       "2      8.157414 -0.636000                31.336503               29.117802   \n",
       "3     88.292015 -0.227500                31.336503               29.117802   \n",
       "4    962.766739 -0.299667                23.546053               23.660429   \n",
       "\n",
       "   strong_roof_salvage_wall  ...    std_tri   mean_elev  coast_length  \\\n",
       "0                  0.042261  ...  34.629550   42.218750   5303.659490   \n",
       "1                  0.037516  ...  25.475388   72.283154  61015.543599   \n",
       "2                  0.042261  ...  54.353996  102.215198  66707.438070   \n",
       "3                  0.042261  ...  31.814048   58.988877  53841.050168   \n",
       "4                  0.037576  ...  25.976413  111.386527  87378.257957   \n",
       "\n",
       "   with_coast  urban  rural  water     total_pop  percent_houses_damaged  \\\n",
       "0           1   0.00   0.00   1.00      0.000000                     0.0   \n",
       "1           1   0.00   0.14   0.86    276.871504                     0.0   \n",
       "2           1   0.00   0.11   0.89    448.539453                     0.0   \n",
       "3           1   0.00   0.12   0.88   2101.708435                     0.0   \n",
       "4           1   0.07   0.46   0.47  11632.726327                     0.0   \n",
       "\n",
       "   percent_houses_damaged_5years  \n",
       "0                            0.0  \n",
       "1                            0.0  \n",
       "2                            0.0  \n",
       "3                            0.0  \n",
       "4                            0.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())\n",
    "display(df_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "428dd14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mun_Code</th>\n",
       "      <th>typhoon</th>\n",
       "      <th>HAZ_rainfall_Total</th>\n",
       "      <th>HAZ_rainfall_max_6h</th>\n",
       "      <th>HAZ_rainfall_max_24h</th>\n",
       "      <th>HAZ_v_max</th>\n",
       "      <th>HAZ_dis_track_min</th>\n",
       "      <th>GEN_landslide_per</th>\n",
       "      <th>GEN_stormsurge_per</th>\n",
       "      <th>GEN_Bu_p_inSSA</th>\n",
       "      <th>...</th>\n",
       "      <th>VUL_LightRoof_LightWall</th>\n",
       "      <th>VUL_LightRoof_SalvageWall</th>\n",
       "      <th>VUL_SalvagedRoof_StrongWall</th>\n",
       "      <th>VUL_SalvagedRoof_LightWall</th>\n",
       "      <th>VUL_SalvagedRoof_SalvageWall</th>\n",
       "      <th>VUL_vulnerable_groups</th>\n",
       "      <th>VUL_pantawid_pamilya_beneficiary</th>\n",
       "      <th>DAM_perc_dmg</th>\n",
       "      <th>HAZ_v_max_3</th>\n",
       "      <th>y_norm_mun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PH175101000</td>\n",
       "      <td>DURIAN2006</td>\n",
       "      <td>185.828571</td>\n",
       "      <td>14.716071</td>\n",
       "      <td>7.381696</td>\n",
       "      <td>55.032241</td>\n",
       "      <td>2.478142</td>\n",
       "      <td>2.64</td>\n",
       "      <td>6.18</td>\n",
       "      <td>6.18</td>\n",
       "      <td>...</td>\n",
       "      <td>41.892832</td>\n",
       "      <td>1.002088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027836</td>\n",
       "      <td>0.083507</td>\n",
       "      <td>2.951511</td>\n",
       "      <td>46.931106</td>\n",
       "      <td>3.632568</td>\n",
       "      <td>166667.757548</td>\n",
       "      <td>3.34975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PH083701000</td>\n",
       "      <td>DURIAN2006</td>\n",
       "      <td>8.818750</td>\n",
       "      <td>0.455208</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>8.728380</td>\n",
       "      <td>288.358553</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>13.645253</td>\n",
       "      <td>0.549120</td>\n",
       "      <td>0.030089</td>\n",
       "      <td>0.090266</td>\n",
       "      <td>0.112833</td>\n",
       "      <td>3.338873</td>\n",
       "      <td>25.989168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>664.968323</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PH015501000</td>\n",
       "      <td>DURIAN2006</td>\n",
       "      <td>24.175000</td>\n",
       "      <td>2.408333</td>\n",
       "      <td>0.957639</td>\n",
       "      <td>10.945624</td>\n",
       "      <td>274.953818</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>...</td>\n",
       "      <td>15.592295</td>\n",
       "      <td>0.075838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015168</td>\n",
       "      <td>0.075838</td>\n",
       "      <td>2.131755</td>\n",
       "      <td>32.185651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1311.358762</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PH015502000</td>\n",
       "      <td>DURIAN2006</td>\n",
       "      <td>14.930000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>0.586250</td>\n",
       "      <td>12.108701</td>\n",
       "      <td>252.828578</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.100454</td>\n",
       "      <td>0.023280</td>\n",
       "      <td>0.011640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128041</td>\n",
       "      <td>1.589369</td>\n",
       "      <td>29.612385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1775.385328</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PH175302000</td>\n",
       "      <td>DURIAN2006</td>\n",
       "      <td>13.550000</td>\n",
       "      <td>1.054167</td>\n",
       "      <td>0.528125</td>\n",
       "      <td>10.660943</td>\n",
       "      <td>258.194381</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>30.354796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.387007</td>\n",
       "      <td>35.052562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1211.676901</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7855</th>\n",
       "      <td>PH084823000</td>\n",
       "      <td>NOUL2015</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.216146</td>\n",
       "      <td>8.136932</td>\n",
       "      <td>277.107823</td>\n",
       "      <td>1.80</td>\n",
       "      <td>6.25</td>\n",
       "      <td>6.25</td>\n",
       "      <td>...</td>\n",
       "      <td>32.492212</td>\n",
       "      <td>0.311526</td>\n",
       "      <td>0.031153</td>\n",
       "      <td>0.155763</td>\n",
       "      <td>0.031153</td>\n",
       "      <td>2.827833</td>\n",
       "      <td>31.308411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>538.743551</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7856</th>\n",
       "      <td>PH015547000</td>\n",
       "      <td>NOUL2015</td>\n",
       "      <td>17.587500</td>\n",
       "      <td>1.414583</td>\n",
       "      <td>0.386458</td>\n",
       "      <td>9.818999</td>\n",
       "      <td>305.789817</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.703833</td>\n",
       "      <td>0.027875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034843</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>1.073268</td>\n",
       "      <td>12.766551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>946.676507</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7857</th>\n",
       "      <td>PH025014000</td>\n",
       "      <td>NOUL2015</td>\n",
       "      <td>11.487500</td>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.230319</td>\n",
       "      <td>15.791907</td>\n",
       "      <td>210.313249</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>3.063753</td>\n",
       "      <td>0.022528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067583</td>\n",
       "      <td>0.022528</td>\n",
       "      <td>1.140109</td>\n",
       "      <td>9.348952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3938.254316</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7858</th>\n",
       "      <td>PH140127000</td>\n",
       "      <td>NOUL2015</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.412766</td>\n",
       "      <td>13.867145</td>\n",
       "      <td>218.189328</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.119093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.837537</td>\n",
       "      <td>21.928166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2666.620370</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7859</th>\n",
       "      <td>PH051612000</td>\n",
       "      <td>NOUL2015</td>\n",
       "      <td>32.305556</td>\n",
       "      <td>1.744444</td>\n",
       "      <td>1.210417</td>\n",
       "      <td>15.647639</td>\n",
       "      <td>219.542224</td>\n",
       "      <td>4.15</td>\n",
       "      <td>3.05</td>\n",
       "      <td>3.05</td>\n",
       "      <td>...</td>\n",
       "      <td>36.191860</td>\n",
       "      <td>0.280316</td>\n",
       "      <td>0.010382</td>\n",
       "      <td>0.031146</td>\n",
       "      <td>0.103821</td>\n",
       "      <td>2.518110</td>\n",
       "      <td>31.634136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3831.302757</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7860 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mun_Code     typhoon  HAZ_rainfall_Total  HAZ_rainfall_max_6h  \\\n",
       "0     PH175101000  DURIAN2006          185.828571            14.716071   \n",
       "1     PH083701000  DURIAN2006            8.818750             0.455208   \n",
       "2     PH015501000  DURIAN2006           24.175000             2.408333   \n",
       "3     PH015502000  DURIAN2006           14.930000             1.650000   \n",
       "4     PH175302000  DURIAN2006           13.550000             1.054167   \n",
       "...           ...         ...                 ...                  ...   \n",
       "7855  PH084823000    NOUL2015            9.700000             0.408333   \n",
       "7856  PH015547000    NOUL2015           17.587500             1.414583   \n",
       "7857  PH025014000    NOUL2015           11.487500             0.614583   \n",
       "7858  PH140127000    NOUL2015           11.600000             1.400000   \n",
       "7859  PH051612000    NOUL2015           32.305556             1.744444   \n",
       "\n",
       "      HAZ_rainfall_max_24h  HAZ_v_max  HAZ_dis_track_min  GEN_landslide_per  \\\n",
       "0                 7.381696  55.032241           2.478142               2.64   \n",
       "1                 0.255319   8.728380         288.358553               0.06   \n",
       "2                 0.957639  10.945624         274.953818               1.52   \n",
       "3                 0.586250  12.108701         252.828578               0.00   \n",
       "4                 0.528125  10.660943         258.194381               5.52   \n",
       "...                    ...        ...                ...                ...   \n",
       "7855              0.216146   8.136932         277.107823               1.80   \n",
       "7856              0.386458   9.818999         305.789817               0.00   \n",
       "7857              0.230319  15.791907         210.313249               0.06   \n",
       "7858              0.412766  13.867145         218.189328               0.00   \n",
       "7859              1.210417  15.647639         219.542224               4.15   \n",
       "\n",
       "      GEN_stormsurge_per  GEN_Bu_p_inSSA  ...  VUL_LightRoof_LightWall  \\\n",
       "0                   6.18            6.18  ...                41.892832   \n",
       "1                   0.00            0.00  ...                13.645253   \n",
       "2                   1.28            1.28  ...                15.592295   \n",
       "3                   0.00            0.00  ...                 7.100454   \n",
       "4                   0.36            0.36  ...                30.354796   \n",
       "...                  ...             ...  ...                      ...   \n",
       "7855                6.25            6.25  ...                32.492212   \n",
       "7856                0.00            0.00  ...                 4.703833   \n",
       "7857                0.09            0.09  ...                 3.063753   \n",
       "7858                0.00            0.00  ...                 3.119093   \n",
       "7859                3.05            3.05  ...                36.191860   \n",
       "\n",
       "      VUL_LightRoof_SalvageWall  VUL_SalvagedRoof_StrongWall  \\\n",
       "0                      1.002088                     0.000000   \n",
       "1                      0.549120                     0.030089   \n",
       "2                      0.075838                     0.000000   \n",
       "3                      0.023280                     0.011640   \n",
       "4                      0.000000                     0.000000   \n",
       "...                         ...                          ...   \n",
       "7855                   0.311526                     0.031153   \n",
       "7856                   0.027875                     0.000000   \n",
       "7857                   0.022528                     0.000000   \n",
       "7858                   0.000000                     0.000000   \n",
       "7859                   0.280316                     0.010382   \n",
       "\n",
       "      VUL_SalvagedRoof_LightWall  VUL_SalvagedRoof_SalvageWall  \\\n",
       "0                       0.027836                      0.083507   \n",
       "1                       0.090266                      0.112833   \n",
       "2                       0.015168                      0.075838   \n",
       "3                       0.000000                      0.128041   \n",
       "4                       0.032852                      0.000000   \n",
       "...                          ...                           ...   \n",
       "7855                    0.155763                      0.031153   \n",
       "7856                    0.034843                      0.097561   \n",
       "7857                    0.067583                      0.022528   \n",
       "7858                    0.000000                      0.000000   \n",
       "7859                    0.031146                      0.103821   \n",
       "\n",
       "      VUL_vulnerable_groups  VUL_pantawid_pamilya_beneficiary  DAM_perc_dmg  \\\n",
       "0                  2.951511                         46.931106      3.632568   \n",
       "1                  3.338873                         25.989168      0.000000   \n",
       "2                  2.131755                         32.185651      0.000000   \n",
       "3                  1.589369                         29.612385      0.000000   \n",
       "4                  1.387007                         35.052562      0.000000   \n",
       "...                     ...                               ...           ...   \n",
       "7855               2.827833                         31.308411      0.000000   \n",
       "7856               1.073268                         12.766551      0.000000   \n",
       "7857               1.140109                          9.348952      0.000000   \n",
       "7858               2.837537                         21.928166      0.000000   \n",
       "7859               2.518110                         31.634136      0.000000   \n",
       "\n",
       "        HAZ_v_max_3  y_norm_mun  \n",
       "0     166667.757548     3.34975  \n",
       "1        664.968323     0.00000  \n",
       "2       1311.358762     0.00000  \n",
       "3       1775.385328     0.00000  \n",
       "4       1211.676901     0.00000  \n",
       "...             ...         ...  \n",
       "7855     538.743551     0.00000  \n",
       "7856     946.676507     0.00000  \n",
       "7857    3938.254316     0.00000  \n",
       "7858    2666.620370     0.00000  \n",
       "7859    3831.302757     0.00000  \n",
       "\n",
       "[7860 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read municipality dataset which already merged with y_norm converted ground truth\n",
    "df_mun_merged = pd.read_csv(\"data/df_merged_2.csv\")\n",
    "\n",
    "# Remove the duplicated rows\n",
    "df_mun_merged.drop_duplicates(keep=\"first\", inplace=True)\n",
    "df_mun_merged = df_mun_merged.reset_index(drop=True)\n",
    "\n",
    "# Make the name of typhoons to uppercase\n",
    "df_mun_merged[\"typhoon\"] = df_mun_merged[\"typhoon\"].str.upper()\n",
    "\n",
    "# Rename y_norm column\n",
    "df_mun_merged = df_mun_merged.rename(columns={\"y_norm\": \"y_norm_mun\"})\n",
    "\n",
    "df_mun_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50f5a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform name of typhoons to lowercase and remove begining of years\n",
    "def transform_strings(strings):\n",
    "    transformed_strings = []\n",
    "    for string in strings:\n",
    "        transformed_string = string[0].upper() + string[1:-4].lower() + string[-2:]\n",
    "        transformed_strings.append(transformed_string)\n",
    "    return transformed_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9170e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of typhoons\n",
    "typhoons = [\n",
    "    \"DURIAN2006\",\n",
    "    \"FENGSHEN2008\",\n",
    "    \"KETSANA2009\",\n",
    "    \"CONSON2010\",\n",
    "    \"NESAT2011\",\n",
    "    \"BOPHA2012\",\n",
    "    \"NARI2013\",\n",
    "    \"KROSA2013\",\n",
    "    \"HAIYAN2013\",\n",
    "    \"USAGI2013\",\n",
    "    \"UTOR2013\",\n",
    "    \"JANGMI2014\",\n",
    "    \"KALMAEGI2014\",\n",
    "    \"RAMMASUN2014\",\n",
    "    \"HAGUPIT2014\",\n",
    "    \"FUNG-WONG2014\",\n",
    "    \"LINGLING2014\",\n",
    "    \"MUJIGAE2015\",\n",
    "    \"MELOR2015\",\n",
    "    \"NOUL2015\",\n",
    "    \"GONI2015\",\n",
    "    \"LINFA2015\",\n",
    "    \"KOPPU2015\",\n",
    "    \"MEKKHALA2015\",\n",
    "    \"HAIMA2016\",\n",
    "    \"TOKAGE2016\",\n",
    "    \"MERANTI2016\",\n",
    "    \"NOCK-TEN2016\",\n",
    "    \"SARIKA2016\",\n",
    "    \"MANGKHUT2018\",\n",
    "    \"YUTU2018\",\n",
    "    \"KAMMURI2019\",\n",
    "    \"NAKRI2019\",\n",
    "    \"PHANFONE2019\",\n",
    "    \"SAUDEL2020\",\n",
    "    \"GONI2020\",\n",
    "    \"VAMCO2020\",\n",
    "    \"VONGFONG2020\",\n",
    "    \"MOLAVE2020\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9cf0a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADM3_PCODE</th>\n",
       "      <th>id_x</th>\n",
       "      <th>Centroid</th>\n",
       "      <th>numbuildings_x</th>\n",
       "      <th>id</th>\n",
       "      <th>numbuildings</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PH012801000</td>\n",
       "      <td>11049.0</td>\n",
       "      <td>120.9E_18.5N</td>\n",
       "      <td>1052</td>\n",
       "      <td>11049</td>\n",
       "      <td>1794</td>\n",
       "      <td>0.586399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PH012810000</td>\n",
       "      <td>11049.0</td>\n",
       "      <td>120.9E_18.5N</td>\n",
       "      <td>0</td>\n",
       "      <td>11049</td>\n",
       "      <td>1794</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PH012815000</td>\n",
       "      <td>11049.0</td>\n",
       "      <td>120.9E_18.5N</td>\n",
       "      <td>742</td>\n",
       "      <td>11049</td>\n",
       "      <td>1794</td>\n",
       "      <td>0.413601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PH012801000</td>\n",
       "      <td>11050.0</td>\n",
       "      <td>120.9E_18.4N</td>\n",
       "      <td>193</td>\n",
       "      <td>11050</td>\n",
       "      <td>196</td>\n",
       "      <td>0.984694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PH012810000</td>\n",
       "      <td>11050.0</td>\n",
       "      <td>120.9E_18.4N</td>\n",
       "      <td>0</td>\n",
       "      <td>11050</td>\n",
       "      <td>196</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ADM3_PCODE     id_x      Centroid  numbuildings_x     id  numbuildings  \\\n",
       "0  PH012801000  11049.0  120.9E_18.5N            1052  11049          1794   \n",
       "1  PH012810000  11049.0  120.9E_18.5N               0  11049          1794   \n",
       "2  PH012815000  11049.0  120.9E_18.5N             742  11049          1794   \n",
       "3  PH012801000  11050.0  120.9E_18.4N             193  11050           196   \n",
       "4  PH012810000  11050.0  120.9E_18.4N               0  11050           196   \n",
       "\n",
       "     weight  \n",
       "0  0.586399  \n",
       "1  0.000000  \n",
       "2  0.413601  \n",
       "3  0.984694  \n",
       "4  0.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the new weight CSV file and import to a df\n",
    "df_weight = weight_file(\"/ggl_grid_to_mun_weights.csv\")\n",
    "df_weight.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ee4dbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADM3_PCODE</th>\n",
       "      <th>id_x</th>\n",
       "      <th>Centroid</th>\n",
       "      <th>numbuildings_x</th>\n",
       "      <th>grid_point_id</th>\n",
       "      <th>numbuildings</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PH012801000</td>\n",
       "      <td>11049.0</td>\n",
       "      <td>120.9E_18.5N</td>\n",
       "      <td>1052</td>\n",
       "      <td>11049</td>\n",
       "      <td>1794</td>\n",
       "      <td>0.586399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PH012810000</td>\n",
       "      <td>11049.0</td>\n",
       "      <td>120.9E_18.5N</td>\n",
       "      <td>0</td>\n",
       "      <td>11049</td>\n",
       "      <td>1794</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PH012815000</td>\n",
       "      <td>11049.0</td>\n",
       "      <td>120.9E_18.5N</td>\n",
       "      <td>742</td>\n",
       "      <td>11049</td>\n",
       "      <td>1794</td>\n",
       "      <td>0.413601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PH012801000</td>\n",
       "      <td>11050.0</td>\n",
       "      <td>120.9E_18.4N</td>\n",
       "      <td>193</td>\n",
       "      <td>11050</td>\n",
       "      <td>196</td>\n",
       "      <td>0.984694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PH012810000</td>\n",
       "      <td>11050.0</td>\n",
       "      <td>120.9E_18.4N</td>\n",
       "      <td>0</td>\n",
       "      <td>11050</td>\n",
       "      <td>196</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ADM3_PCODE     id_x      Centroid  numbuildings_x  grid_point_id  \\\n",
       "0  PH012801000  11049.0  120.9E_18.5N            1052          11049   \n",
       "1  PH012810000  11049.0  120.9E_18.5N               0          11049   \n",
       "2  PH012815000  11049.0  120.9E_18.5N             742          11049   \n",
       "3  PH012801000  11050.0  120.9E_18.4N             193          11050   \n",
       "4  PH012810000  11050.0  120.9E_18.4N               0          11050   \n",
       "\n",
       "   numbuildings    weight  \n",
       "0          1794  0.586399  \n",
       "1          1794  0.000000  \n",
       "2          1794  0.413601  \n",
       "3           196  0.984694  \n",
       "4           196  0.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change name of column ['id'] to ['grid_point_id'] the same name as in input df\n",
    "df_weight.rename(columns={\"id\": \"grid_point_id\"}, inplace=True)\n",
    "df_weight.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5cc8e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify features\n",
    "features = [\n",
    "    \"wind_speed\",\n",
    "    \"track_distance\",\n",
    "    \"total_houses\",\n",
    "    \"rainfall_max_6h\",\n",
    "    \"rainfall_max_24h\",\n",
    "    \"rwi\",\n",
    "    # \"strong_roof_strong_wall\",\n",
    "    # \"strong_roof_light_wall\",\n",
    "    # \"strong_roof_salvage_wall\",\n",
    "    # \"light_roof_strong_wall\",\n",
    "    # \"light_roof_light_wall\",\n",
    "    # \"light_roof_salvage_wall\",\n",
    "    # \"salvaged_roof_strong_wall\",\n",
    "    # \"salvaged_roof_light_wall\",\n",
    "    # \"salvaged_roof_salvage_wall\",\n",
    "    \"mean_slope\",\n",
    "    \"std_slope\",\n",
    "    \"mean_tri\",\n",
    "    \"std_tri\",\n",
    "    \"mean_elev\",\n",
    "    \"coast_length\",\n",
    "    \"with_coast\",\n",
    "    \"urban\",\n",
    "    \"rural\",\n",
    "    \"water\",\n",
    "    \"total_pop\",\n",
    "    \"percent_houses_damaged_5years\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2319bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins\n",
    "bins2 = [0, 0.00009, 1, 10, 50, 101]\n",
    "samples_per_bin2, binsP2 = np.histogram(df_data[\"percent_houses_damaged\"], bins=bins2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63d341fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define range of for loops\n",
    "num_exp_main = 20\n",
    "\n",
    "# Latest typhoons in terms of time\n",
    "num_exp = 12\n",
    "typhoons_for_test = typhoons[-num_exp:]\n",
    "\n",
    "# LOOCV\n",
    "#num_exp = len(typhoons)\n",
    "\n",
    "# Define number of bins\n",
    "num_bins = len(bins2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cbf77d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define empty list to save RMSE in each iteration\n",
    "main_RMSE_lst = []\n",
    "main_RMSE_bin = defaultdict(list)\n",
    "\n",
    "main_AVE_lst = []\n",
    "main_AVE_bin = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a060453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOCK-TEN2016']\n",
      "801\n",
      "432\n",
      "RMSE for grid_based model: 5.94\n",
      "Average Error for grid_based model: 1.46\n",
      "['SARIKA2016']\n",
      "830\n",
      "66\n",
      "RMSE for grid_based model: 0.47\n",
      "Average Error for grid_based model: -0.14\n",
      "['MANGKHUT2018']\n",
      "345\n",
      "280\n",
      "RMSE for grid_based model: 4.64\n",
      "Average Error for grid_based model: 1.41\n",
      "['YUTU2018']\n",
      "562\n",
      "173\n",
      "RMSE for grid_based model: 0.77\n",
      "Average Error for grid_based model: -0.05\n",
      "['KAMMURI2019']\n",
      "821\n",
      "328\n",
      "RMSE for grid_based model: 4.55\n",
      "Average Error for grid_based model: 0.42\n",
      "['NAKRI2019']\n",
      "6\n",
      "2\n",
      "RMSE for grid_based model: 0.02\n",
      "Average Error for grid_based model: 0.02\n",
      "['PHANFONE2019']\n",
      "922\n",
      "218\n",
      "RMSE for grid_based model: 4.51\n",
      "Average Error for grid_based model: -2.02\n",
      "['SAUDEL2020']\n",
      "711\n",
      "2\n",
      "RMSE for grid_based model: 0.17\n",
      "Average Error for grid_based model: 0.17\n",
      "['GONI2020']\n",
      "826\n",
      "229\n",
      "RMSE for grid_based model: 2.86\n",
      "Average Error for grid_based model: -0.61\n",
      "['VAMCO2020']\n",
      "751\n",
      "296\n",
      "RMSE for grid_based model: 1.38\n",
      "Average Error for grid_based model: -0.28\n",
      "['VONGFONG2020']\n",
      "1172\n",
      "313\n",
      "RMSE for grid_based model: 4.00\n",
      "Average Error for grid_based model: -0.40\n",
      "['MOLAVE2020']\n",
      "737\n",
      "125\n",
      "RMSE for grid_based model: 1.22\n",
      "Average Error for grid_based model: 0.44\n",
      "[5.9434499223548185, 0.46952847372691847, 4.638136248973591, 0.7730202256359381, 4.548609216541342, 0.023273978195560485, 4.510291416370362, 0.17413787423671478, 2.8644752480357645, 1.3793069634013775, 3.9957745550200165, 1.2213774750867892]\n",
      "['NOCK-TEN2016']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sx/c10hm4fj3glf7mw1_mzwcl700000gn/T/ipykernel_83641/3224178597.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0meval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mxgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# Make prediction on train and test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/global-storm/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/global-storm/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/global-storm/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \"\"\"\n\u001b[0;32m--> 188\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    189\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/global-storm/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/global-storm/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1680\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1681\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for run_exm in range(num_exp_main):\n",
    "\n",
    "    # Define empty list to save RMSE in combined model\n",
    "    test_RMSE_lst = []\n",
    "    test_RMSE_bin = defaultdict(list)\n",
    "\n",
    "    # Define empty list to save RMSE in model1\n",
    "    test_RMSE_lst_M1 = []\n",
    "    test_RMSE_bin_M1 = defaultdict(list)\n",
    "\n",
    "    # Defin two lists to save RMSE and Average Error\n",
    "    RMSE = defaultdict(list)\n",
    "    AVE = defaultdict(list)\n",
    "\n",
    "    #for run_ix in range(27, num_exp):\n",
    "    for run_ix in range(num_exp):\n",
    "\n",
    "        # WITHOUT removing old typhoons from training set\n",
    "        typhoons_train_lst = typhoons[0 : run_ix + 27]\n",
    "\n",
    "        # WITH removing old typhoons from training set\n",
    "        # typhoons_train_lst = typhoons[run_ix : run_ix + 27]\n",
    "\n",
    "        # In each run Keep one typhoon for the test list while the rest of the typhoons in the training set\n",
    "        #typhoons_for_test = typhoons[run_ix]\n",
    "        #typhoons_train_lst = typhoons[:run_ix] + typhoons[run_ix + 1 :]\n",
    "\n",
    "        # Random split\n",
    "        # typhoons_for_test = test_list[run_ix]\n",
    "        # typhoons_train_lst = train_list\n",
    "\n",
    "        # print(typhoons_train_lst)\n",
    "\n",
    "        bin_index2 = np.digitize(df_data[\"percent_houses_damaged\"], bins=binsP2)\n",
    "        y_input_strat = bin_index2\n",
    "\n",
    "        # Split X and y from dataframe features\n",
    "        X = df_data[features]\n",
    "        y = df_data[\"percent_houses_damaged\"]\n",
    "\n",
    "        # Split df to train and test (one typhoon for test and the rest of typhoons for train)\n",
    "        # For when we train over all typhoon this df_test is required\n",
    "        #df_test = df_data[df_data[\"typhoon_name\"] == typhoons_for_test]\n",
    "\n",
    "        df_test = df[df[\"typhoon_name\"] == typhoons_for_test[run_ix]]\n",
    "\n",
    "        df_train = pd.DataFrame()\n",
    "        for run_ix_train in range(len(typhoons_train_lst)):\n",
    "            df_train = df_train.append(\n",
    "                df_data[df_data[\"typhoon_name\"] == typhoons_train_lst[run_ix_train]]\n",
    "            )\n",
    "\n",
    "        # Split X and y from dataframe features\n",
    "        X_test = df_test[features]\n",
    "        X_train = df_train[features]\n",
    "\n",
    "        y_train = df_train[\"percent_houses_damaged\"]\n",
    "        y_test = df_test[\"percent_houses_damaged\"]\n",
    "\n",
    "        print(df_test[\"typhoon_name\"].unique())\n",
    "\n",
    "        # XGBoost Reduced Overfitting\n",
    "        xgb = XGBRegressor(\n",
    "            base_score=0.5,\n",
    "            booster=\"gbtree\",\n",
    "            colsample_bylevel=0.8,\n",
    "            colsample_bynode=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            gamma=3,\n",
    "            eta=0.01,\n",
    "            importance_type=\"gain\",\n",
    "            learning_rate=0.1,\n",
    "            max_delta_step=0,\n",
    "            max_depth=4,\n",
    "            min_child_weight=1,\n",
    "            missing=1,\n",
    "            n_estimators=100,\n",
    "            early_stopping_rounds=10,\n",
    "            n_jobs=1,\n",
    "            nthread=None,\n",
    "            objective=\"reg:squarederror\",\n",
    "            reg_alpha=0,\n",
    "            reg_lambda=1,\n",
    "            scale_pos_weight=1,\n",
    "            seed=None,\n",
    "            silent=None,\n",
    "            subsample=0.8,\n",
    "            verbosity=0,\n",
    "            eval_metric=[\"rmse\", \"logloss\"],\n",
    "            random_state=0,\n",
    "        )\n",
    "\n",
    "        eval_set = [(X_train, y_train)]\n",
    "        xgb_model = xgb.fit(X_train, y_train, eval_set=eval_set, verbose=False)\n",
    "\n",
    "        # Make prediction on train and test data\n",
    "        y_pred_train = xgb.predict(X_train)\n",
    "        y_pred = xgb.predict(X_test)\n",
    "\n",
    "        # Calculate RMSE in total\n",
    "        mse_train_idx = mean_squared_error(y_train, y_pred_train)\n",
    "        rmse_train = np.sqrt(mse_train_idx)\n",
    "\n",
    "        mse_idx = mean_squared_error(y_test, y_pred)\n",
    "        rmseM1 = np.sqrt(mse_idx)\n",
    "\n",
    "        # Add total RMSE of Model1 to the list\n",
    "        test_RMSE_lst_M1.insert(run_ix, rmseM1)\n",
    "        # print(\"RMSE in total and per bin (M1 model)\")\n",
    "        # print(f\"total: {rmseM1:.2f}\")\n",
    "\n",
    "        # Calculate RMSE per bins\n",
    "        bin_index_test = np.digitize(y_test, bins=binsP2)\n",
    "        RSME_test_model1 = np.zeros(num_bins - 1)\n",
    "\n",
    "        for bin_num in range(1, num_bins):\n",
    "\n",
    "            # Estimation of RMSE for test data\n",
    "            if (\n",
    "                len(y_test[bin_index_test == bin_num]) != 0\n",
    "                and len(y_pred[bin_index_test == bin_num]) != 0\n",
    "            ):\n",
    "                mse_idx = mean_squared_error(\n",
    "                    y_test[bin_index_test == bin_num], y_pred[bin_index_test == bin_num]\n",
    "                )\n",
    "                RSME_test_model1[bin_num - 1] = np.sqrt(mse_idx)\n",
    "\n",
    "                # Add RMSE of Model1 to the list of each bin\n",
    "                test_RMSE_bin_M1[bin_num].append(RSME_test_model1[bin_num - 1])\n",
    "                # print(f\"bin{[bin_num]}:{RSME_test_model1[bin_num-1]}\")\n",
    "        # else:\n",
    "        #    test_RMSE_bin_M1[bin_num].insert(run_ix, \"No exist\")\n",
    "\n",
    "        # Define a threshold to separate target into damaged and not_damaged\n",
    "        thres = 10.0\n",
    "        y_test_bool = y_test >= thres\n",
    "        y_train_bool = y_train >= thres\n",
    "        y_test_bin = (y_test_bool) * 1\n",
    "        y_train_bin = (y_train_bool) * 1\n",
    "\n",
    "        sum(y_train_bin)\n",
    "\n",
    "        ## Define undersampling strategy\n",
    "        under = RandomUnderSampler(sampling_strategy=0.1)\n",
    "\n",
    "        # Fit and apply the transform\n",
    "        X_train_us, y_train_us = under.fit_resample(X_train, y_train_bin)\n",
    "\n",
    "        # Use XGBClassifier as a Machine Learning model to fit the data\n",
    "        xgb_model = XGBClassifier(eval_metric=[\"error\", \"logloss\"])\n",
    "\n",
    "        eval_set = [(X_train, y_train_bin)]\n",
    "        xgb_model.fit(\n",
    "            X_train_us,\n",
    "            y_train_us,\n",
    "            eval_set=eval_set,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        # Make prediction on test data and print Confusion Matrix\n",
    "        y_pred_test = xgb_model.predict(X_test)\n",
    "        cm_test = confusion_matrix(y_test_bin, y_pred_test)\n",
    "        # print(cm_test)\n",
    "\n",
    "        # Make prediction on train data and print Confusion Matrix\n",
    "        y_pred_train = xgb_model.predict(X_train)\n",
    "        cm_train = confusion_matrix(y_train_bin, y_pred_train)\n",
    "        # print(cm_train)\n",
    "\n",
    "        y_pred_train_us = xgb_model.predict(X_train_us)\n",
    "        cm_train_us = confusion_matrix(y_train_us, y_pred_train_us)\n",
    "        # print(cm_train_us)\n",
    "\n",
    "        reduced_df = X_train.copy()\n",
    "\n",
    "        reduced_df[\"percent_houses_damaged\"] = y_train.values\n",
    "        reduced_df[\"predicted_value\"] = y_pred_train\n",
    "\n",
    "        fliterd_df = reduced_df[reduced_df.predicted_value == 1]\n",
    "\n",
    "        ### Third step is to train XGBoost regression model for this reduced train data (including damg>10.0%)\n",
    "        bin_index2 = np.digitize(fliterd_df[\"percent_houses_damaged\"], bins=binsP2)\n",
    "        y_input_strat = bin_index2\n",
    "\n",
    "        # Split X and y from dataframe features\n",
    "        X_r = fliterd_df[features]\n",
    "        y_r = fliterd_df[\"percent_houses_damaged\"]\n",
    "\n",
    "        # XGBoost Reduced Overfitting\n",
    "        xgbR = XGBRegressor(\n",
    "            base_score=0.5,\n",
    "            booster=\"gbtree\",\n",
    "            colsample_bylevel=0.8,\n",
    "            colsample_bynode=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            gamma=3,\n",
    "            eta=0.01,\n",
    "            importance_type=\"gain\",\n",
    "            learning_rate=0.1,\n",
    "            max_delta_step=0,\n",
    "            max_depth=4,\n",
    "            min_child_weight=1,\n",
    "            missing=1,\n",
    "            n_estimators=100,\n",
    "            early_stopping_rounds=10,\n",
    "            n_jobs=1,\n",
    "            nthread=None,\n",
    "            objective=\"reg:squarederror\",\n",
    "            reg_alpha=0,\n",
    "            reg_lambda=1,\n",
    "            scale_pos_weight=1,\n",
    "            seed=None,\n",
    "            silent=None,\n",
    "            subsample=0.8,\n",
    "            verbosity=0,\n",
    "            eval_metric=[\"rmse\", \"logloss\"],\n",
    "            random_state=0,\n",
    "        )\n",
    "\n",
    "        eval_set = [(X_r, y_r)]\n",
    "        xgbR_model = xgbR.fit(X_r, y_r, eval_set=eval_set, verbose=False)\n",
    "\n",
    "        # Make prediction on train and global test data\n",
    "        y_pred_r = xgbR.predict(X_r)\n",
    "        y_pred_test_total = xgbR.predict(X_test)\n",
    "\n",
    "        # Calculate RMSE in total\n",
    "\n",
    "        mse_train_idxR = mean_squared_error(y_r, y_pred_r)\n",
    "        rmse_trainR = np.sqrt(mse_train_idxR)\n",
    "\n",
    "        mse_idxR = mean_squared_error(y_test, y_pred_test_total)\n",
    "        rmseR = np.sqrt(mse_idxR)\n",
    "\n",
    "        ## Last step is to add model combination (model M1 with model MR)\n",
    "        # Check the result of classifier for test set\n",
    "        reduced_test_df = X_test.copy()\n",
    "\n",
    "        # joined X_test with countinous target and binary predicted values\n",
    "        reduced_test_df[\"percent_houses_damaged\"] = y_test.values\n",
    "        reduced_test_df[\"predicted_value\"] = y_pred_test\n",
    "\n",
    "        # damaged prediction\n",
    "        fliterd_test_df1 = reduced_test_df[reduced_test_df.predicted_value == 1]\n",
    "\n",
    "        # not damaged prediction\n",
    "        fliterd_test_df0 = reduced_test_df[reduced_test_df.predicted_value == 0]\n",
    "\n",
    "        # Use X0 and X1 for the M1 and MR models' predictions\n",
    "        X1 = fliterd_test_df1[features]\n",
    "        X0 = fliterd_test_df0[features]\n",
    "\n",
    "        # For the output equal to 1 apply MR to evaluate the performance\n",
    "        y1_pred = xgbR.predict(X1)\n",
    "        y1 = fliterd_test_df1[\"percent_houses_damaged\"]\n",
    "\n",
    "        # For the output equal to 0 apply M1 to evaluate the performance\n",
    "        y0_pred = xgb.predict(X0)\n",
    "        y0 = fliterd_test_df0[\"percent_houses_damaged\"]\n",
    "\n",
    "        fliterd_test_df0[\"predicted_percent_damage\"] = y0_pred\n",
    "        if len(y1_pred) > 0:\n",
    "            fliterd_test_df1[\"predicted_percent_damage\"] = y1_pred\n",
    "\n",
    "        # Join two dataframes together\n",
    "        join_test_dfs = pd.concat([fliterd_test_df0, fliterd_test_df1])\n",
    "\n",
    "        y_join = join_test_dfs[\"percent_houses_damaged\"]\n",
    "        y_pred_join = join_test_dfs[\"predicted_percent_damage\"]\n",
    "\n",
    "        pred_df = pd.DataFrame(columns=[\"y_all\", \"y_pred_all\"])\n",
    "\n",
    "        pred_df[\"y_all\"] = y_join\n",
    "        pred_df[\"y_pred_all\"] = y_pred_join\n",
    "\n",
    "        # Filter damages greater than 10 to estimate RMSE for these values\n",
    "        # pred_df[\"y_all\"] = y_join[y_join > 10]\n",
    "        # pred_df[\"y_pred_all\"] = y_pred_join[y_join > 10]\n",
    "        \n",
    "\n",
    "        # Join data with y_all and y_all_pred\n",
    "        df_data_w_pred = pd.merge(pred_df, df_data, left_index=True, right_index=True)\n",
    "        # Join data with grid_point_id typhoon_year\n",
    "        df_data_w_pred_grid = pd.merge(\n",
    "            df[[\"grid_point_id\", \"typhoon_year\"]],\n",
    "            df_data_w_pred,\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "        )\n",
    "        df_data_w_pred_grid.sort_values(\"y_pred_all\", ascending=False)\n",
    "\n",
    "        # join with weights df\n",
    "        join_df = df_data_w_pred_grid.merge(df_weight, on=\"grid_point_id\", how=\"left\")\n",
    "\n",
    "        # Indicate where values are valid and not missing\n",
    "        join_df = join_df.loc[join_df[\"weight\"].notna()]\n",
    "\n",
    "        # Multiply weight by y_all and y_pred_all\n",
    "        join_df[\"weight*y_pred*houses\"] = (\n",
    "            join_df[\"y_pred_all\"] * join_df[\"weight\"] * join_df[\"total_houses\"] / 100\n",
    "        )\n",
    "        join_df[\"weight*y*houses\"] = (\n",
    "            join_df[\"y_all\"] * join_df[\"weight\"] * join_df[\"total_houses\"] / 100\n",
    "        )\n",
    "        join_df[\"weight*houses\"] = join_df[\"weight\"] * join_df[\"total_houses\"]\n",
    "\n",
    "        join_df.sort_values(\"y_pred_all\", ascending=False)\n",
    "\n",
    "        # Groupby by municipality and typhoon_name with sum as the aggregation function\n",
    "        agg_df = join_df.groupby([\"ADM3_PCODE\", \"typhoon_name\", \"typhoon_year\"]).agg(\n",
    "            \"sum\"\n",
    "        )\n",
    "\n",
    "        # Normalize by the sum of the weights\n",
    "        agg_df[\"y_pred_norm\"] = (\n",
    "            agg_df[\"weight*y_pred*houses\"] / agg_df[\"weight*houses\"] * 100\n",
    "        )\n",
    "        agg_df[\"y_norm\"] = agg_df[\"weight*y*houses\"] / agg_df[\"weight*houses\"] * 100\n",
    "\n",
    "        # Drop not required column y and y_pred before multiplying by weight\n",
    "        agg_df.drop(\"y_all\", axis=1, inplace=True)\n",
    "        agg_df.drop(\"y_pred_all\", axis=1, inplace=True)\n",
    "\n",
    "        # Remove rows with NaN after normalization\n",
    "        final_df = agg_df.dropna()\n",
    "        final_df=final_df.reset_index()\n",
    "        print(len(final_df))\n",
    "        \n",
    "        # Intersection of two datasets grid and municipality    \n",
    "        # Rename a column\n",
    "        final_df = final_df.rename(columns={\"ADM3_PCODE\": \"Mun_Code\", \"typhoon_name\": \"typhoon\"})\n",
    "        \n",
    "        # Merge DataFrames based on 'typhoon_name' and 'Mun_Code'\n",
    "        merged_df = pd.merge(final_df, df_mun_merged, on=[\"Mun_Code\", \"typhoon\"], how=\"inner\")\n",
    "        print(len(merged_df))\n",
    "\n",
    "        # Calculate RMSE & Average Error in total for converted grid_based model to Mun_based\n",
    "        if len(merged_df[\"y_norm\"]) > 0:\n",
    "            rmse = sqrt(mean_squared_error(merged_df[\"y_norm\"], merged_df[\"y_pred_norm\"]))\n",
    "            ave = (merged_df[\"y_pred_norm\"] - merged_df[\"y_norm\"]).sum() / len(\n",
    "                merged_df[\"y_norm\"]\n",
    "            )\n",
    "\n",
    "            print(f\"RMSE for grid_based model: {rmse:.2f}\")\n",
    "            print(f\"Average Error for grid_based model: {ave:.2f}\")\n",
    "\n",
    "            RMSE[\"all\"].append(rmse)\n",
    "            AVE[\"all\"].append(ave)\n",
    "\n",
    "        bin_index = np.digitize(merged_df[\"y_norm\"], bins=binsP2)\n",
    "\n",
    "        for bin_num in range(1, 6):\n",
    "            if len(merged_df[\"y_norm\"][bin_index == bin_num]) > 0:\n",
    "\n",
    "                mse_idx = mean_squared_error(\n",
    "                    merged_df[\"y_norm\"][bin_index == bin_num],\n",
    "                    merged_df[\"y_pred_norm\"][bin_index == bin_num],\n",
    "                )\n",
    "                rmse = np.sqrt(mse_idx)\n",
    "\n",
    "                ave = (\n",
    "                    merged_df[\"y_pred_norm\"][bin_index == bin_num]\n",
    "                    - merged_df[\"y_norm\"][bin_index == bin_num]\n",
    "                ).sum() / len(merged_df[\"y_norm\"][bin_index == bin_num])\n",
    "\n",
    "                RMSE[bin_num].append(rmse)\n",
    "                AVE[bin_num].append(ave)\n",
    "    print(RMSE[\"all\"])\n",
    "    # Save total RMSE in each iteration\n",
    "\n",
    "    main_RMSE_lst.append(RMSE[\"all\"])\n",
    "    main_AVE_lst.append(AVE[\"all\"])\n",
    "\n",
    "    for bin_num in range(1, 6):\n",
    "\n",
    "        # Save RMSE per bin in each iteration\n",
    "        main_RMSE_bin[bin_num].append(RMSE[bin_num])\n",
    "        main_AVE_bin[bin_num].append(AVE[bin_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f77f19c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.55\n",
      "stdev: 1.98\n",
      "Average Error: 0.03\n",
      "Stdev of Average Error: 0.87\n"
     ]
    }
   ],
   "source": [
    "# Estimate total RMSE\n",
    "\n",
    "rmse = statistics.mean(list(chain.from_iterable(main_RMSE_lst)))\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "\n",
    "sd_rmse = statistics.stdev(list(chain.from_iterable(main_RMSE_lst)))\n",
    "print(f\"stdev: {sd_rmse:.2f}\")\n",
    "\n",
    "ave = statistics.mean(list(chain.from_iterable(main_AVE_lst)))\n",
    "print(f\"Average Error: {ave:.2f}\")\n",
    "\n",
    "sd_ave = statistics.stdev(list(chain.from_iterable(main_AVE_lst)))\n",
    "print(f\"Stdev of Average Error: {sd_ave:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "113828f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE & STDEV & Average Error per bin 1\n",
      "RMSE: 0.10\n",
      "STDEV: 0.07\n",
      "Average_Error: 0.02\n",
      "Stdev of Average_Error: 0.05\n",
      "\n",
      "RMSE & STDEV & Average Error per bin 2\n",
      "RMSE: 1.32\n",
      "STDEV: 1.84\n",
      "Average_Error: 0.51\n",
      "Stdev of Average_Error: 1.03\n",
      "\n",
      "RMSE & STDEV & Average Error per bin 3\n",
      "RMSE: 4.82\n",
      "STDEV: 3.42\n",
      "Average_Error: 0.69\n",
      "Stdev of Average_Error: 3.17\n",
      "\n",
      "RMSE & STDEV & Average Error per bin 4\n",
      "RMSE: 12.89\n",
      "STDEV: 3.08\n",
      "Average_Error: -2.89\n",
      "Stdev of Average_Error: 9.83\n",
      "\n",
      "RMSE & STDEV & Average Error per bin 5\n",
      "RMSE: 31.05\n",
      "STDEV: 21.92\n",
      "Average_Error: -31.05\n",
      "Stdev of Average_Error: 21.92\n"
     ]
    }
   ],
   "source": [
    "# Estimate RMSE per bin\n",
    "\n",
    "for bin_num in range(1, 6):\n",
    "\n",
    "    rmse_bin = statistics.mean(list(chain.from_iterable(main_RMSE_bin[bin_num])))\n",
    "    sd_rmse_bin = statistics.stdev(list(chain.from_iterable(main_RMSE_bin[bin_num])))\n",
    "    ave_bin = statistics.mean(list(chain.from_iterable(main_AVE_bin[bin_num])))\n",
    "    sd_ave_bin = statistics.stdev(list(chain.from_iterable(main_AVE_bin[bin_num])))\n",
    "\n",
    "    print(f\"\\nRMSE & STDEV & Average Error per bin {bin_num}\")\n",
    "\n",
    "    print(f\"RMSE: {rmse_bin:.2f}\")\n",
    "    print(f\"STDEV: {sd_rmse_bin:.2f}\")\n",
    "    print(f\"Average_Error: {ave_bin:.2f}\")\n",
    "    print(f\"Stdev of Average_Error: {sd_ave_bin:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15307c29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
