{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a83e7e8-5a32-4877-bccf-a1f5398ee37d",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "## NOTE: This notebook uses a previous version of the dataset that included total buildings and will not run with current data set that uses total houses.\n",
    "\n",
    "Baseline is the simplest algorithm that provides predictions \n",
    "without complex computations. For regression tasks, the Baseline \n",
    "returns the average of the target from training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6b37d9-2953-4b52-a267-aa37848686d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f435bf7-203f-4fa6-8aa5-8dbcfe89e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from utils import get_training_dataset, RS_BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6636b9df-3470-438c-a1d5-68c3e5a4a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file and import to df\n",
    "df = get_training_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2efca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show histogram of damage\n",
    "df.hist(column=\"percent_buildings_damaged\", figsize=(4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fc3d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hist plot after data stratification\n",
    "bins2 = [0, 0.00009, 1, 10, 50, 101]\n",
    "samples_per_bin2, binsP2 = np.histogram(\n",
    "    df[\"percent_buildings_damaged\"], bins=bins2\n",
    ")\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.xlabel(\"Damage Values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.plot(binsP2[1:], samples_per_bin2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8001bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove zeros from wind_speed\n",
    "df = df[(df[[\"wind_speed\"]] != 0).any(axis=1)]\n",
    "\n",
    "df = df.drop(columns=[\"grid_point_id\", \"typhoon_year\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8e7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hist plot after removing rows where windspeed is 0\n",
    "bins2 = [0, 0.00009, 1, 10, 50, 101]\n",
    "samples_per_bin2, binsP2 = np.histogram(\n",
    "    df[\"percent_buildings_damaged\"], bins=bins2\n",
    ")\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.xlabel(\"Damage Values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.plot(binsP2[1:], samples_per_bin2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d63e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples_per_bin2)\n",
    "print(binsP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dbd369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the bins' intervalls\n",
    "# df[\"percent_buildings_damaged\"].value_counts(bins=binsP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ecbbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_index2 = np.digitize(df[\"percent_buildings_damaged\"], bins=binsP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c050a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_input_strat = bin_index2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f70d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y from dataframe features\n",
    "\n",
    "features = [\"track_distance\", \"wind_speed\", \"total_buildings\"]\n",
    "X = df[features]\n",
    "display(X.columns)\n",
    "y = df[\"percent_buildings_damaged\"]\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be59307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled,\n",
    "    df[\"percent_buildings_damaged\"],\n",
    "    stratify=y_input_strat,\n",
    "    test_size=0.2,\n",
    "    random_state=RS_BASE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7106eea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy(X_train, X_test, y_train, y_test, num_bin):\n",
    "    # create a dummy regressor\n",
    "    dummy_reg = DummyRegressor(strategy=\"mean\")\n",
    "\n",
    "    # fit it on the training set\n",
    "    dummy_reg.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions on the test set\n",
    "    y_pred = dummy_reg.predict(X_test)\n",
    "    y_pred_train = dummy_reg.predict(X_train)\n",
    "\n",
    "    bin_index_test = np.digitize(y_test, bins=binsP2)\n",
    "    bin_index_train = np.digitize(y_train, bins=binsP2)\n",
    "\n",
    "    # Estimation of RMSE for train data per each bin\n",
    "    mse_train = mean_squared_error(\n",
    "        y_train[bin_index_train == num_bin],\n",
    "        y_pred_train[bin_index_train == num_bin],\n",
    "    )\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "\n",
    "    # Estimation of RMSE for test data per each bin\n",
    "    mse = mean_squared_error(\n",
    "        y_test[bin_index_test == num_bin], y_pred[bin_index_test == num_bin]\n",
    "    )\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    print(f\"RMSE per bin\")\n",
    "    print(f\"Dummy_RMSE_test per bin: {rmse:.2f}\")\n",
    "    print(f\"Dummy_RMSE_train per bin: {rmse_train:.2f}\", \"\\n\")\n",
    "\n",
    "    # calculate root mean squared error in total\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "\n",
    "    print(f\"RMSE in total\")\n",
    "    print(f\"total_RMSE_test: {rmse:.2f}\")\n",
    "    print(f\"total_RMSE_train: {rmse_train:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ccbb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the number of bin\n",
    "create_dummy(X_train, X_test, y_train, y_test, 2)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
