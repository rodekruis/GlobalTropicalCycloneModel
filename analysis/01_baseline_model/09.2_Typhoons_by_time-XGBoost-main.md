Implementing XGBoost Regression model on the input data

Estimate and plot the Root Mean Square Error of 8 different test sets.

The idea is to do a train-test-split based on the typhoon's time. Therefore, typhoons are ordered with respect to their time of occurrence and then the 8 recent typhoons are selected as the test set (8 as a test over 39 typhoons in total means 20% as a test while 80% as a train). Then 8 different RMSEs are estimated while for each calculation one of the less recent typhoons was dropped from the test set and added to the train set. The idea is to determine how well the model performs in learning from older typhoons' characteristics to make predictions on the target value of the most recent ones.

```python
import os
import numpy as np
import pandas as pd
import xgboost as xgb

from sklearn import preprocessing
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import train_test_split
from xgboost.sklearn import XGBRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, max_error
from numpy.lib.function_base import average

import statistics
import matplotlib.pyplot as plt


wor_dir="/home/mforooshani/Typhoon-Impact-based-forecasting-model-training-5:7/IBF-Typhoon-model/"
os.chdir(wor_dir)
cdir = os.getcwd()

combined_input_data=pd.read_csv("Training-data-new/data/model_input/combined_input_data.csv")
#display(combined_input_data)

typhoons_with_impact_data=['bopha2012', 'conson2010', 'durian2006', 'fengshen2008',
       'fung-wong2014', 'goni2015', 'goni2020', 'hagupit2014',
       'haima2016', 'haiyan2013', 'jangmi2014', 'kalmaegi2014',
       'kammuri2019', 'ketsana2009', 'koppu2015', 'krosa2013',
       'linfa2015', 'lingling2014', 'mangkhut2018', 'mekkhala2015',
       'melor2015', 'meranti2016', 'molave2020', 'mujigae2015',
       'nakri2019', 'nari2013', 'nesat2011', 'nock-ten2016', 'noul2015',
       'phanfone2019', 'rammasun2014', 'sarika2016', 'saudel2020',
       'tokage2016', 'trami2013', 'usagi2013', 'utor2013', 'vamco2020',
       'vongfong2020', 'yutu2018']

len(np.unique(combined_input_data.typhoon))
combined_input_data=combined_input_data[combined_input_data.typhoon.isin(typhoons_with_impact_data)]


def set_zeros(x):
    x_max = 25
    y_max = 50
    
    v_max = x[0]
    rainfall_max = x[1]
    damage = x[2]
    if pd.notnull(damage):
        value = damage
    elif v_max > x_max or rainfall_max > y_max:
        value =damage
    elif (v_max < np.sqrt((1- (rainfall_max**2/y_max ** 2))*x_max ** 2)):
        value = 0
    #elif ((v_max < x_max)  and  (rainfall_max_6h < y_max) ):
    #elif (v_max < x_max ):
    #value = 0
    else:
        value = np.nan

    return value
combined_input_data["DAM_perc_dmg"] = combined_input_data[["HAZ_v_max", "HAZ_rainfall_Total", "DAM_perc_dmg"]].apply(set_zeros, axis="columns")


np.mean(combined_input_data["DAM_perc_dmg"])
combined_input_data = combined_input_data[combined_input_data['DAM_perc_dmg'].notnull()]
np.mean(combined_input_data["DAM_perc_dmg"])
np.unique(combined_input_data.typhoon)

def cubeic(x):
    #x=float(x)
    value=x*x*x
    return value

combined_input_data['HAZ_v_max_3']=combined_input_data['HAZ_v_max'].apply(lambda x: x*x*x) 


combined_input_data =combined_input_data.filter(['typhoon','HAZ_rainfall_Total', 
        'HAZ_rainfall_max_6h',
        'HAZ_rainfall_max_24h',
        'HAZ_v_max',
        'HAZ_v_max_3',
        'HAZ_dis_track_min',
        'GEN_landslide_per',
        'GEN_stormsurge_per',
        'GEN_Bu_p_inSSA', 
        'GEN_Bu_p_LS', 
        'GEN_Red_per_LSbldg',
        'GEN_Or_per_LSblg', 
        'GEN_Yel_per_LSSAb', 
        'GEN_RED_per_SSAbldg',
        'GEN_OR_per_SSAbldg',
        'GEN_Yellow_per_LSbl',
        'TOP_mean_slope',
        'TOP_mean_elevation_m', 
        'TOP_ruggedness_stdev', 
        'TOP_mean_ruggedness',
        'TOP_slope_stdev', 
        'VUL_poverty_perc',
        'GEN_with_coast',
        'GEN_coast_length', 
        'VUL_Housing_Units',
        'VUL_StrongRoof_StrongWall', 
        'VUL_StrongRoof_LightWall',
        'VUL_StrongRoof_SalvageWall', 
        'VUL_LightRoof_StrongWall',
        'VUL_LightRoof_LightWall', 
        'VUL_LightRoof_SalvageWall',
        'VUL_SalvagedRoof_StrongWall',
        'VUL_SalvagedRoof_LightWall',
        'VUL_SalvagedRoof_SalvageWall', 
        'VUL_vulnerable_groups',
        'VUL_pantawid_pamilya_beneficiary', 
        'DAM_perc_dmg'])


features_name = combined_input_data.columns
#display(features_name)

features =['HAZ_rainfall_Total', 
        'HAZ_rainfall_max_6h',
        'HAZ_rainfall_max_24h',
        'HAZ_v_max',
        'HAZ_v_max_3',
        'HAZ_dis_track_min',
        'GEN_landslide_per',
        'GEN_stormsurge_per',
        'GEN_Bu_p_inSSA', 
        'GEN_Bu_p_LS', 
        'GEN_Red_per_LSbldg',
        'GEN_Or_per_LSblg', 
        'GEN_Yel_per_LSSAb', 
        'GEN_RED_per_SSAbldg',
        'GEN_OR_per_SSAbldg',
        'GEN_Yellow_per_LSbl',
        'TOP_mean_slope',
        'TOP_mean_elevation_m', 
        'TOP_ruggedness_stdev', 
        'TOP_mean_ruggedness',
        'TOP_slope_stdev', 
        'VUL_poverty_perc',
        'GEN_with_coast',
        'GEN_coast_length', 
        'VUL_Housing_Units',
        'VUL_StrongRoof_StrongWall', 
        'VUL_StrongRoof_LightWall',
        'VUL_StrongRoof_SalvageWall', 
        'VUL_LightRoof_StrongWall',
        'VUL_LightRoof_LightWall', 
        'VUL_LightRoof_SalvageWall',
        'VUL_SalvagedRoof_StrongWall',
        'VUL_SalvagedRoof_LightWall',
        'VUL_SalvagedRoof_SalvageWall', 
        'VUL_vulnerable_groups',
        'VUL_pantawid_pamilya_beneficiary']


df=combined_input_data.dropna()
display(df)


```

```python
#Define bins
#bins2= [0, 1, 60, 101]   #Old bins
bins2 = [0, 0.00009, 1, 10, 50, 101]    #New bins
samples_per_bin2, binsP2 = np.histogram(df['DAM_perc_dmg'], bins=bins2)
plt.xlabel("Damage Values")
plt.ylabel("Frequency")
plt.plot(binsP2[1:],samples_per_bin2)

print(samples_per_bin2)
print(binsP2)

```

###The data (except target) needs to be standardize

```python
#Separate target from all other data
#df_scaled = df
#df_scaled

#Separate typhoon from other features
dfs = np.split(df, [1], axis=1)
dfa = np.split(dfs[1], [36], axis=1)
#print(dfs[0], dfs[1], dfa[0], dfa[1])

#Standardaize data 
scaler = preprocessing.StandardScaler().fit(dfa[0])
X1 = scaler.transform(dfa[0])
Xnew = pd.DataFrame(X1)
display(Xnew)


```

```python
dfa[1] = dfa[1].astype(float)
```

```python
Xnew = pd.concat([Xnew.reset_index(drop=True), dfa[1].reset_index(drop=True)], axis=1)
Xnew
```

```python
i=0
for feature in features:
    Xnew = Xnew.rename(columns={i: feature})
    i+=1
    
Xnew = pd.concat([dfs[0].reset_index(drop=True),Xnew.reset_index(drop=True)], axis=1)
#Xnew
```

```python
typhoons_lst = Xnew.typhoon.unique()
tls=typhoons_lst.tolist()
```

```python
df_typhoon=pd.DataFrame(columns = ['typhoon', 'year'])

for i in range(len(tls)):
    df_typhoon.at[i,'typhoon']=tls[i]
    df_typhoon.at[i,'year'] = int(tls[i][-4:])
    
df_typhoon_sort = df_typhoon.sort_values('year')
df_typhoon_sort=df_typhoon_sort.reset_index(drop=True)
df_typhoon_sort
```

```python
#Define an empty list to append the estimated rmse to the list
rmse_test_list=[]

#Define an empty list to append the selected typhoons to the list
test_list = []

#Define 5 empty lists to append the estimated rmse for each bin to the each list
rmse_list_1=[]
rmse_list_2=[]
rmse_list_3=[]
rmse_list_4=[]
rmse_list_5=[]
```

####Check the mean value of each group of typhoon to figure out most severe typhoons.

```python
i_list=[38, 37, 36, 35, 34, 33, 32, 31]
for i in range(len(i_list)):
    test_list.append(df_typhoon_sort.iloc[i_list[i], 0])

print(test_list)
```

```python
#Reorder test_list according to typhoons'dates from months in 2019 to last one in November 2020 

test_list=['nakri2019', 'kammuri2019', 'phanfone2019', 'vongfong2020', 'saudel2020', 'molave2020', 'goni2020', 'vamco2020']

```

```python
ltl=len(test_list)
ltl
```

```python
#df_test=pd.DataFrame(Xnew, columns = ['typhoon','HAZ_rainfall_Total',
df_test=pd.DataFrame(columns = ['typhoon','HAZ_rainfall_Total',
                                      'HAZ_rainfall_max_6h',
                                      'HAZ_rainfall_max_24h',
                                      'HAZ_v_max',
                                      'HAZ_v_max_3',
                                      'HAZ_dis_track_min',
                                      'GEN_landslide_per',
                                      'GEN_stormsurge_per',
                                      'GEN_Bu_p_inSSA', 
                                      'GEN_Bu_p_LS', 
                                      'GEN_Red_per_LSbldg',
                                      'GEN_Or_per_LSblg', 
                                      'GEN_Yel_per_LSSAb', 
                                      'GEN_RED_per_SSAbldg',
                                      'GEN_OR_per_SSAbldg',
                                      'GEN_Yellow_per_LSbl',
                                      'TOP_mean_slope',
                                      'TOP_mean_elevation_m', 
                                      'TOP_ruggedness_stdev', 
                                      'TOP_mean_ruggedness',
                                      'TOP_slope_stdev', 
                                      'VUL_poverty_perc',
                                      'GEN_with_coast',
                                      'GEN_coast_length', 
                                      'VUL_Housing_Units',
                                      'VUL_StrongRoof_StrongWall', 
                                      'VUL_StrongRoof_LightWall',
                                      'VUL_StrongRoof_SalvageWall', 
                                      'VUL_LightRoof_StrongWall',
                                      'VUL_LightRoof_LightWall', 
                                      'VUL_LightRoof_SalvageWall',
                                      'VUL_SalvagedRoof_StrongWall',
                                      'VUL_SalvagedRoof_LightWall',
                                      'VUL_SalvagedRoof_SalvageWall', 
                                      'VUL_vulnerable_groups',
                                      'VUL_pantawid_pamilya_beneficiary', 
                                      'DAM_perc_dmg']) 
#df_test
```

In the following cell the RMSE is calculated for different test set and added to a list for plotting.

```python
while ltl!=0:

    if ltl==8:   
        df_test = Xnew[Xnew['typhoon'] == test_list[7]]
        df_test=df_test.append(Xnew[Xnew['typhoon'] == test_list[6]])
        df_test=df_test.append(Xnew[Xnew['typhoon'] == test_list[5]])
        df_test=df_test.append(Xnew[Xnew['typhoon'] == test_list[4]])
        df_test=df_test.append(Xnew[Xnew['typhoon'] == test_list[3]])
        df_test=df_test.append(Xnew[Xnew['typhoon'] == test_list[2]])
        df_test=df_test.append(Xnew[Xnew['typhoon'] == test_list[1]])
        df_test=df_test.append(Xnew[Xnew['typhoon'] == test_list[0]])

        Xnew.drop(Xnew.index[Xnew['typhoon'] == test_list[7]], inplace=True)
        Xnew.drop(Xnew.index[Xnew['typhoon'] == test_list[6]], inplace=True)
        Xnew.drop(Xnew.index[Xnew['typhoon'] == test_list[5]], inplace=True)
        Xnew.drop(Xnew.index[Xnew['typhoon'] == test_list[4]], inplace=True)
        Xnew.drop(Xnew.index[Xnew['typhoon'] == test_list[3]], inplace=True)
        Xnew.drop(Xnew.index[Xnew['typhoon'] == test_list[2]], inplace=True)
        Xnew.drop(Xnew.index[Xnew['typhoon'] == test_list[1]], inplace=True)
        Xnew.drop(Xnew.index[Xnew['typhoon'] == test_list[0]], inplace=True)   

        display(df_test)    
        df_train=Xnew
        display(df_train)


    elif ltl < 8:

            if ltl==7:
                num=0

            elif ltl==6:
                num=1

            elif ltl==5:
                num=2

            elif ltl==4:
                num=3

            elif ltl==3:
                num=4

            elif ltl==2:
                num=5

            elif ltl==1:
                num=6

            df_train=df_train.append(df_test[df_test['typhoon'] == test_list[num]])
            df_test.drop(df_test.index[df_test['typhoon'] == test_list[num]], inplace=True)



            display(df_test)
            display(df_train)


    # Split X and y from dataframe features
    X_test = df_test[features]
    X_train = df_train[features]

    y_train = df_train["DAM_perc_dmg"]
    y_test = df_test["DAM_perc_dmg"]

    bin_index_test=np.digitize(y_test, bins=binsP2)
    bin_index_train=np.digitize(y_train, bins=binsP2)


    #XGBoost

    xgb = XGBRegressor(n_estimators=100, max_depth=4, learning_rate=0.1, gamma=1, reg_lambda=0.1, colsample_bytree=0.8)
    xgb_model=xgb.fit(X_train, y_train)

    #XGBoost_ReducedOverfitting
    #xgb = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.8,
    #                   colsample_bynode=0.8, colsample_bytree=0.8, gamma=3, eta=0.01,
    #                   importance_type='gain', learning_rate=0.1, max_delta_step=0,
    #                   max_depth=4, min_child_weight=1, missing=1, n_estimators=100, early_stopping_rounds=10,
    #                   n_jobs=1, nthread=None, objective='reg:squarederror', 
    #                   reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
    #                   silent=None, subsample=0.8, verbosity=1, eval_metric=["rmse", "logloss"],
    #                   #random_state=0,
    #                  )


    #eval_set = [(X_test, y_test)]
    #xgb_model=xgb.fit(X_train, y_train, eval_set=eval_set, verbose=False)



    #RMSE Estimation for each bins
    y_pred_train = xgb.predict(X_train)

    mse_train_idx1 = mean_squared_error(y_train[bin_index_train==1], y_pred_train[bin_index_train==1])
    rmse_train_1 = np.sqrt(mse_train_idx1)
    mse_train_idx2 = mean_squared_error(y_train[bin_index_train==2], y_pred_train[bin_index_train==2])
    rmse_train_2 = np.sqrt(mse_train_idx2)
    mse_train_idx3 = mean_squared_error(y_train[bin_index_train==3], y_pred_train[bin_index_train==3])
    rmse_train_3 = np.sqrt(mse_train_idx3)
    mse_train_idx4 = mean_squared_error(y_train[bin_index_train==4], y_pred_train[bin_index_train==4])
    rmse_train_4 = np.sqrt(mse_train_idx4)
    mse_train_idx5 = mean_squared_error(y_train[bin_index_train==5], y_pred_train[bin_index_train==5])
    rmse_train_5 = np.sqrt(mse_train_idx5)


    print('----- Training_bins_RMSE  ------')
    print(f'Root mean squared error of bins_1: {rmse_train_1:.2f}')
    print(f'Root mean squared error of bins_2: {rmse_train_2:.2f}')
    print(f'Root mean squared error of bins_3: {rmse_train_3:.2f}')
    print(f'Root mean squared error of bins_4: {rmse_train_4:.2f}')
    print(f'Root mean squared error of bins_5: {rmse_train_5:.2f}')


    y_pred = xgb.predict(X_test)

    mse_idx1 = mean_squared_error(y_test[bin_index_test==1], y_pred[bin_index_test==1])
    rmse_1 = np.sqrt(mse_idx1)

    if len(y_test[bin_index_test==2])==0:
        rmse_2=-1
    else:
        mse_idx2 = mean_squared_error(y_test[bin_index_test==2], y_pred[bin_index_test==2])
        rmse_2 = np.sqrt(mse_idx2)

    if len(y_test[bin_index_test==3])==0:
        rmse_3=-1
    else:
        mse_idx3 = mean_squared_error(y_test[bin_index_test==3], y_pred[bin_index_test==3])
        rmse_3 = np.sqrt(mse_idx3)

    if len(y_test[bin_index_test==4])==0:
        rmse_4=-1
    else:
        mse_idx4 = mean_squared_error(y_test[bin_index_test==4], y_pred[bin_index_test==4])
        rmse_4 = np.sqrt(mse_idx4)

    if len(y_test[bin_index_test==5])==0:
        rmse_5=-1
    else:
        mse_idx5 = mean_squared_error(y_test[bin_index_test==5], y_pred[bin_index_test==5])
        rmse_5 = np.sqrt(mse_idx5)


    print('----- Test_bins_RMSE  ------')
    print(f'Root mean squared error of bins_1: {rmse_1:.2f}')
    print(f'Root mean squared error of bins_2: {rmse_2:.2f}')
    print(f'Root mean squared error of bins_3: {rmse_3:.2f}')
    print(f'Root mean squared error of bins_4: {rmse_4:.2f}')
    print(f'Root mean squared error of bins_5: {rmse_5:.2f}')

    rmse_list_1.append(rmse_1)
    rmse_list_2.append(rmse_2)
    rmse_list_3.append(rmse_3)
    rmse_list_4.append(rmse_4)
    rmse_list_5.append(rmse_5)


    #Different Error Estimation
    y_pred_train = xgb.predict(X_train)
    mae_train = mean_absolute_error(y_train, y_pred_train)
    mse_train = mean_squared_error(y_train, y_pred_train)
    rmse_train = np.sqrt(mse_train)
    mx_train = max_error(y_train, y_pred_train)
    me_train = (y_pred_train - y_train).sum()/len(y_train)

    y_pred = xgb.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mx = max_error(y_test, y_pred)
    me = (y_pred - y_test).sum()/len(y_test)

    print('----- Test  ------')
    print(f'Mean absolute error: {mae:.2f}')
    print(f'Mean squared error: {mse:.2f}')
    print(f'Root mean squared error: {rmse:.2f}')
    print(f'Max error: {mx:.2f}')
    print(f"Average Error: {me:.2f}")

    print('---- Training -----')
    print(f'Mean absolute error: {mae_train:.2f}')
    print(f'Mean squared error: {mse_train:.2f}')
    print(f'Root mean squared error: {rmse_train:.2f}')
    print(f'Max error: {mx_train:.2f}')
    print(f"Average Error: {me_train:.2f}")


    score = xgb.score(X_train, y_train)  
    print("Training score coefficient of determination for the model R^2: %.3f " % (score))

    rmse_test_list.append(rmse)

    #ltl means len(test_list)
    ltl=ltl-1
    ltl



rmse_test_list
```

```python
#Plot of RMSE estimation according to 8 different test sets

import matplotlib.pyplot as plt
import numpy as np

x = ['nakri2019', 'kammuri2019', 'phanfone2019', 'vongfong2020', 'saudel2020', 'molave2020', 'goni2020', 'vamco2020']
y = rmse_test_list

plt.scatter(x, y, cmap='viridis')

#obtain m (slope) and b(intercept) of linear regression line
#m, b = np.polyfit(x, y, 1)
plt.plot(x, y, color='orange')


plt.xlabel("Typhoon's Date", fontsize=10)
plt.ylabel('RMSE_Test', fontsize=10)
plt.title("Typhoon's Date vs Performance Measure")

np.rot90(plt.xticks(rotation=70, fontsize=12))
plt.yticks(np.arange(2.5,5.0,step=0.25))
plt.show()
```

Plots Per bins

```python
import matplotlib.pyplot as plt
import numpy as np

#Plot RMSE estimation of bin_1 based on 8 different test sets    
x = ['nakri2019', 'kammuri2019', 'phanfone2019', 'vongfong2020', 'saudel2020', 'molave2020', 'goni2020', 'vamco2020']
y = rmse_list_1

plt.scatter(x, y, cmap='viridis')
plt.plot(x, y, color='r')

plt.xlabel("Typhoon's Date", fontsize=10)
plt.ylabel('RMSE_Test', fontsize=10)
plt.title("Typhoon's Date vs Performance Measure")

np.rot90(plt.xticks(rotation=70, fontsize=12))
plt.yticks(np.arange(0.0,1.0,step=0.25))
plt.show()


#Plot RMSE estimation of bin_2 based on 8 different test sets  
x = ['nakri2019', 'kammuri2019', 'phanfone2019', 'vongfong2020', 'saudel2020', 'molave2020', 'goni2020', 'vamco2020']
y = rmse_list_2

plt.scatter(x, y, cmap='viridis')
plt.plot(x, y, color='r')

plt.xlabel("Typhoon's Date", fontsize=10)
plt.ylabel('RMSE_Test', fontsize=10)
plt.title("Typhoon's Date vs Performance Measure-bin2:(0,1]")

np.rot90(plt.xticks(rotation=70, fontsize=12))
#plt.yticks(np.arange(0.0,1.0,step=0.25))
plt.show()


#Plot RMSE estimation of bin_3 based on 8 different test sets    
x = ['nakri2019', 'kammuri2019', 'phanfone2019', 'vongfong2020', 'saudel2020', 'molave2020', 'goni2020', 'vamco2020']
y = rmse_list_3

plt.scatter(x, y, cmap='viridis')
plt.plot(x, y, color='r')

plt.xlabel("Typhoon's Date", fontsize=10)
plt.ylabel('RMSE_Test', fontsize=10)
plt.title("Typhoon's Date vs Performance Measure-bin3:(1,10]")

np.rot90(plt.xticks(rotation=70, fontsize=12))
#plt.yticks(np.arange(0.0,1.0,step=0.25))
plt.show()


#Plot RMSE estimation of bin_4 based on 8 different test sets    
x = ['nakri2019', 'kammuri2019', 'phanfone2019', 'vongfong2020', 'saudel2020', 'molave2020', 'goni2020', 'vamco2020']
y = rmse_list_4

plt.scatter(x, y, cmap='viridis')
plt.plot(x, y, color='r')

plt.xlabel("Typhoon's Date", fontsize=10)
plt.ylabel('RMSE_Test', fontsize=10)
plt.title("Typhoon's Date vs Performance Measure bin_4:(10,50]")

np.rot90(plt.xticks(rotation=70, fontsize=12))
plt.yticks(np.arange(12.5,14.75,step=0.5))
plt.show()


#Plot RMSE estimation of bin_5 based on 8 different test sets
x = ['nakri2019', 'kammuri2019', 'phanfone2019', 'vongfong2020', 'saudel2020', 'molave2020', 'goni2020', 'vamco2020']
y = rmse_list_5


index = [i for i,j in enumerate(y) if j == -1]
for i in range(len(index)):
    a=index[0]
    typhoon_name = x[a]
    x.remove(typhoon_name)
    y.remove(-1)

plt.scatter(x, y, cmap='viridis')
plt.plot(x, y, color='r')

plt.xlabel("Typhoon's Date", fontsize=10)
plt.ylabel('RMSE_Test', fontsize=10)
plt.title("Typhoon's Date vs Performance Measure bin_5:(50,100]")

np.rot90(plt.xticks(rotation=70, fontsize=12))
#plt.yticks(np.arange(46,59,step=1))
plt.show()
```

```python
"""
Due to the fact that the calculated RMSE for the first three bins are more or less in the same range so we plot them
in one figure.
Plot RMSE estimation of bin(1 & 2 & 3) based on 8 different test sets
"""

x = ['nakri2019', 'kammuri2019', 'phanfone2019', 'vongfong2020', 'saudel2020', 'molave2020', 'goni2020', 'vamco2020']
y = rmse_list_1
y2 = rmse_list_2
y3 = rmse_list_3


plt.plot(x, y, 'g', label='Line y1')
plt.plot(x, y2, 'r', label='Line y2')
plt.plot(x, y3, 'b', label='Line y3')

plt.scatter(x, y, cmap='viridis')
plt.scatter(x, y2, cmap='viridis')
plt.scatter(x, y3, cmap='viridis')


#create legend
labels= ["bin1","bin2","bin3"]
plt.legend(labels)


plt.xlabel("Typhoon's Date", fontsize=10)
plt.ylabel('RMSE_Test', fontsize=10)
plt.title("Typhoon's Date vs Performance Measure bin_1:[0], bin_2:(0,1], bin_3:(1,10]")

np.rot90(plt.xticks(rotation=70, fontsize=12))
plt.yticks(np.arange(0.0,7.0,step=0.5))
plt.show()
```

```python

```
