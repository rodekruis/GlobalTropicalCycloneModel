{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbc99885",
   "metadata": {},
   "source": [
    "Implementing XGBoost Regression model\n",
    "\n",
    "Estimate and plot different error metrics (RMSE, MSE, MAE, Average Error) in a 20 runs of a XGBoost Regression model. ***Each runs has a different 20/80 test training split, and with the stratified data.***\n",
    "The point is that the estimation could be done for two different set of bins and for mode with and without overfitting reduction. So, this makes possibility to check the difference in estimated errors according to different set of bins and also to have comparison between reducedoverfitting model and overfitting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e7a73ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>typhoon</th>\n",
       "      <th>HAZ_rainfall_Total</th>\n",
       "      <th>HAZ_rainfall_max_6h</th>\n",
       "      <th>HAZ_rainfall_max_24h</th>\n",
       "      <th>HAZ_v_max</th>\n",
       "      <th>HAZ_v_max_3</th>\n",
       "      <th>HAZ_dis_track_min</th>\n",
       "      <th>GEN_landslide_per</th>\n",
       "      <th>GEN_stormsurge_per</th>\n",
       "      <th>GEN_Bu_p_inSSA</th>\n",
       "      <th>...</th>\n",
       "      <th>VUL_StrongRoof_SalvageWall</th>\n",
       "      <th>VUL_LightRoof_StrongWall</th>\n",
       "      <th>VUL_LightRoof_LightWall</th>\n",
       "      <th>VUL_LightRoof_SalvageWall</th>\n",
       "      <th>VUL_SalvagedRoof_StrongWall</th>\n",
       "      <th>VUL_SalvagedRoof_LightWall</th>\n",
       "      <th>VUL_SalvagedRoof_SalvageWall</th>\n",
       "      <th>VUL_vulnerable_groups</th>\n",
       "      <th>VUL_pantawid_pamilya_beneficiary</th>\n",
       "      <th>DAM_perc_dmg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>durian2006</td>\n",
       "      <td>185.828571</td>\n",
       "      <td>14.716071</td>\n",
       "      <td>7.381696</td>\n",
       "      <td>55.032241</td>\n",
       "      <td>166667.757548</td>\n",
       "      <td>2.478142</td>\n",
       "      <td>2.64</td>\n",
       "      <td>6.18</td>\n",
       "      <td>6.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097425</td>\n",
       "      <td>2.533055</td>\n",
       "      <td>41.892832</td>\n",
       "      <td>1.002088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027836</td>\n",
       "      <td>0.083507</td>\n",
       "      <td>2.951511</td>\n",
       "      <td>46.931106</td>\n",
       "      <td>3.632568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>durian2006</td>\n",
       "      <td>8.818750</td>\n",
       "      <td>0.455208</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>8.728380</td>\n",
       "      <td>664.968323</td>\n",
       "      <td>288.358553</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850008</td>\n",
       "      <td>1.218595</td>\n",
       "      <td>13.645253</td>\n",
       "      <td>0.549120</td>\n",
       "      <td>0.030089</td>\n",
       "      <td>0.090266</td>\n",
       "      <td>0.112833</td>\n",
       "      <td>3.338873</td>\n",
       "      <td>25.989168</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>durian2006</td>\n",
       "      <td>24.175000</td>\n",
       "      <td>2.408333</td>\n",
       "      <td>0.957639</td>\n",
       "      <td>10.945624</td>\n",
       "      <td>1311.358762</td>\n",
       "      <td>274.953818</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197179</td>\n",
       "      <td>0.667374</td>\n",
       "      <td>15.592295</td>\n",
       "      <td>0.075838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015168</td>\n",
       "      <td>0.075838</td>\n",
       "      <td>2.131755</td>\n",
       "      <td>32.185651</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>durian2006</td>\n",
       "      <td>14.930000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>0.586250</td>\n",
       "      <td>12.108701</td>\n",
       "      <td>1775.385328</td>\n",
       "      <td>252.828578</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279362</td>\n",
       "      <td>0.675125</td>\n",
       "      <td>7.100454</td>\n",
       "      <td>0.023280</td>\n",
       "      <td>0.011640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128041</td>\n",
       "      <td>1.589369</td>\n",
       "      <td>29.612385</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>durian2006</td>\n",
       "      <td>13.550000</td>\n",
       "      <td>1.054167</td>\n",
       "      <td>0.528125</td>\n",
       "      <td>10.660943</td>\n",
       "      <td>1211.676901</td>\n",
       "      <td>258.194381</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065703</td>\n",
       "      <td>0.821288</td>\n",
       "      <td>30.354796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.387007</td>\n",
       "      <td>35.052562</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25835</th>\n",
       "      <td>noul2015</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.216146</td>\n",
       "      <td>8.136932</td>\n",
       "      <td>538.743551</td>\n",
       "      <td>277.107823</td>\n",
       "      <td>1.80</td>\n",
       "      <td>6.25</td>\n",
       "      <td>6.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186916</td>\n",
       "      <td>3.613707</td>\n",
       "      <td>32.492212</td>\n",
       "      <td>0.311526</td>\n",
       "      <td>0.031153</td>\n",
       "      <td>0.155763</td>\n",
       "      <td>0.031153</td>\n",
       "      <td>2.827833</td>\n",
       "      <td>31.308411</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25837</th>\n",
       "      <td>noul2015</td>\n",
       "      <td>17.587500</td>\n",
       "      <td>1.414583</td>\n",
       "      <td>0.386458</td>\n",
       "      <td>9.818999</td>\n",
       "      <td>946.676507</td>\n",
       "      <td>305.789817</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209059</td>\n",
       "      <td>0.383275</td>\n",
       "      <td>4.703833</td>\n",
       "      <td>0.027875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034843</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>1.073268</td>\n",
       "      <td>12.766551</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25838</th>\n",
       "      <td>noul2015</td>\n",
       "      <td>11.487500</td>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.230319</td>\n",
       "      <td>15.791907</td>\n",
       "      <td>3938.254316</td>\n",
       "      <td>210.313249</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202748</td>\n",
       "      <td>0.090110</td>\n",
       "      <td>3.063753</td>\n",
       "      <td>0.022528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067583</td>\n",
       "      <td>0.022528</td>\n",
       "      <td>1.140109</td>\n",
       "      <td>9.348952</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25839</th>\n",
       "      <td>noul2015</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.412766</td>\n",
       "      <td>13.867145</td>\n",
       "      <td>2666.620370</td>\n",
       "      <td>218.189328</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094518</td>\n",
       "      <td>3.119093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.837537</td>\n",
       "      <td>21.928166</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25841</th>\n",
       "      <td>noul2015</td>\n",
       "      <td>32.305556</td>\n",
       "      <td>1.744444</td>\n",
       "      <td>1.210417</td>\n",
       "      <td>15.647639</td>\n",
       "      <td>3831.302757</td>\n",
       "      <td>219.542224</td>\n",
       "      <td>4.15</td>\n",
       "      <td>3.05</td>\n",
       "      <td>3.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031146</td>\n",
       "      <td>12.198920</td>\n",
       "      <td>36.191860</td>\n",
       "      <td>0.280316</td>\n",
       "      <td>0.010382</td>\n",
       "      <td>0.031146</td>\n",
       "      <td>0.103821</td>\n",
       "      <td>2.518110</td>\n",
       "      <td>31.634136</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8073 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          typhoon  HAZ_rainfall_Total  HAZ_rainfall_max_6h  \\\n",
       "0      durian2006          185.828571            14.716071   \n",
       "2      durian2006            8.818750             0.455208   \n",
       "4      durian2006           24.175000             2.408333   \n",
       "6      durian2006           14.930000             1.650000   \n",
       "7      durian2006           13.550000             1.054167   \n",
       "...           ...                 ...                  ...   \n",
       "25835    noul2015            9.700000             0.408333   \n",
       "25837    noul2015           17.587500             1.414583   \n",
       "25838    noul2015           11.487500             0.614583   \n",
       "25839    noul2015           11.600000             1.400000   \n",
       "25841    noul2015           32.305556             1.744444   \n",
       "\n",
       "       HAZ_rainfall_max_24h  HAZ_v_max    HAZ_v_max_3  HAZ_dis_track_min  \\\n",
       "0                  7.381696  55.032241  166667.757548           2.478142   \n",
       "2                  0.255319   8.728380     664.968323         288.358553   \n",
       "4                  0.957639  10.945624    1311.358762         274.953818   \n",
       "6                  0.586250  12.108701    1775.385328         252.828578   \n",
       "7                  0.528125  10.660943    1211.676901         258.194381   \n",
       "...                     ...        ...            ...                ...   \n",
       "25835              0.216146   8.136932     538.743551         277.107823   \n",
       "25837              0.386458   9.818999     946.676507         305.789817   \n",
       "25838              0.230319  15.791907    3938.254316         210.313249   \n",
       "25839              0.412766  13.867145    2666.620370         218.189328   \n",
       "25841              1.210417  15.647639    3831.302757         219.542224   \n",
       "\n",
       "       GEN_landslide_per  GEN_stormsurge_per  GEN_Bu_p_inSSA  ...  \\\n",
       "0                   2.64                6.18            6.18  ...   \n",
       "2                   0.06                0.00            0.00  ...   \n",
       "4                   1.52                1.28            1.28  ...   \n",
       "6                   0.00                0.00            0.00  ...   \n",
       "7                   5.52                0.36            0.36  ...   \n",
       "...                  ...                 ...             ...  ...   \n",
       "25835               1.80                6.25            6.25  ...   \n",
       "25837               0.00                0.00            0.00  ...   \n",
       "25838               0.06                0.09            0.09  ...   \n",
       "25839               0.00                0.00            0.00  ...   \n",
       "25841               4.15                3.05            3.05  ...   \n",
       "\n",
       "       VUL_StrongRoof_SalvageWall  VUL_LightRoof_StrongWall  \\\n",
       "0                        0.097425                  2.533055   \n",
       "2                        0.850008                  1.218595   \n",
       "4                        0.197179                  0.667374   \n",
       "6                        0.279362                  0.675125   \n",
       "7                        0.065703                  0.821288   \n",
       "...                           ...                       ...   \n",
       "25835                    0.186916                  3.613707   \n",
       "25837                    0.209059                  0.383275   \n",
       "25838                    0.202748                  0.090110   \n",
       "25839                    0.000000                  0.094518   \n",
       "25841                    0.031146                 12.198920   \n",
       "\n",
       "       VUL_LightRoof_LightWall  VUL_LightRoof_SalvageWall  \\\n",
       "0                    41.892832                   1.002088   \n",
       "2                    13.645253                   0.549120   \n",
       "4                    15.592295                   0.075838   \n",
       "6                     7.100454                   0.023280   \n",
       "7                    30.354796                   0.000000   \n",
       "...                        ...                        ...   \n",
       "25835                32.492212                   0.311526   \n",
       "25837                 4.703833                   0.027875   \n",
       "25838                 3.063753                   0.022528   \n",
       "25839                 3.119093                   0.000000   \n",
       "25841                36.191860                   0.280316   \n",
       "\n",
       "       VUL_SalvagedRoof_StrongWall  VUL_SalvagedRoof_LightWall  \\\n",
       "0                         0.000000                    0.027836   \n",
       "2                         0.030089                    0.090266   \n",
       "4                         0.000000                    0.015168   \n",
       "6                         0.011640                    0.000000   \n",
       "7                         0.000000                    0.032852   \n",
       "...                            ...                         ...   \n",
       "25835                     0.031153                    0.155763   \n",
       "25837                     0.000000                    0.034843   \n",
       "25838                     0.000000                    0.067583   \n",
       "25839                     0.000000                    0.000000   \n",
       "25841                     0.010382                    0.031146   \n",
       "\n",
       "       VUL_SalvagedRoof_SalvageWall  VUL_vulnerable_groups  \\\n",
       "0                          0.083507               2.951511   \n",
       "2                          0.112833               3.338873   \n",
       "4                          0.075838               2.131755   \n",
       "6                          0.128041               1.589369   \n",
       "7                          0.000000               1.387007   \n",
       "...                             ...                    ...   \n",
       "25835                      0.031153               2.827833   \n",
       "25837                      0.097561               1.073268   \n",
       "25838                      0.022528               1.140109   \n",
       "25839                      0.000000               2.837537   \n",
       "25841                      0.103821               2.518110   \n",
       "\n",
       "       VUL_pantawid_pamilya_beneficiary  DAM_perc_dmg  \n",
       "0                             46.931106      3.632568  \n",
       "2                             25.989168      0.000000  \n",
       "4                             32.185651      0.000000  \n",
       "6                             29.612385      0.000000  \n",
       "7                             35.052562      0.000000  \n",
       "...                                 ...           ...  \n",
       "25835                         31.308411      0.000000  \n",
       "25837                         12.766551      0.000000  \n",
       "25838                          9.348952      0.000000  \n",
       "25839                         21.928166      0.000000  \n",
       "25841                         31.634136      0.000000  \n",
       "\n",
       "[8073 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, max_error\n",
    "\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wor_dir=\"/home/mforooshani/Typhoon-Impact-based-forecasting-model-training-5:7/IBF-Typhoon-model/\"\n",
    "os.chdir(wor_dir)\n",
    "cdir = os.getcwd()\n",
    "\n",
    "combined_input_data=pd.read_csv(\"Training-data-new/data/model_input/combined_input_data.csv\")\n",
    "\n",
    "typhoons_with_impact_data=['bopha2012', 'conson2010', 'durian2006', 'fengshen2008',\n",
    "       'fung-wong2014', 'goni2015', 'goni2020', 'hagupit2014',\n",
    "       'haima2016', 'haiyan2013', 'jangmi2014', 'kalmaegi2014',\n",
    "       'kammuri2019', 'ketsana2009', 'koppu2015', 'krosa2013',\n",
    "       'linfa2015', 'lingling2014', 'mangkhut2018', 'mekkhala2015',\n",
    "       'melor2015', 'meranti2016', 'molave2020', 'mujigae2015',\n",
    "       'nakri2019', 'nari2013', 'nesat2011', 'nock-ten2016', 'noul2015',\n",
    "       'phanfone2019', 'rammasun2014', 'sarika2016', 'saudel2020',\n",
    "       'tokage2016', 'trami2013', 'usagi2013', 'utor2013', 'vamco2020',\n",
    "       'vongfong2020', 'yutu2018']\n",
    "\n",
    "len(np.unique(combined_input_data.typhoon))\n",
    "combined_input_data=combined_input_data[combined_input_data.typhoon.isin(typhoons_with_impact_data)]\n",
    "#display(combined_input_data)\n",
    "\n",
    "def set_zeros(x):\n",
    "    x_max = 25\n",
    "    y_max = 50\n",
    "    \n",
    "    v_max = x[0]\n",
    "    rainfall_max = x[1]\n",
    "    damage = x[2]\n",
    "    if pd.notnull(damage):\n",
    "        value = damage\n",
    "    elif v_max > x_max or rainfall_max > y_max:\n",
    "        value =damage\n",
    "    elif (v_max < np.sqrt((1- (rainfall_max**2/y_max ** 2))*x_max ** 2)):\n",
    "        value = 0\n",
    "    else:\n",
    "        value = np.nan\n",
    "\n",
    "    return value\n",
    "combined_input_data[\"DAM_perc_dmg\"] = combined_input_data[[\"HAZ_v_max\", \"HAZ_rainfall_Total\", \"DAM_perc_dmg\"]].apply(set_zeros, axis=\"columns\")\n",
    "\n",
    "\n",
    "np.mean(combined_input_data[\"DAM_perc_dmg\"])\n",
    "combined_input_data = combined_input_data[combined_input_data['DAM_perc_dmg'].notnull()]\n",
    "np.mean(combined_input_data[\"DAM_perc_dmg\"])\n",
    "np.unique(combined_input_data.typhoon)\n",
    "\n",
    "def cubeic(x):\n",
    "    #x=float(x)\n",
    "    value=x*x*x\n",
    "    return value\n",
    "\n",
    "combined_input_data['HAZ_v_max_3']=combined_input_data['HAZ_v_max'].apply(lambda x: x*x*x) \n",
    "#display(combined_input_data)\n",
    "#combined_input_data.hist(column=\"DAM_perc_dmg\") \n",
    "\n",
    "combined_input_data =combined_input_data.filter(['typhoon','HAZ_rainfall_Total', \n",
    "        'HAZ_rainfall_max_6h',\n",
    "        'HAZ_rainfall_max_24h',\n",
    "        'HAZ_v_max',\n",
    "        'HAZ_v_max_3',\n",
    "        'HAZ_dis_track_min',\n",
    "        'GEN_landslide_per',\n",
    "        'GEN_stormsurge_per',\n",
    "        'GEN_Bu_p_inSSA', \n",
    "        'GEN_Bu_p_LS', \n",
    "        'GEN_Red_per_LSbldg',\n",
    "        'GEN_Or_per_LSblg', \n",
    "        'GEN_Yel_per_LSSAb', \n",
    "        'GEN_RED_per_SSAbldg',\n",
    "        'GEN_OR_per_SSAbldg',\n",
    "        'GEN_Yellow_per_LSbl',\n",
    "        'TOP_mean_slope',\n",
    "        'TOP_mean_elevation_m', \n",
    "        'TOP_ruggedness_stdev', \n",
    "        'TOP_mean_ruggedness',\n",
    "        'TOP_slope_stdev', \n",
    "        'VUL_poverty_perc',\n",
    "        'GEN_with_coast',\n",
    "        'GEN_coast_length', \n",
    "        'VUL_Housing_Units',\n",
    "        'VUL_StrongRoof_StrongWall', \n",
    "        'VUL_StrongRoof_LightWall',\n",
    "        'VUL_StrongRoof_SalvageWall', \n",
    "        'VUL_LightRoof_StrongWall',\n",
    "        'VUL_LightRoof_LightWall', \n",
    "        'VUL_LightRoof_SalvageWall',\n",
    "        'VUL_SalvagedRoof_StrongWall',\n",
    "        'VUL_SalvagedRoof_LightWall',\n",
    "        'VUL_SalvagedRoof_SalvageWall', \n",
    "        'VUL_vulnerable_groups',\n",
    "        'VUL_pantawid_pamilya_beneficiary', \n",
    "        'DAM_perc_dmg'])\n",
    "\n",
    "\n",
    "features_name = combined_input_data.columns\n",
    "#display(features_name)\n",
    "\n",
    "#Dropping highly correlated features which their correlation values are greater than 0.99.\n",
    "features =['HAZ_rainfall_Total', \n",
    "           'HAZ_rainfall_max_6h',\n",
    "           'HAZ_rainfall_max_24h',\n",
    "           'HAZ_v_max',\n",
    "           'HAZ_v_max_3',\n",
    "           'HAZ_dis_track_min',\n",
    "           'GEN_landslide_per',\n",
    "           'GEN_stormsurge_per',\n",
    "           #'GEN_Bu_p_inSSA', \n",
    "           #'GEN_Bu_p_LS', \n",
    "           'GEN_Red_per_LSbldg',\n",
    "           'GEN_Or_per_LSblg', \n",
    "           'GEN_Yel_per_LSSAb', \n",
    "           #'GEN_RED_per_SSAbldg',\n",
    "           'GEN_OR_per_SSAbldg',\n",
    "           'GEN_Yellow_per_LSbl',\n",
    "           'TOP_mean_slope',\n",
    "           'TOP_mean_elevation_m', \n",
    "           'TOP_ruggedness_stdev', \n",
    "           #'TOP_mean_ruggedness',\n",
    "           #'TOP_slope_stdev', \n",
    "           'VUL_poverty_perc',\n",
    "           'GEN_with_coast',\n",
    "           'GEN_coast_length', \n",
    "           'VUL_Housing_Units',\n",
    "           'VUL_StrongRoof_StrongWall', \n",
    "           'VUL_StrongRoof_LightWall',\n",
    "           'VUL_StrongRoof_SalvageWall', \n",
    "           'VUL_LightRoof_StrongWall',\n",
    "           'VUL_LightRoof_LightWall', \n",
    "           'VUL_LightRoof_SalvageWall',\n",
    "           'VUL_SalvagedRoof_StrongWall',\n",
    "           'VUL_SalvagedRoof_LightWall',\n",
    "           'VUL_SalvagedRoof_SalvageWall', \n",
    "           'VUL_vulnerable_groups',\n",
    "           'VUL_pantawid_pamilya_beneficiary']\n",
    "\n",
    "\n",
    "df=combined_input_data.dropna()\n",
    "display(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f93549d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1432ea6430>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#The Old and New set of bins\n",
    "#bins2= [0, 1, 60, 101]\n",
    "bins2 = [0, 0.00009, 1, 10, 50, 101]\n",
    "samples_per_bin2, binsP2 = np.histogram(df['DAM_perc_dmg'], bins=bins2)\n",
    "plt.xlabel(\"Damage Values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.plot(binsP2[1:],samples_per_bin2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6ff44ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4086 2431 1061  405   90]\n",
      "[0.00e+00 9.00e-05 1.00e+00 1.00e+01 5.00e+01 1.01e+02]\n"
     ]
    }
   ],
   "source": [
    "print(samples_per_bin2)\n",
    "print(binsP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26ddac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_index2=np.digitize(df['DAM_perc_dmg'], bins=binsP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "668dea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_input_strat=bin_index2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aba5b83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date and time : \n",
      "2022-11-10 02:30:24\n"
     ]
    }
   ],
   "source": [
    "#the Beginning time to run the model 20 times\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print (\"Current date and time : \")\n",
    "print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "565f48c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HAZ_rainfall_Total</th>\n",
       "      <th>HAZ_rainfall_max_6h</th>\n",
       "      <th>HAZ_rainfall_max_24h</th>\n",
       "      <th>HAZ_v_max</th>\n",
       "      <th>HAZ_v_max_3</th>\n",
       "      <th>HAZ_dis_track_min</th>\n",
       "      <th>GEN_landslide_per</th>\n",
       "      <th>GEN_stormsurge_per</th>\n",
       "      <th>GEN_Red_per_LSbldg</th>\n",
       "      <th>GEN_Or_per_LSblg</th>\n",
       "      <th>...</th>\n",
       "      <th>VUL_StrongRoof_LightWall</th>\n",
       "      <th>VUL_StrongRoof_SalvageWall</th>\n",
       "      <th>VUL_LightRoof_StrongWall</th>\n",
       "      <th>VUL_LightRoof_LightWall</th>\n",
       "      <th>VUL_LightRoof_SalvageWall</th>\n",
       "      <th>VUL_SalvagedRoof_StrongWall</th>\n",
       "      <th>VUL_SalvagedRoof_LightWall</th>\n",
       "      <th>VUL_SalvagedRoof_SalvageWall</th>\n",
       "      <th>VUL_vulnerable_groups</th>\n",
       "      <th>VUL_pantawid_pamilya_beneficiary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185.828571</td>\n",
       "      <td>14.716071</td>\n",
       "      <td>7.381696</td>\n",
       "      <td>55.032241</td>\n",
       "      <td>166667.757548</td>\n",
       "      <td>2.478142</td>\n",
       "      <td>2.64</td>\n",
       "      <td>6.18</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>8.211552</td>\n",
       "      <td>0.097425</td>\n",
       "      <td>2.533055</td>\n",
       "      <td>41.892832</td>\n",
       "      <td>1.002088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027836</td>\n",
       "      <td>0.083507</td>\n",
       "      <td>2.951511</td>\n",
       "      <td>46.931106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.818750</td>\n",
       "      <td>0.455208</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>8.728380</td>\n",
       "      <td>664.968323</td>\n",
       "      <td>288.358553</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>33.639236</td>\n",
       "      <td>0.850008</td>\n",
       "      <td>1.218595</td>\n",
       "      <td>13.645253</td>\n",
       "      <td>0.549120</td>\n",
       "      <td>0.030089</td>\n",
       "      <td>0.090266</td>\n",
       "      <td>0.112833</td>\n",
       "      <td>3.338873</td>\n",
       "      <td>25.989168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.175000</td>\n",
       "      <td>2.408333</td>\n",
       "      <td>0.957639</td>\n",
       "      <td>10.945624</td>\n",
       "      <td>1311.358762</td>\n",
       "      <td>274.953818</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>22.963749</td>\n",
       "      <td>0.197179</td>\n",
       "      <td>0.667374</td>\n",
       "      <td>15.592295</td>\n",
       "      <td>0.075838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015168</td>\n",
       "      <td>0.075838</td>\n",
       "      <td>2.131755</td>\n",
       "      <td>32.185651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.930000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>0.586250</td>\n",
       "      <td>12.108701</td>\n",
       "      <td>1775.385328</td>\n",
       "      <td>252.828578</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>16.179723</td>\n",
       "      <td>0.279362</td>\n",
       "      <td>0.675125</td>\n",
       "      <td>7.100454</td>\n",
       "      <td>0.023280</td>\n",
       "      <td>0.011640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128041</td>\n",
       "      <td>1.589369</td>\n",
       "      <td>29.612385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.550000</td>\n",
       "      <td>1.054167</td>\n",
       "      <td>0.528125</td>\n",
       "      <td>10.660943</td>\n",
       "      <td>1211.676901</td>\n",
       "      <td>258.194381</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>32.522996</td>\n",
       "      <td>0.065703</td>\n",
       "      <td>0.821288</td>\n",
       "      <td>30.354796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.387007</td>\n",
       "      <td>35.052562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25835</th>\n",
       "      <td>9.700000</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.216146</td>\n",
       "      <td>8.136932</td>\n",
       "      <td>538.743551</td>\n",
       "      <td>277.107823</td>\n",
       "      <td>1.80</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>19.563863</td>\n",
       "      <td>0.186916</td>\n",
       "      <td>3.613707</td>\n",
       "      <td>32.492212</td>\n",
       "      <td>0.311526</td>\n",
       "      <td>0.031153</td>\n",
       "      <td>0.155763</td>\n",
       "      <td>0.031153</td>\n",
       "      <td>2.827833</td>\n",
       "      <td>31.308411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25837</th>\n",
       "      <td>17.587500</td>\n",
       "      <td>1.414583</td>\n",
       "      <td>0.386458</td>\n",
       "      <td>9.818999</td>\n",
       "      <td>946.676507</td>\n",
       "      <td>305.789817</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>13.456446</td>\n",
       "      <td>0.209059</td>\n",
       "      <td>0.383275</td>\n",
       "      <td>4.703833</td>\n",
       "      <td>0.027875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034843</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>1.073268</td>\n",
       "      <td>12.766551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25838</th>\n",
       "      <td>11.487500</td>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.230319</td>\n",
       "      <td>15.791907</td>\n",
       "      <td>3938.254316</td>\n",
       "      <td>210.313249</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>22.347376</td>\n",
       "      <td>0.202748</td>\n",
       "      <td>0.090110</td>\n",
       "      <td>3.063753</td>\n",
       "      <td>0.022528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067583</td>\n",
       "      <td>0.022528</td>\n",
       "      <td>1.140109</td>\n",
       "      <td>9.348952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25839</th>\n",
       "      <td>11.600000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.412766</td>\n",
       "      <td>13.867145</td>\n",
       "      <td>2666.620370</td>\n",
       "      <td>218.189328</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>29.584121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094518</td>\n",
       "      <td>3.119093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.837537</td>\n",
       "      <td>21.928166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25841</th>\n",
       "      <td>32.305556</td>\n",
       "      <td>1.744444</td>\n",
       "      <td>1.210417</td>\n",
       "      <td>15.647639</td>\n",
       "      <td>3831.302757</td>\n",
       "      <td>219.542224</td>\n",
       "      <td>4.15</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.644103</td>\n",
       "      <td>0.031146</td>\n",
       "      <td>12.198920</td>\n",
       "      <td>36.191860</td>\n",
       "      <td>0.280316</td>\n",
       "      <td>0.010382</td>\n",
       "      <td>0.031146</td>\n",
       "      <td>0.103821</td>\n",
       "      <td>2.518110</td>\n",
       "      <td>31.634136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8073 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HAZ_rainfall_Total  HAZ_rainfall_max_6h  HAZ_rainfall_max_24h  \\\n",
       "0              185.828571            14.716071              7.381696   \n",
       "2                8.818750             0.455208              0.255319   \n",
       "4               24.175000             2.408333              0.957639   \n",
       "6               14.930000             1.650000              0.586250   \n",
       "7               13.550000             1.054167              0.528125   \n",
       "...                   ...                  ...                   ...   \n",
       "25835            9.700000             0.408333              0.216146   \n",
       "25837           17.587500             1.414583              0.386458   \n",
       "25838           11.487500             0.614583              0.230319   \n",
       "25839           11.600000             1.400000              0.412766   \n",
       "25841           32.305556             1.744444              1.210417   \n",
       "\n",
       "       HAZ_v_max    HAZ_v_max_3  HAZ_dis_track_min  GEN_landslide_per  \\\n",
       "0      55.032241  166667.757548           2.478142               2.64   \n",
       "2       8.728380     664.968323         288.358553               0.06   \n",
       "4      10.945624    1311.358762         274.953818               1.52   \n",
       "6      12.108701    1775.385328         252.828578               0.00   \n",
       "7      10.660943    1211.676901         258.194381               5.52   \n",
       "...          ...            ...                ...                ...   \n",
       "25835   8.136932     538.743551         277.107823               1.80   \n",
       "25837   9.818999     946.676507         305.789817               0.00   \n",
       "25838  15.791907    3938.254316         210.313249               0.06   \n",
       "25839  13.867145    2666.620370         218.189328               0.00   \n",
       "25841  15.647639    3831.302757         219.542224               4.15   \n",
       "\n",
       "       GEN_stormsurge_per  GEN_Red_per_LSbldg  GEN_Or_per_LSblg  ...  \\\n",
       "0                    6.18                1.17              0.03  ...   \n",
       "2                    0.00                0.06              0.00  ...   \n",
       "4                    1.28                0.02              0.00  ...   \n",
       "6                    0.00                0.00              0.00  ...   \n",
       "7                    0.36                0.00              0.00  ...   \n",
       "...                   ...                 ...               ...  ...   \n",
       "25835                6.25                0.12              0.00  ...   \n",
       "25837                0.00                0.00              0.00  ...   \n",
       "25838                0.09                0.06              0.00  ...   \n",
       "25839                0.00                0.00              0.00  ...   \n",
       "25841                3.05                0.00              0.00  ...   \n",
       "\n",
       "       VUL_StrongRoof_LightWall  VUL_StrongRoof_SalvageWall  \\\n",
       "0                      8.211552                    0.097425   \n",
       "2                     33.639236                    0.850008   \n",
       "4                     22.963749                    0.197179   \n",
       "6                     16.179723                    0.279362   \n",
       "7                     32.522996                    0.065703   \n",
       "...                         ...                         ...   \n",
       "25835                 19.563863                    0.186916   \n",
       "25837                 13.456446                    0.209059   \n",
       "25838                 22.347376                    0.202748   \n",
       "25839                 29.584121                    0.000000   \n",
       "25841                  3.644103                    0.031146   \n",
       "\n",
       "       VUL_LightRoof_StrongWall  VUL_LightRoof_LightWall  \\\n",
       "0                      2.533055                41.892832   \n",
       "2                      1.218595                13.645253   \n",
       "4                      0.667374                15.592295   \n",
       "6                      0.675125                 7.100454   \n",
       "7                      0.821288                30.354796   \n",
       "...                         ...                      ...   \n",
       "25835                  3.613707                32.492212   \n",
       "25837                  0.383275                 4.703833   \n",
       "25838                  0.090110                 3.063753   \n",
       "25839                  0.094518                 3.119093   \n",
       "25841                 12.198920                36.191860   \n",
       "\n",
       "       VUL_LightRoof_SalvageWall  VUL_SalvagedRoof_StrongWall  \\\n",
       "0                       1.002088                     0.000000   \n",
       "2                       0.549120                     0.030089   \n",
       "4                       0.075838                     0.000000   \n",
       "6                       0.023280                     0.011640   \n",
       "7                       0.000000                     0.000000   \n",
       "...                          ...                          ...   \n",
       "25835                   0.311526                     0.031153   \n",
       "25837                   0.027875                     0.000000   \n",
       "25838                   0.022528                     0.000000   \n",
       "25839                   0.000000                     0.000000   \n",
       "25841                   0.280316                     0.010382   \n",
       "\n",
       "       VUL_SalvagedRoof_LightWall  VUL_SalvagedRoof_SalvageWall  \\\n",
       "0                        0.027836                      0.083507   \n",
       "2                        0.090266                      0.112833   \n",
       "4                        0.015168                      0.075838   \n",
       "6                        0.000000                      0.128041   \n",
       "7                        0.032852                      0.000000   \n",
       "...                           ...                           ...   \n",
       "25835                    0.155763                      0.031153   \n",
       "25837                    0.034843                      0.097561   \n",
       "25838                    0.067583                      0.022528   \n",
       "25839                    0.000000                      0.000000   \n",
       "25841                    0.031146                      0.103821   \n",
       "\n",
       "       VUL_vulnerable_groups  VUL_pantawid_pamilya_beneficiary  \n",
       "0                   2.951511                         46.931106  \n",
       "2                   3.338873                         25.989168  \n",
       "4                   2.131755                         32.185651  \n",
       "6                   1.589369                         29.612385  \n",
       "7                   1.387007                         35.052562  \n",
       "...                      ...                               ...  \n",
       "25835               2.827833                         31.308411  \n",
       "25837               1.073268                         12.766551  \n",
       "25838               1.140109                          9.348952  \n",
       "25839               2.837537                         21.928166  \n",
       "25841               2.518110                         31.634136  \n",
       "\n",
       "[8073 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.462\n",
      "Model:                            OLS   Adj. R-squared:                  0.460\n",
      "Method:                 Least Squares   F-statistic:                     178.3\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:30:29   Log-Likelihood:                -21559.\n",
      "No. Observations:                6458   AIC:                         4.318e+04\n",
      "Df Residuals:                    6426   BIC:                         4.340e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4968      0.085     29.333      0.000       2.330       2.664\n",
      "x1            -1.1569      0.388     -2.985      0.003      -1.917      -0.397\n",
      "x2             1.5936      0.285      5.599      0.000       1.036       2.152\n",
      "x3             0.4626      0.539      0.858      0.391      -0.594       1.520\n",
      "x4            -4.9181      0.331    -14.854      0.000      -5.567      -4.269\n",
      "x5             9.3345      0.224     41.692      0.000       8.896       9.773\n",
      "x6            -0.5331      0.199     -2.675      0.007      -0.924      -0.142\n",
      "x7           -53.6965     61.467     -0.874      0.382    -174.192      66.799\n",
      "x8             0.2768      0.099      2.794      0.005       0.083       0.471\n",
      "x9            31.9541     36.441      0.877      0.381     -39.482     103.391\n",
      "x10            0.3755      0.469      0.801      0.423      -0.543       1.294\n",
      "x11           43.0871     49.664      0.868      0.386     -54.270     140.444\n",
      "x12           -0.0566      0.087     -0.651      0.515      -0.227       0.114\n",
      "x13           -0.1180      0.098     -1.207      0.227      -0.310       0.074\n",
      "x14            0.2253      0.267      0.842      0.400      -0.299       0.750\n",
      "x15           -0.4506      0.178     -2.528      0.011      -0.800      -0.101\n",
      "x16           -0.2101      0.183     -1.150      0.250      -0.568       0.148\n",
      "x17           -2.8402      0.275    -10.326      0.000      -3.379      -2.301\n",
      "x18            0.1954      0.120      1.633      0.103      -0.039       0.430\n",
      "x19           -0.1514      0.110     -1.375      0.169      -0.367       0.064\n",
      "x20           -0.2453      0.092     -2.652      0.008      -0.427      -0.064\n",
      "x21           -2.9315      2.984     -0.982      0.326      -8.781       2.918\n",
      "x22           -2.3526      2.194     -1.072      0.284      -6.654       1.949\n",
      "x23            0.3816      0.144      2.658      0.008       0.100       0.663\n",
      "x24           -0.2353      0.428     -0.550      0.582      -1.074       0.603\n",
      "x25           -2.0720      2.010     -1.031      0.303      -6.013       1.869\n",
      "x26            0.1503      0.115      1.312      0.190      -0.074       0.375\n",
      "x27           -0.0087      0.111     -0.079      0.937      -0.226       0.209\n",
      "x28            0.2282      0.113      2.026      0.043       0.007       0.449\n",
      "x29           -0.0209      0.120     -0.175      0.861      -0.256       0.214\n",
      "x30            0.5985      0.141      4.248      0.000       0.322       0.875\n",
      "x31            3.3281      0.258     12.895      0.000       2.822       3.834\n",
      "==============================================================================\n",
      "Omnibus:                     6410.316   Durbin-Watson:                   2.016\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           562521.441\n",
      "Skew:                           4.685   Prob(JB):                         0.00\n",
      "Kurtosis:                      47.752   Cond. No.                     2.30e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.3e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "----- Test  ------\n",
      "Mean absolute error: 1.92\n",
      "Mean squared error: 30.50\n",
      "Root mean squared error: 5.52\n",
      "Max error: 60.52\n",
      "Average Error: -0.04\n",
      "---- Training -----\n",
      "Mean absolute error: 1.68\n",
      "Mean squared error: 24.12\n",
      "Root mean squared error: 4.91\n",
      "Max error: 83.87\n",
      "Average Error: -0.10\n",
      "Training score coefficient of determination for XGboost R^2: 0.721 \n",
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.465\n",
      "Model:                            OLS   Adj. R-squared:                  0.462\n",
      "Method:                 Least Squares   F-statistic:                     180.1\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:30:30   Log-Likelihood:                -21513.\n",
      "No. Observations:                6458   AIC:                         4.309e+04\n",
      "Df Residuals:                    6426   BIC:                         4.331e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4714      0.084     29.261      0.000       2.306       2.637\n",
      "x1            -1.6092      0.383     -4.205      0.000      -2.359      -0.859\n",
      "x2             1.2360      0.285      4.330      0.000       0.676       1.796\n",
      "x3             1.2011      0.531      2.260      0.024       0.159       2.243\n",
      "x4            -4.7934      0.326    -14.694      0.000      -5.433      -4.154\n",
      "x5             9.1687      0.223     41.193      0.000       8.732       9.605\n",
      "x6            -0.5724      0.197     -2.906      0.004      -0.959      -0.186\n",
      "x7           -75.7073     60.556     -1.250      0.211    -194.417      43.003\n",
      "x8             0.3933      0.095      4.123      0.000       0.206       0.580\n",
      "x9            45.0312     35.901      1.254      0.210     -25.347     115.409\n",
      "x10            0.5883      0.462      1.274      0.203      -0.317       1.494\n",
      "x11           60.7658     48.927      1.242      0.214     -35.148     156.680\n",
      "x12           -0.0758      0.090     -0.846      0.398      -0.252       0.100\n",
      "x13           -0.1586      0.096     -1.644      0.100      -0.348       0.031\n",
      "x14           -0.1080      0.267     -0.405      0.686      -0.631       0.415\n",
      "x15           -0.4137      0.176     -2.348      0.019      -0.759      -0.068\n",
      "x16            0.1192      0.182      0.653      0.514      -0.238       0.477\n",
      "x17           -3.5499      0.280    -12.700      0.000      -4.098      -3.002\n",
      "x18            0.1800      0.118      1.521      0.128      -0.052       0.412\n",
      "x19           -0.0657      0.104     -0.633      0.527      -0.269       0.138\n",
      "x20           -0.2291      0.090     -2.537      0.011      -0.406      -0.052\n",
      "x21           -2.0741      2.785     -0.745      0.457      -7.534       3.386\n",
      "x22           -1.7763      2.048     -0.867      0.386      -5.792       2.239\n",
      "x23            0.5072      0.140      3.626      0.000       0.233       0.781\n",
      "x24           -0.1668      0.402     -0.415      0.678      -0.955       0.621\n",
      "x25           -1.5547      1.875     -0.829      0.407      -5.231       2.122\n",
      "x26            0.1407      0.128      1.098      0.272      -0.111       0.392\n",
      "x27           -0.0957      0.094     -1.024      0.306      -0.279       0.088\n",
      "x28            0.2853      0.110      2.590      0.010       0.069       0.501\n",
      "x29            0.0264      0.119      0.221      0.825      -0.207       0.260\n",
      "x30            0.6621      0.141      4.708      0.000       0.386       0.938\n",
      "x31            4.0483      0.269     15.043      0.000       3.521       4.576\n",
      "==============================================================================\n",
      "Omnibus:                     6319.361   Durbin-Watson:                   1.999\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           530307.201\n",
      "Skew:                           4.587   Prob(JB):                         0.00\n",
      "Kurtosis:                      46.435   Cond. No.                     2.28e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.28e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "----- Test  ------\n",
      "Mean absolute error: 1.85\n",
      "Mean squared error: 28.67\n",
      "Root mean squared error: 5.35\n",
      "Max error: 62.00\n",
      "Average Error: -0.16\n",
      "---- Training -----\n",
      "Mean absolute error: 1.64\n",
      "Mean squared error: 24.05\n",
      "Root mean squared error: 4.90\n",
      "Max error: 83.24\n",
      "Average Error: -0.08\n",
      "Training score coefficient of determination for XGboost R^2: 0.719 \n",
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.455\n",
      "Model:                            OLS   Adj. R-squared:                  0.453\n",
      "Method:                 Least Squares   F-statistic:                     173.3\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:30:30   Log-Likelihood:                -21610.\n",
      "No. Observations:                6458   AIC:                         4.328e+04\n",
      "Df Residuals:                    6426   BIC:                         4.350e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4650      0.086     28.746      0.000       2.297       2.633\n",
      "x1            -1.4415      0.390     -3.699      0.000      -2.205      -0.678\n",
      "x2             1.3484      0.288      4.682      0.000       0.784       1.913\n",
      "x3             0.9738      0.541      1.799      0.072      -0.087       2.035\n",
      "x4            -4.5054      0.330    -13.633      0.000      -5.153      -3.858\n",
      "x5             8.7594      0.226     38.805      0.000       8.317       9.202\n",
      "x6            -0.4682      0.200     -2.343      0.019      -0.860      -0.076\n",
      "x7           -59.2252     61.431     -0.964      0.335    -179.651      61.201\n",
      "x8             0.4453      0.100      4.439      0.000       0.249       0.642\n",
      "x9            35.2686     36.420      0.968      0.333     -36.127     106.665\n",
      "x10            0.4309      0.467      0.923      0.356      -0.484       1.346\n",
      "x11           47.3454     49.635      0.954      0.340     -49.957     144.647\n",
      "x12           -0.0749      0.092     -0.811      0.417      -0.256       0.106\n",
      "x13           -0.1316      0.097     -1.357      0.175      -0.322       0.059\n",
      "x14            0.0525      0.269      0.195      0.845      -0.476       0.581\n",
      "x15           -0.4859      0.179     -2.711      0.007      -0.837      -0.135\n",
      "x16            0.0279      0.185      0.151      0.880      -0.334       0.390\n",
      "x17           -4.8302      0.278    -17.382      0.000      -5.375      -4.285\n",
      "x18            0.3177      0.120      2.644      0.008       0.082       0.553\n",
      "x19           -0.2599      0.107     -2.423      0.015      -0.470      -0.050\n",
      "x20           -0.2165      0.094     -2.303      0.021      -0.401      -0.032\n",
      "x21           -0.2643      2.909     -0.091      0.928      -5.967       5.438\n",
      "x22           -0.3767      2.139     -0.176      0.860      -4.569       3.816\n",
      "x23            0.5222      0.143      3.645      0.000       0.241       0.803\n",
      "x24            0.1196      0.418      0.286      0.775      -0.700       0.939\n",
      "x25           -0.2773      1.959     -0.142      0.887      -4.118       3.563\n",
      "x26            0.2895      0.130      2.219      0.027       0.034       0.545\n",
      "x27           -0.0351      0.102     -0.343      0.732      -0.236       0.165\n",
      "x28            0.2009      0.103      1.955      0.051      -0.001       0.402\n",
      "x29            0.0304      0.120      0.254      0.799      -0.204       0.265\n",
      "x30            0.4262      0.143      2.983      0.003       0.146       0.706\n",
      "x31            5.5030      0.264     20.875      0.000       4.986       6.020\n",
      "==============================================================================\n",
      "Omnibus:                     6334.695   Durbin-Watson:                   2.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           517541.699\n",
      "Skew:                           4.618   Prob(JB):                         0.00\n",
      "Kurtosis:                      45.872   Cond. No.                     2.26e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.26e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "----- Test  ------\n",
      "Mean absolute error: 1.97\n",
      "Mean squared error: 33.99\n",
      "Root mean squared error: 5.83\n",
      "Max error: 51.79\n",
      "Average Error: -0.25\n",
      "---- Training -----\n",
      "Mean absolute error: 1.78\n",
      "Mean squared error: 28.73\n",
      "Root mean squared error: 5.36\n",
      "Max error: 85.33\n",
      "Average Error: -0.26\n",
      "Training score coefficient of determination for XGboost R^2: 0.668 \n",
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.461\n",
      "Model:                            OLS   Adj. R-squared:                  0.458\n",
      "Method:                 Least Squares   F-statistic:                     177.1\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:30:31   Log-Likelihood:                -21504.\n",
      "No. Observations:                6458   AIC:                         4.307e+04\n",
      "Df Residuals:                    6426   BIC:                         4.329e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4586      0.084     29.144      0.000       2.293       2.624\n",
      "x1            -1.4705      0.386     -3.807      0.000      -2.228      -0.713\n",
      "x2             1.1538      0.286      4.034      0.000       0.593       1.714\n",
      "x3             1.1561      0.535      2.163      0.031       0.108       2.204\n",
      "x4            -4.5230      0.324    -13.964      0.000      -5.158      -3.888\n",
      "x5             8.8893      0.220     40.385      0.000       8.458       9.321\n",
      "x6            -0.4858      0.196     -2.478      0.013      -0.870      -0.102\n",
      "x7           -89.9086     60.474     -1.487      0.137    -208.457      28.640\n",
      "x8             0.4377      0.095      4.630      0.000       0.252       0.623\n",
      "x9            53.4466     35.852      1.491      0.136     -16.835     123.728\n",
      "x10            0.7179      0.462      1.554      0.120      -0.188       1.624\n",
      "x11           72.3390     48.861      1.481      0.139     -23.444     168.122\n",
      "x12           -0.0857      0.088     -0.978      0.328      -0.257       0.086\n",
      "x13           -0.1134      0.096     -1.176      0.240      -0.302       0.076\n",
      "x14           -0.0468      0.265     -0.177      0.860      -0.566       0.472\n",
      "x15           -0.3875      0.174     -2.222      0.026      -0.729      -0.046\n",
      "x16            0.0198      0.182      0.109      0.914      -0.338       0.377\n",
      "x17           -3.6587      0.256    -14.294      0.000      -4.160      -3.157\n",
      "x18            0.1683      0.119      1.416      0.157      -0.065       0.401\n",
      "x19           -0.1344      0.105     -1.279      0.201      -0.341       0.072\n",
      "x20           -0.2474      0.089     -2.780      0.005      -0.422      -0.073\n",
      "x21           -1.3514      2.851     -0.474      0.636      -6.941       4.238\n",
      "x22           -1.2432      2.096     -0.593      0.553      -5.352       2.865\n",
      "x23            0.6006      0.141      4.271      0.000       0.325       0.876\n",
      "x24           -0.0635      0.409     -0.155      0.877      -0.866       0.739\n",
      "x25           -0.9055      1.920     -0.472      0.637      -4.670       2.859\n",
      "x26            0.1206      0.114      1.060      0.289      -0.102       0.344\n",
      "x27           -0.0909      0.100     -0.909      0.363      -0.287       0.105\n",
      "x28            0.2793      0.111      2.505      0.012       0.061       0.498\n",
      "x29           -0.0005      0.121     -0.004      0.997      -0.237       0.236\n",
      "x30            0.5992      0.140      4.273      0.000       0.324       0.874\n",
      "x31            4.0931      0.241     16.982      0.000       3.621       4.566\n",
      "==============================================================================\n",
      "Omnibus:                     6421.467   Durbin-Watson:                   1.997\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           550522.653\n",
      "Skew:                           4.709   Prob(JB):                         0.00\n",
      "Kurtosis:                      47.240   Cond. No.                     2.28e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.28e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "----- Test  ------\n",
      "Mean absolute error: 1.90\n",
      "Mean squared error: 30.29\n",
      "Root mean squared error: 5.50\n",
      "Max error: 60.89\n",
      "Average Error: -0.02\n",
      "---- Training -----\n",
      "Mean absolute error: 1.52\n",
      "Mean squared error: 18.56\n",
      "Root mean squared error: 4.31\n",
      "Max error: 76.22\n",
      "Average Error: -0.01\n",
      "Training score coefficient of determination for XGboost R^2: 0.781 \n",
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.472\n",
      "Model:                            OLS   Adj. R-squared:                  0.470\n",
      "Method:                 Least Squares   F-statistic:                     185.6\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:30:32   Log-Likelihood:                -21376.\n",
      "No. Observations:                6458   AIC:                         4.282e+04\n",
      "Df Residuals:                    6426   BIC:                         4.303e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4381      0.083     29.474      0.000       2.276       2.600\n",
      "x1            -1.9163      0.378     -5.076      0.000      -2.656      -1.176\n",
      "x2             1.0729      0.276      3.886      0.000       0.532       1.614\n",
      "x3             1.6788      0.520      3.232      0.001       0.660       2.697\n",
      "x4            -5.0306      0.319    -15.790      0.000      -5.655      -4.406\n",
      "x5             9.3189      0.219     42.522      0.000       8.889       9.749\n",
      "x6            -0.6052      0.193     -3.136      0.002      -0.983      -0.227\n",
      "x7           -97.9095     59.317     -1.651      0.099    -214.191      18.372\n",
      "x8             0.3267      0.094      3.479      0.001       0.143       0.511\n",
      "x9            58.0855     35.166      1.652      0.099     -10.852     127.023\n",
      "x10            0.7729      0.453      1.706      0.088      -0.115       1.661\n",
      "x11           78.7831     47.928      1.644      0.100     -15.171     172.737\n",
      "x12           -0.0693      0.088     -0.785      0.433      -0.243       0.104\n",
      "x13           -0.0935      0.096     -0.974      0.330      -0.282       0.095\n",
      "x14            0.1630      0.261      0.623      0.533      -0.349       0.675\n",
      "x15           -0.4741      0.170     -2.783      0.005      -0.808      -0.140\n",
      "x16           -0.0265      0.180     -0.147      0.883      -0.378       0.325\n",
      "x17           -3.7275      0.262    -14.204      0.000      -4.242      -3.213\n",
      "x18            0.1667      0.117      1.426      0.154      -0.062       0.396\n",
      "x19           -0.1144      0.106     -1.079      0.281      -0.322       0.093\n",
      "x20           -0.2398      0.090     -2.654      0.008      -0.417      -0.063\n",
      "x21           -0.3242      2.784     -0.116      0.907      -5.782       5.133\n",
      "x22           -0.5559      2.046     -0.272      0.786      -4.567       3.456\n",
      "x23            0.6487      0.141      4.593      0.000       0.372       0.926\n",
      "x24           -0.0374      0.401     -0.093      0.926      -0.823       0.749\n",
      "x25           -0.2221      1.874     -0.119      0.906      -3.896       3.452\n",
      "x26            0.1322      0.124      1.064      0.288      -0.112       0.376\n",
      "x27           -0.0815      0.105     -0.776      0.438      -0.287       0.124\n",
      "x28            0.2045      0.109      1.875      0.061      -0.009       0.418\n",
      "x29            0.0969      0.116      0.836      0.403      -0.130       0.324\n",
      "x30            0.5537      0.136      4.059      0.000       0.286       0.821\n",
      "x31            4.2523      0.248     17.179      0.000       3.767       4.738\n",
      "==============================================================================\n",
      "Omnibus:                     6178.830   Durbin-Watson:                   2.018\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           480173.415\n",
      "Skew:                           4.442   Prob(JB):                         0.00\n",
      "Kurtosis:                      44.298   Cond. No.                     2.28e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.28e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "----- Test  ------\n",
      "Mean absolute error: 2.10\n",
      "Mean squared error: 42.58\n",
      "Root mean squared error: 6.53\n",
      "Max error: 89.95\n",
      "Average Error: -0.21\n",
      "---- Training -----\n",
      "Mean absolute error: 1.60\n",
      "Mean squared error: 21.59\n",
      "Root mean squared error: 4.65\n",
      "Max error: 80.20\n",
      "Average Error: -0.10\n",
      "Training score coefficient of determination for XGboost R^2: 0.741 \n",
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.467\n",
      "Model:                            OLS   Adj. R-squared:                  0.465\n",
      "Method:                 Least Squares   F-statistic:                     181.7\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:30:32   Log-Likelihood:                -21473.\n",
      "No. Observations:                6458   AIC:                         4.301e+04\n",
      "Df Residuals:                    6426   BIC:                         4.323e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4843      0.084     29.587      0.000       2.320       2.649\n",
      "x1            -1.6404      0.380     -4.319      0.000      -2.385      -0.896\n",
      "x2             1.1176      0.282      3.969      0.000       0.566       1.669\n",
      "x3             1.3971      0.525      2.662      0.008       0.368       2.426\n",
      "x4            -4.5967      0.321    -14.300      0.000      -5.227      -3.967\n",
      "x5             8.9768      0.220     40.841      0.000       8.546       9.408\n",
      "x6            -0.4572      0.195     -2.341      0.019      -0.840      -0.074\n",
      "x7           -95.2632     59.922     -1.590      0.112    -212.731      22.205\n",
      "x8             0.4238      0.094      4.519      0.000       0.240       0.608\n",
      "x9            56.5812     35.525      1.593      0.111     -13.060     126.222\n",
      "x10            0.6877      0.458      1.502      0.133      -0.210       1.585\n",
      "x11           76.5907     48.416      1.582      0.114     -18.320     171.502\n",
      "x12           -0.0890      0.091     -0.975      0.330      -0.268       0.090\n",
      "x13           -0.1004      0.097     -1.034      0.301      -0.291       0.090\n",
      "x14            0.1782      0.264      0.675      0.500      -0.339       0.696\n",
      "x15           -0.5223      0.176     -2.960      0.003      -0.868      -0.176\n",
      "x16           -0.0795      0.181     -0.438      0.661      -0.435       0.276\n",
      "x17           -4.0358      0.255    -15.855      0.000      -4.535      -3.537\n",
      "x18            0.2495      0.118      2.113      0.035       0.018       0.481\n",
      "x19           -0.1032      0.104     -0.992      0.321      -0.307       0.101\n",
      "x20           -0.2325      0.087     -2.679      0.007      -0.403      -0.062\n",
      "x21           -1.7197      2.876     -0.598      0.550      -7.358       3.919\n",
      "x22           -1.6054      2.114     -0.759      0.448      -5.750       2.539\n",
      "x23            0.4735      0.138      3.430      0.001       0.203       0.744\n",
      "x24           -0.1531      0.413     -0.371      0.711      -0.962       0.656\n",
      "x25           -1.3804      1.938     -0.712      0.476      -5.179       2.418\n",
      "x26            0.2184      0.129      1.688      0.091      -0.035       0.472\n",
      "x27           -0.0307      0.096     -0.320      0.749      -0.219       0.158\n",
      "x28            0.1016      0.126      0.805      0.421      -0.146       0.349\n",
      "x29            0.0366      0.124      0.295      0.768      -0.207       0.280\n",
      "x30            0.6699      0.138      4.871      0.000       0.400       0.940\n",
      "x31            4.5893      0.237     19.336      0.000       4.124       5.055\n",
      "==============================================================================\n",
      "Omnibus:                     6124.800   Durbin-Watson:                   2.002\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           456801.341\n",
      "Skew:                           4.392   Prob(JB):                         0.00\n",
      "Kurtosis:                      43.255   Cond. No.                     2.27e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.27e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "----- Test  ------\n",
      "Mean absolute error: 2.03\n",
      "Mean squared error: 41.23\n",
      "Root mean squared error: 6.42\n",
      "Max error: 80.93\n",
      "Average Error: -0.28\n",
      "---- Training -----\n",
      "Mean absolute error: 1.80\n",
      "Mean squared error: 29.29\n",
      "Root mean squared error: 5.41\n",
      "Max error: 90.95\n",
      "Average Error: -0.32\n",
      "Training score coefficient of determination for XGboost R^2: 0.655 \n",
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.477\n",
      "Model:                            OLS   Adj. R-squared:                  0.474\n",
      "Method:                 Least Squares   F-statistic:                     188.9\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:30:33   Log-Likelihood:                -21401.\n",
      "No. Observations:                6458   AIC:                         4.287e+04\n",
      "Df Residuals:                    6426   BIC:                         4.308e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4204      0.083     29.152      0.000       2.258       2.583\n",
      "x1            -1.2924      0.378     -3.419      0.001      -2.033      -0.551\n",
      "x2             1.5177      0.276      5.506      0.000       0.977       2.058\n",
      "x3             0.6151      0.524      1.175      0.240      -0.411       1.642\n",
      "x4            -4.6982      0.317    -14.800      0.000      -5.320      -4.076\n",
      "x5             9.0653      0.213     42.485      0.000       8.647       9.484\n",
      "x6            -0.5014      0.194     -2.588      0.010      -0.881      -0.122\n",
      "x7           -65.7969     59.401     -1.108      0.268    -182.243      50.649\n",
      "x8             0.4273      0.096      4.453      0.000       0.239       0.615\n",
      "x9            39.1076     35.216      1.111      0.267     -29.927     108.142\n",
      "x10            0.4786      0.452      1.059      0.290      -0.407       1.365\n",
      "x11           52.8431     47.995      1.101      0.271     -41.242     146.928\n",
      "x12           -0.1150      0.086     -1.345      0.179      -0.283       0.053\n",
      "x13           -0.0606      0.094     -0.642      0.521      -0.246       0.124\n",
      "x14            0.0013      0.260      0.005      0.996      -0.509       0.512\n",
      "x15           -0.4717      0.170     -2.772      0.006      -0.805      -0.138\n",
      "x16            0.0774      0.179      0.431      0.666      -0.274       0.429\n",
      "x17           -2.8136      0.261    -10.779      0.000      -3.325      -2.302\n",
      "x18            0.1470      0.117      1.254      0.210      -0.083       0.377\n",
      "x19           -0.1645      0.105     -1.561      0.118      -0.371       0.042\n",
      "x20           -0.2105      0.090     -2.332      0.020      -0.387      -0.034\n",
      "x21           -3.3701      2.907     -1.159      0.246      -9.068       2.328\n",
      "x22           -2.6715      2.137     -1.250      0.211      -6.861       1.518\n",
      "x23            0.4196      0.138      3.033      0.002       0.148       0.691\n",
      "x24           -0.3764      0.416     -0.905      0.365      -1.191       0.439\n",
      "x25           -2.3065      1.959     -1.178      0.239      -6.146       1.533\n",
      "x26            0.1250      0.113      1.102      0.270      -0.097       0.347\n",
      "x27           -0.0911      0.113     -0.805      0.421      -0.313       0.131\n",
      "x28            0.1348      0.111      1.219      0.223      -0.082       0.352\n",
      "x29            0.0824      0.117      0.707      0.479      -0.146       0.311\n",
      "x30            0.5235      0.139      3.768      0.000       0.251       0.796\n",
      "x31            3.3568      0.247     13.586      0.000       2.872       3.841\n",
      "==============================================================================\n",
      "Omnibus:                     6190.998   Durbin-Watson:                   1.990\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           484065.090\n",
      "Skew:                           4.455   Prob(JB):                         0.00\n",
      "Kurtosis:                      44.468   Cond. No.                     2.29e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.29e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "----- Test  ------\n",
      "Mean absolute error: 1.87\n",
      "Mean squared error: 37.37\n",
      "Root mean squared error: 6.11\n",
      "Max error: 89.17\n",
      "Average Error: -0.18\n",
      "---- Training -----\n",
      "Mean absolute error: 1.59\n",
      "Mean squared error: 20.96\n",
      "Root mean squared error: 4.58\n",
      "Max error: 84.30\n",
      "Average Error: -0.07\n",
      "Training score coefficient of determination for XGboost R^2: 0.752 \n",
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.476\n",
      "Model:                            OLS   Adj. R-squared:                  0.474\n",
      "Method:                 Least Squares   F-statistic:                     188.5\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:30:33   Log-Likelihood:                -21474.\n",
      "No. Observations:                6458   AIC:                         4.301e+04\n",
      "Df Residuals:                    6426   BIC:                         4.323e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4838      0.084     29.585      0.000       2.319       2.648\n",
      "x1            -1.3693      0.389     -3.519      0.000      -2.132      -0.606\n",
      "x2             1.3058      0.286      4.565      0.000       0.745       1.867\n",
      "x3             0.9315      0.536      1.737      0.082      -0.120       1.983\n",
      "x4            -4.9590      0.323    -15.366      0.000      -5.592      -4.326\n",
      "x5             9.4131      0.219     42.962      0.000       8.984       9.843\n",
      "x6            -0.5012      0.196     -2.560      0.010      -0.885      -0.117\n",
      "x7           -85.7822     59.553     -1.440      0.150    -202.525      30.961\n",
      "x8             0.3177      0.096      3.299      0.001       0.129       0.506\n",
      "x9            50.9614     35.307      1.443      0.149     -18.251     120.174\n",
      "x10            0.6395      0.454      1.409      0.159      -0.250       1.529\n",
      "x11           68.9423     48.117      1.433      0.152     -25.384     163.268\n",
      "x12           -0.0748      0.087     -0.864      0.388      -0.244       0.095\n",
      "x13           -0.0895      0.096     -0.934      0.350      -0.277       0.098\n",
      "x14           -0.0543      0.266     -0.204      0.838      -0.576       0.467\n",
      "x15           -0.3446      0.174     -1.984      0.047      -0.685      -0.004\n",
      "x16           -0.0110      0.183     -0.060      0.952      -0.369       0.347\n",
      "x17           -2.9844      0.261    -11.450      0.000      -3.495      -2.473\n",
      "x18            0.2530      0.118      2.144      0.032       0.022       0.484\n",
      "x19           -0.1535      0.106     -1.452      0.147      -0.361       0.054\n",
      "x20           -0.2623      0.091     -2.881      0.004      -0.441      -0.084\n",
      "x21           -0.5075      2.823     -0.180      0.857      -6.042       5.027\n",
      "x22           -0.5111      2.075     -0.246      0.805      -4.580       3.557\n",
      "x23            0.4637      0.140      3.308      0.001       0.189       0.739\n",
      "x24            0.0636      0.406      0.156      0.876      -0.733       0.860\n",
      "x25           -0.4048      1.901     -0.213      0.831      -4.132       3.323\n",
      "x26            0.1625      0.114      1.430      0.153      -0.060       0.385\n",
      "x27            0.0294      0.098      0.301      0.763      -0.162       0.221\n",
      "x28            0.2253      0.099      2.267      0.023       0.030       0.420\n",
      "x29            0.0508      0.120      0.422      0.673      -0.185       0.287\n",
      "x30            0.4751      0.141      3.377      0.001       0.199       0.751\n",
      "x31            3.5341      0.250     14.158      0.000       3.045       4.023\n",
      "==============================================================================\n",
      "Omnibus:                     6277.701   Durbin-Watson:                   1.986\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           509780.857\n",
      "Skew:                           4.548   Prob(JB):                         0.00\n",
      "Kurtosis:                      45.565   Cond. No.                     2.26e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.26e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "----- Test  ------\n",
      "Mean absolute error: 1.85\n",
      "Mean squared error: 30.84\n",
      "Root mean squared error: 5.55\n",
      "Max error: 79.37\n",
      "Average Error: 0.08\n",
      "---- Training -----\n",
      "Mean absolute error: 1.61\n",
      "Mean squared error: 21.05\n",
      "Root mean squared error: 4.59\n",
      "Max error: 84.16\n",
      "Average Error: -0.04\n",
      "Training score coefficient of determination for XGboost R^2: 0.756 \n",
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.471\n",
      "Model:                            OLS   Adj. R-squared:                  0.468\n",
      "Method:                 Least Squares   F-statistic:                     184.3\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:30:34   Log-Likelihood:                -21379.\n",
      "No. Observations:                6458   AIC:                         4.282e+04\n",
      "Df Residuals:                    6426   BIC:                         4.304e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4115      0.083     29.143      0.000       2.249       2.574\n",
      "x1            -1.3403      0.372     -3.605      0.000      -2.069      -0.611\n",
      "x2             1.1048      0.279      3.956      0.000       0.557       1.652\n",
      "x3             0.8991      0.517      1.738      0.082      -0.115       1.913\n",
      "x4            -4.7017      0.319    -14.745      0.000      -5.327      -4.077\n",
      "x5             9.1353      0.216     42.205      0.000       8.711       9.560\n",
      "x6            -0.5425      0.194     -2.798      0.005      -0.923      -0.162\n",
      "x7           -29.8735     59.115     -0.505      0.613    -145.758      86.011\n",
      "x8             0.3473      0.094      3.689      0.000       0.163       0.532\n",
      "x9            17.8191     35.046      0.508      0.611     -50.882      86.521\n",
      "x10            0.2040      0.450      0.453      0.650      -0.678       1.087\n",
      "x11           23.7648     47.762      0.498      0.619     -69.865     117.395\n",
      "x12           -0.0403      0.091     -0.443      0.658      -0.219       0.138\n",
      "x13           -0.0955      0.095     -1.009      0.313      -0.281       0.090\n",
      "x14            0.0431      0.260      0.166      0.869      -0.467       0.554\n",
      "x15           -0.3514      0.172     -2.044      0.041      -0.688      -0.014\n",
      "x16           -0.0527      0.178     -0.296      0.767      -0.402       0.296\n",
      "x17           -2.7839      0.266    -10.461      0.000      -3.306      -2.262\n",
      "x18            0.2127      0.117      1.821      0.069      -0.016       0.442\n",
      "x19           -0.1658      0.106     -1.558      0.119      -0.375       0.043\n",
      "x20           -0.1536      0.087     -1.759      0.079      -0.325       0.018\n",
      "x21           -0.4429      2.759     -0.161      0.872      -5.852       4.966\n",
      "x22           -0.6136      2.029     -0.302      0.762      -4.590       3.363\n",
      "x23            0.4568      0.136      3.367      0.001       0.191       0.723\n",
      "x24            0.2190      0.396      0.553      0.580      -0.557       0.995\n",
      "x25           -0.5045      1.859     -0.271      0.786      -4.148       3.139\n",
      "x26            0.0787      0.111      0.709      0.479      -0.139       0.297\n",
      "x27            0.0469      0.110      0.427      0.669      -0.168       0.262\n",
      "x28            0.1950      0.125      1.566      0.117      -0.049       0.439\n",
      "x29            0.0901      0.118      0.764      0.445      -0.141       0.321\n",
      "x30            0.5913      0.138      4.288      0.000       0.321       0.862\n",
      "x31            3.3759      0.253     13.357      0.000       2.880       3.871\n",
      "==============================================================================\n",
      "Omnibus:                     6288.198   Durbin-Watson:                   1.973\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           514975.072\n",
      "Skew:                           4.558   Prob(JB):                         0.00\n",
      "Kurtosis:                      45.787   Cond. No.                     2.27e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.27e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "----- Test  ------\n",
      "Mean absolute error: 2.00\n",
      "Mean squared error: 40.36\n",
      "Root mean squared error: 6.35\n",
      "Max error: 89.50\n",
      "Average Error: -0.36\n",
      "---- Training -----\n",
      "Mean absolute error: 1.64\n",
      "Mean squared error: 23.46\n",
      "Root mean squared error: 4.84\n",
      "Max error: 85.70\n",
      "Average Error: -0.13\n",
      "Training score coefficient of determination for XGboost R^2: 0.718 \n",
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.459\n",
      "Model:                            OLS   Adj. R-squared:                  0.456\n",
      "Method:                 Least Squares   F-statistic:                     175.8\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:30:34   Log-Likelihood:                -21639.\n",
      "No. Observations:                6458   AIC:                         4.334e+04\n",
      "Df Residuals:                    6426   BIC:                         4.356e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4572      0.086     28.534      0.000       2.288       2.626\n",
      "x1            -1.1158      0.387     -2.881      0.004      -1.875      -0.357\n",
      "x2             1.5320      0.290      5.288      0.000       0.964       2.100\n",
      "x3             0.3317      0.537      0.618      0.537      -0.720       1.384\n",
      "x4            -4.6364      0.330    -14.033      0.000      -5.284      -3.989\n",
      "x5             9.0752      0.226     40.151      0.000       8.632       9.518\n",
      "x6            -0.5345      0.201     -2.664      0.008      -0.928      -0.141\n",
      "x7           -66.2736     61.611     -1.076      0.282    -187.051      54.504\n",
      "x8             0.4640      0.097      4.807      0.000       0.275       0.653\n",
      "x9            39.3987     36.526      1.079      0.281     -32.204     111.002\n",
      "x10            0.4804      0.469      1.023      0.306      -0.440       1.401\n",
      "x11           53.1513     49.780      1.068      0.286     -44.434     150.736\n",
      "x12           -0.1024      0.093     -1.100      0.271      -0.285       0.080\n",
      "x13           -0.1250      0.098     -1.279      0.201      -0.317       0.067\n",
      "x14            0.1879      0.269      0.698      0.485      -0.339       0.715\n",
      "x15           -0.4525      0.177     -2.558      0.011      -0.799      -0.106\n",
      "x16           -0.1223      0.184     -0.663      0.507      -0.484       0.239\n",
      "x17           -3.7906      0.259    -14.654      0.000      -4.298      -3.284\n",
      "x18            0.1230      0.121      1.017      0.309      -0.114       0.360\n",
      "x19           -0.1178      0.111     -1.061      0.289      -0.335       0.100\n",
      "x20           -0.2271      0.095     -2.381      0.017      -0.414      -0.040\n",
      "x21            0.4533      2.924      0.155      0.877      -5.279       6.185\n",
      "x22           -0.0340      2.149     -0.016      0.987      -4.248       4.180\n",
      "x23            0.6018      0.143      4.221      0.000       0.322       0.881\n",
      "x24            0.1793      0.420      0.427      0.669      -0.643       1.002\n",
      "x25            0.2204      1.968      0.112      0.911      -3.638       4.079\n",
      "x26            0.2006      0.118      1.702      0.089      -0.030       0.432\n",
      "x27           -0.0845      0.100     -0.843      0.399      -0.281       0.112\n",
      "x28            0.3303      0.113      2.921      0.004       0.109       0.552\n",
      "x29            0.0511      0.122      0.418      0.676      -0.189       0.291\n",
      "x30            0.5771      0.142      4.056      0.000       0.298       0.856\n",
      "x31            4.4169      0.239     18.510      0.000       3.949       4.885\n",
      "==============================================================================\n",
      "Omnibus:                     6317.233   Durbin-Watson:                   2.024\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           527854.998\n",
      "Skew:                           4.586   Prob(JB):                         0.00\n",
      "Kurtosis:                      46.331   Cond. No.                     2.28e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.28e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "----- Test  ------\n",
      "Mean absolute error: 1.88\n",
      "Mean squared error: 30.23\n",
      "Root mean squared error: 5.50\n",
      "Max error: 59.67\n",
      "Average Error: -0.04\n",
      "---- Training -----\n",
      "Mean absolute error: 1.56\n",
      "Mean squared error: 19.82\n",
      "Root mean squared error: 4.45\n",
      "Max error: 79.14\n",
      "Average Error: -0.02\n",
      "Training score coefficient of determination for XGboost R^2: 0.775 \n",
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.472\n",
      "Model:                            OLS   Adj. R-squared:                  0.469\n",
      "Method:                 Least Squares   F-statistic:                     185.3\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:30:35   Log-Likelihood:                -21535.\n",
      "No. Observations:                6458   AIC:                         4.313e+04\n",
      "Df Residuals:                    6426   BIC:                         4.335e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4418      0.085     28.805      0.000       2.276       2.608\n",
      "x1            -1.2749      0.385     -3.311      0.001      -2.030      -0.520\n",
      "x2             1.4701      0.287      5.116      0.000       0.907       2.034\n",
      "x3             0.6791      0.536      1.268      0.205      -0.371       1.729\n",
      "x4            -4.6992      0.326    -14.424      0.000      -5.338      -4.061\n",
      "x5             9.1077      0.222     41.089      0.000       8.673       9.542\n",
      "x6            -0.4716      0.197     -2.395      0.017      -0.858      -0.086\n",
      "x7           -74.4985     61.355     -1.214      0.225    -194.775      45.778\n",
      "x8             0.4462      0.096      4.642      0.000       0.258       0.635\n",
      "x9            44.2584     36.374      1.217      0.224     -27.047     115.564\n",
      "x10            0.6071      0.468      1.297      0.195      -0.310       1.524\n",
      "x11           59.7929     49.573      1.206      0.228     -37.387     156.973\n",
      "x12           -0.0908      0.088     -1.030      0.303      -0.263       0.082\n",
      "x13           -0.1152      0.097     -1.191      0.234      -0.305       0.074\n",
      "x14           -0.0278      0.269     -0.104      0.917      -0.554       0.499\n",
      "x15           -0.4369      0.175     -2.499      0.012      -0.780      -0.094\n",
      "x16            0.0729      0.183      0.398      0.691      -0.286       0.432\n",
      "x17           -4.0197      0.255    -15.770      0.000      -4.519      -3.520\n",
      "x18            0.1924      0.118      1.627      0.104      -0.039       0.424\n",
      "x19           -0.1443      0.106     -1.361      0.174      -0.352       0.064\n",
      "x20           -0.2051      0.090     -2.283      0.022      -0.381      -0.029\n",
      "x21           -0.8282      2.748     -0.301      0.763      -6.215       4.558\n",
      "x22           -0.8372      2.020     -0.414      0.679      -4.797       3.123\n",
      "x23            0.6164      0.139      4.422      0.000       0.343       0.890\n",
      "x24            0.0084      0.397      0.021      0.983      -0.770       0.787\n",
      "x25           -0.6078      1.850     -0.329      0.743      -4.235       3.019\n",
      "x26            0.0047      0.115      0.041      0.967      -0.220       0.229\n",
      "x27           -0.0432      0.093     -0.462      0.644      -0.226       0.140\n",
      "x28            0.2683      0.110      2.445      0.015       0.053       0.483\n",
      "x29           -0.0081      0.116     -0.070      0.944      -0.236       0.220\n",
      "x30            0.5456      0.140      3.897      0.000       0.271       0.820\n",
      "x31            4.5855      0.238     19.249      0.000       4.119       5.053\n",
      "==============================================================================\n",
      "Omnibus:                     6284.899   Durbin-Watson:                   2.013\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           528552.109\n",
      "Skew:                           4.542   Prob(JB):                         0.00\n",
      "Kurtosis:                      46.379   Cond. No.                     2.31e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.31e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "----- Test  ------\n",
      "Mean absolute error: 1.95\n",
      "Mean squared error: 35.86\n",
      "Root mean squared error: 5.99\n",
      "Max error: 66.19\n",
      "Average Error: -0.40\n",
      "---- Training -----\n",
      "Mean absolute error: 1.74\n",
      "Mean squared error: 27.99\n",
      "Root mean squared error: 5.29\n",
      "Max error: 88.99\n",
      "Average Error: -0.26\n",
      "Training score coefficient of determination for XGboost R^2: 0.680 \n",
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.463\n",
      "Model:                            OLS   Adj. R-squared:                  0.461\n",
      "Method:                 Least Squares   F-statistic:                     179.0\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:30:36   Log-Likelihood:                -21491.\n",
      "No. Observations:                6458   AIC:                         4.305e+04\n",
      "Df Residuals:                    6426   BIC:                         4.326e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4558      0.084     29.170      0.000       2.291       2.621\n",
      "x1            -1.5197      0.382     -3.976      0.000      -2.269      -0.771\n",
      "x2             1.3639      0.286      4.761      0.000       0.802       1.926\n",
      "x3             0.9773      0.531      1.842      0.066      -0.063       2.017\n",
      "x4            -4.8518      0.323    -15.000      0.000      -5.486      -4.218\n",
      "x5             9.1807      0.222     41.426      0.000       8.746       9.615\n",
      "x6            -0.5947      0.195     -3.056      0.002      -0.976      -0.213\n",
      "x7           -19.5075     58.816     -0.332      0.740    -134.806      95.791\n",
      "x8             0.4059      0.092      4.401      0.000       0.225       0.587\n",
      "x9            11.6493     34.870      0.334      0.738     -56.707      80.006\n",
      "x10            0.1138      0.448      0.254      0.800      -0.764       0.992\n",
      "x11           15.4416     47.522      0.325      0.745     -77.717     108.600\n",
      "x12           -0.0887      0.086     -1.028      0.304      -0.258       0.080\n",
      "x13           -0.1177      0.097     -1.216      0.224      -0.307       0.072\n",
      "x14            0.0033      0.265      0.012      0.990      -0.517       0.524\n",
      "x15           -0.2897      0.174     -1.665      0.096      -0.631       0.051\n",
      "x16           -0.0042      0.182     -0.023      0.982      -0.361       0.352\n",
      "x17           -3.3726      0.257    -13.106      0.000      -3.877      -2.868\n",
      "x18            0.2194      0.118      1.851      0.064      -0.013       0.452\n",
      "x19           -0.1696      0.104     -1.636      0.102      -0.373       0.034\n",
      "x20           -0.2955      0.103     -2.875      0.004      -0.497      -0.094\n",
      "x21           -1.5932      2.953     -0.540      0.590      -7.382       4.196\n",
      "x22           -1.4935      2.171     -0.688      0.492      -5.750       2.763\n",
      "x23            0.5798      0.140      4.137      0.000       0.305       0.855\n",
      "x24           -0.1068      0.423     -0.252      0.801      -0.937       0.723\n",
      "x25           -1.1920      1.989     -0.599      0.549      -5.091       2.707\n",
      "x26            0.1617      0.113      1.435      0.151      -0.059       0.383\n",
      "x27            0.0168      0.098      0.171      0.865      -0.176       0.210\n",
      "x28            0.1231      0.102      1.211      0.226      -0.076       0.322\n",
      "x29           -0.0063      0.118     -0.053      0.958      -0.238       0.226\n",
      "x30            0.5652      0.141      4.022      0.000       0.290       0.841\n",
      "x31            3.9371      0.239     16.465      0.000       3.468       4.406\n",
      "==============================================================================\n",
      "Omnibus:                     6238.033   Durbin-Watson:                   2.047\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           479525.379\n",
      "Skew:                           4.521   Prob(JB):                         0.00\n",
      "Kurtosis:                      44.235   Cond. No.                     2.22e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.22e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "----- Test  ------\n",
      "Mean absolute error: 1.93\n",
      "Mean squared error: 33.99\n",
      "Root mean squared error: 5.83\n",
      "Max error: 81.45\n",
      "Average Error: -0.01\n",
      "---- Training -----\n",
      "Mean absolute error: 1.64\n",
      "Mean squared error: 23.35\n",
      "Root mean squared error: 4.83\n",
      "Max error: 87.26\n",
      "Average Error: -0.08\n",
      "Training score coefficient of determination for XGboost R^2: 0.725 \n",
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.465\n",
      "Model:                            OLS   Adj. R-squared:                  0.463\n",
      "Method:                 Least Squares   F-statistic:                     180.3\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:30:36   Log-Likelihood:                -21499.\n",
      "No. Observations:                6458   AIC:                         4.306e+04\n",
      "Df Residuals:                    6426   BIC:                         4.328e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4913      0.084     29.559      0.000       2.326       2.656\n",
      "x1            -1.1981      0.376     -3.184      0.001      -1.936      -0.460\n",
      "x2             1.6022      0.281      5.702      0.000       1.051       2.153\n",
      "x3             0.4455      0.523      0.852      0.394      -0.580       1.471\n",
      "x4            -4.6460      0.324    -14.342      0.000      -5.281      -4.011\n",
      "x5             9.1664      0.223     41.121      0.000       8.729       9.603\n",
      "x6            -0.4363      0.196     -2.228      0.026      -0.820      -0.052\n",
      "x7           -74.4780     61.036     -1.220      0.222    -194.129      45.173\n",
      "x8             0.3849      0.095      4.056      0.000       0.199       0.571\n",
      "x9            44.2766     36.185      1.224      0.221     -26.659     115.212\n",
      "x10            0.5875      0.465      1.263      0.207      -0.324       1.499\n",
      "x11           59.8681     49.316      1.214      0.225     -36.808     156.544\n",
      "x12           -0.0760      0.092     -0.828      0.408      -0.256       0.104\n",
      "x13           -0.1363      0.097     -1.408      0.159      -0.326       0.054\n",
      "x14            0.1507      0.267      0.565      0.572      -0.373       0.674\n",
      "x15           -0.4637      0.176     -2.627      0.009      -0.810      -0.118\n",
      "x16           -0.0971      0.183     -0.532      0.595      -0.455       0.261\n",
      "x17           -3.6490      0.270    -13.502      0.000      -4.179      -3.119\n",
      "x18            0.2197      0.118      1.860      0.063      -0.012       0.451\n",
      "x19           -0.1643      0.104     -1.578      0.115      -0.368       0.040\n",
      "x20           -0.1947      0.092     -2.111      0.035      -0.376      -0.014\n",
      "x21           -0.5212      2.854     -0.183      0.855      -6.117       5.074\n",
      "x22           -0.6831      2.099     -0.325      0.745      -4.798       3.431\n",
      "x23            0.5354      0.144      3.731      0.000       0.254       0.817\n",
      "x24            0.0613      0.410      0.149      0.881      -0.743       0.866\n",
      "x25           -0.4545      1.922     -0.236      0.813      -4.222       3.313\n",
      "x26            0.1959      0.114      1.722      0.085      -0.027       0.419\n",
      "x27           -0.0389      0.096     -0.407      0.684      -0.226       0.149\n",
      "x28            0.2310      0.100      2.305      0.021       0.035       0.428\n",
      "x29            0.0414      0.118      0.351      0.726      -0.190       0.273\n",
      "x30            0.5129      0.140      3.665      0.000       0.239       0.787\n",
      "x31            4.3126      0.255     16.928      0.000       3.813       4.812\n",
      "==============================================================================\n",
      "Omnibus:                     6324.679   Durbin-Watson:                   1.981\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           534387.557\n",
      "Skew:                           4.591   Prob(JB):                         0.00\n",
      "Kurtosis:                      46.608   Cond. No.                     2.30e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.3e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "----- Test  ------\n",
      "Mean absolute error: 2.03\n",
      "Mean squared error: 35.97\n",
      "Root mean squared error: 6.00\n",
      "Max error: 62.95\n",
      "Average Error: 0.03\n",
      "---- Training -----\n",
      "Mean absolute error: 1.67\n",
      "Mean squared error: 24.73\n",
      "Root mean squared error: 4.97\n",
      "Max error: 83.61\n",
      "Average Error: -0.15\n",
      "Training score coefficient of determination for XGboost R^2: 0.710 \n",
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.460\n",
      "Model:                            OLS   Adj. R-squared:                  0.458\n",
      "Method:                 Least Squares   F-statistic:                     176.8\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:30:37   Log-Likelihood:                -21594.\n",
      "No. Observations:                6458   AIC:                         4.325e+04\n",
      "Df Residuals:                    6426   BIC:                         4.347e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4765      0.086     28.933      0.000       2.309       2.644\n",
      "x1            -1.3368      0.395     -3.383      0.001      -2.111      -0.562\n",
      "x2             1.6637      0.287      5.789      0.000       1.100       2.227\n",
      "x3             0.5138      0.545      0.943      0.346      -0.554       1.582\n",
      "x4            -4.7538      0.327    -14.523      0.000      -5.395      -4.112\n",
      "x5             9.2044      0.223     41.194      0.000       8.766       9.642\n",
      "x6            -0.5642      0.198     -2.851      0.004      -0.952      -0.176\n",
      "x7           -34.9349     61.880     -0.565      0.572    -156.240      86.370\n",
      "x8             0.3520      0.095      3.704      0.000       0.166       0.538\n",
      "x9            20.7921     36.686      0.567      0.571     -51.126      92.710\n",
      "x10            0.2669      0.471      0.567      0.571      -0.656       1.190\n",
      "x11           27.9404     49.997      0.559      0.576     -70.070     125.950\n",
      "x12           -0.1003      0.086     -1.161      0.246      -0.270       0.069\n",
      "x13           -0.1144      0.095     -1.199      0.231      -0.301       0.073\n",
      "x14           -0.0311      0.271     -0.115      0.909      -0.561       0.499\n",
      "x15           -0.3157      0.176     -1.793      0.073      -0.661       0.029\n",
      "x16           -0.0591      0.186     -0.318      0.751      -0.424       0.305\n",
      "x17           -2.7323      0.267    -10.223      0.000      -3.256      -2.208\n",
      "x18            0.1699      0.121      1.404      0.160      -0.067       0.407\n",
      "x19           -0.1521      0.108     -1.415      0.157      -0.363       0.059\n",
      "x20           -0.2765      0.108     -2.548      0.011      -0.489      -0.064\n",
      "x21           -1.0213      2.882     -0.354      0.723      -6.671       4.628\n",
      "x22           -0.9998      2.118     -0.472      0.637      -5.152       3.152\n",
      "x23            0.4433      0.143      3.107      0.002       0.164       0.723\n",
      "x24            0.0300      0.414      0.073      0.942      -0.781       0.841\n",
      "x25           -0.7739      1.940     -0.399      0.690      -4.578       3.030\n",
      "x26            0.1316      0.115      1.143      0.253      -0.094       0.357\n",
      "x27           -0.0508      0.102     -0.497      0.620      -0.252       0.150\n",
      "x28            0.1748      0.102      1.713      0.087      -0.025       0.375\n",
      "x29            0.1759      0.117      1.498      0.134      -0.054       0.406\n",
      "x30            0.6018      0.141      4.259      0.000       0.325       0.879\n",
      "x31            3.2616      0.252     12.949      0.000       2.768       3.755\n",
      "==============================================================================\n",
      "Omnibus:                     6425.525   Durbin-Watson:                   1.927\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           559886.986\n",
      "Skew:                           4.708   Prob(JB):                         0.00\n",
      "Kurtosis:                      47.633   Cond. No.                     2.30e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.3e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "----- Test  ------\n",
      "Mean absolute error: 1.87\n",
      "Mean squared error: 27.98\n",
      "Root mean squared error: 5.29\n",
      "Max error: 47.45\n",
      "Average Error: 0.31\n",
      "---- Training -----\n",
      "Mean absolute error: 1.53\n",
      "Mean squared error: 19.07\n",
      "Root mean squared error: 4.37\n",
      "Max error: 82.76\n",
      "Average Error: -0.02\n",
      "Training score coefficient of determination for XGboost R^2: 0.781 \n",
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.465\n",
      "Model:                            OLS   Adj. R-squared:                  0.462\n",
      "Method:                 Least Squares   F-statistic:                     179.9\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:30:37   Log-Likelihood:                -21499.\n",
      "No. Observations:                6458   AIC:                         4.306e+04\n",
      "Df Residuals:                    6426   BIC:                         4.328e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4567      0.084     29.150      0.000       2.291       2.622\n",
      "x1            -1.5959      0.379     -4.214      0.000      -2.338      -0.854\n",
      "x2             1.7601      0.287      6.128      0.000       1.197       2.323\n",
      "x3             0.7492      0.529      1.418      0.156      -0.287       1.785\n",
      "x4            -4.6524      0.324    -14.346      0.000      -5.288      -4.017\n",
      "x5             9.1094      0.222     41.010      0.000       8.674       9.545\n",
      "x6            -0.4297      0.196     -2.190      0.029      -0.814      -0.045\n",
      "x7           -61.7769     60.282     -1.025      0.305    -179.949      56.395\n",
      "x8             0.3873      0.094      4.119      0.000       0.203       0.572\n",
      "x9            36.7342     35.739      1.028      0.304     -33.325     106.794\n",
      "x10            0.4705      0.461      1.020      0.308      -0.434       1.375\n",
      "x11           49.5796     48.706      1.018      0.309     -45.901     145.061\n",
      "x12           -0.0494      0.088     -0.561      0.575      -0.222       0.123\n",
      "x13           -0.1682      0.095     -1.778      0.076      -0.354       0.017\n",
      "x14            0.1376      0.263      0.523      0.601      -0.378       0.653\n",
      "x15           -0.4826      0.174     -2.778      0.005      -0.823      -0.142\n",
      "x16           -0.0341      0.181     -0.188      0.851      -0.389       0.321\n",
      "x17           -3.3082      0.260    -12.721      0.000      -3.818      -2.798\n",
      "x18            0.1837      0.118      1.552      0.121      -0.048       0.416\n",
      "x19           -0.1527      0.106     -1.446      0.148      -0.360       0.054\n",
      "x20           -0.2093      0.090     -2.317      0.021      -0.386      -0.032\n",
      "x21           -2.1557      2.951     -0.731      0.465      -7.940       3.629\n",
      "x22           -1.9827      2.169     -0.914      0.361      -6.235       2.270\n",
      "x23            0.4404      0.143      3.079      0.002       0.160       0.721\n",
      "x24           -0.3130      0.423     -0.740      0.459      -1.142       0.516\n",
      "x25           -1.5401      1.987     -0.775      0.438      -5.436       2.356\n",
      "x26            0.0919      0.127      0.726      0.468      -0.156       0.340\n",
      "x27           -0.0751      0.094     -0.797      0.425      -0.260       0.110\n",
      "x28            0.2787      0.109      2.558      0.011       0.065       0.492\n",
      "x29            0.0183      0.122      0.149      0.882      -0.222       0.258\n",
      "x30            0.6934      0.138      5.011      0.000       0.422       0.965\n",
      "x31            3.9045      0.244     15.984      0.000       3.426       4.383\n",
      "==============================================================================\n",
      "Omnibus:                     6246.010   Durbin-Watson:                   1.983\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           491404.047\n",
      "Skew:                           4.521   Prob(JB):                         0.00\n",
      "Kurtosis:                      44.767   Cond. No.                     2.28e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.28e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "----- Test  ------\n",
      "Mean absolute error: 1.95\n",
      "Mean squared error: 36.56\n",
      "Root mean squared error: 6.05\n",
      "Max error: 91.70\n",
      "Average Error: -0.18\n",
      "---- Training -----\n",
      "Mean absolute error: 1.69\n",
      "Mean squared error: 24.65\n",
      "Root mean squared error: 4.96\n",
      "Max error: 87.85\n",
      "Average Error: -0.15\n",
      "Training score coefficient of determination for XGboost R^2: 0.711 \n",
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.448\n",
      "Model:                            OLS   Adj. R-squared:                  0.445\n",
      "Method:                 Least Squares   F-statistic:                     168.2\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:30:38   Log-Likelihood:                -21562.\n",
      "No. Observations:                6458   AIC:                         4.319e+04\n",
      "Df Residuals:                    6426   BIC:                         4.340e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4736      0.085     29.062      0.000       2.307       2.640\n",
      "x1            -1.5779      0.388     -4.064      0.000      -2.339      -0.817\n",
      "x2             1.6566      0.285      5.811      0.000       1.098       2.215\n",
      "x3             0.8068      0.538      1.499      0.134      -0.248       1.862\n",
      "x4            -4.5576      0.327    -13.931      0.000      -5.199      -3.916\n",
      "x5             8.8539      0.225     39.280      0.000       8.412       9.296\n",
      "x6            -0.5164      0.197     -2.618      0.009      -0.903      -0.130\n",
      "x7           -67.3405     61.192     -1.100      0.271    -187.297      52.616\n",
      "x8             0.2844      0.096      2.955      0.003       0.096       0.473\n",
      "x9            40.0404     36.278      1.104      0.270     -31.077     111.158\n",
      "x10            0.4818      0.467      1.032      0.302      -0.433       1.397\n",
      "x11           53.9546     49.441      1.091      0.275     -42.966     150.875\n",
      "x12           -0.0663      0.090     -0.734      0.463      -0.244       0.111\n",
      "x13           -0.0321      0.098     -0.327      0.743      -0.224       0.160\n",
      "x14            0.0027      0.269      0.010      0.992      -0.525       0.531\n",
      "x15           -0.4253      0.178     -2.386      0.017      -0.775      -0.076\n",
      "x16            0.0178      0.184      0.097      0.923      -0.342       0.378\n",
      "x17           -3.2223      0.276    -11.663      0.000      -3.764      -2.681\n",
      "x18            0.2221      0.120      1.857      0.063      -0.012       0.457\n",
      "x19           -0.1204      0.107     -1.126      0.260      -0.330       0.089\n",
      "x20           -0.2526      0.090     -2.796      0.005      -0.430      -0.075\n",
      "x21           -1.3667      2.913     -0.469      0.639      -7.077       4.343\n",
      "x22           -1.3116      2.142     -0.612      0.540      -5.510       2.887\n",
      "x23            0.4466      0.143      3.125      0.002       0.166       0.727\n",
      "x24           -0.0210      0.418     -0.050      0.960      -0.840       0.798\n",
      "x25           -0.8451      1.961     -0.431      0.667      -4.689       2.999\n",
      "x26            0.1339      0.116      1.155      0.248      -0.093       0.361\n",
      "x27           -0.0732      0.099     -0.738      0.461      -0.268       0.121\n",
      "x28            0.3079      0.112      2.738      0.006       0.087       0.528\n",
      "x29            0.1024      0.121      0.848      0.396      -0.134       0.339\n",
      "x30            0.6866      0.142      4.848      0.000       0.409       0.964\n",
      "x31            3.5774      0.260     13.734      0.000       3.067       4.088\n",
      "==============================================================================\n",
      "Omnibus:                     6444.120   Durbin-Watson:                   1.991\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           555602.597\n",
      "Skew:                           4.736   Prob(JB):                         0.00\n",
      "Kurtosis:                      47.442   Cond. No.                     2.28e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.28e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "----- Test  ------\n",
      "Mean absolute error: 1.92\n",
      "Mean squared error: 28.73\n",
      "Root mean squared error: 5.36\n",
      "Max error: 54.03\n",
      "Average Error: 0.06\n",
      "---- Training -----\n",
      "Mean absolute error: 1.61\n",
      "Mean squared error: 21.65\n",
      "Root mean squared error: 4.65\n",
      "Max error: 83.24\n",
      "Average Error: -0.04\n",
      "Training score coefficient of determination for XGboost R^2: 0.743 \n",
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.463\n",
      "Model:                            OLS   Adj. R-squared:                  0.460\n",
      "Method:                 Least Squares   F-statistic:                     178.8\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:30:39   Log-Likelihood:                -21527.\n",
      "No. Observations:                6458   AIC:                         4.312e+04\n",
      "Df Residuals:                    6426   BIC:                         4.334e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4348      0.085     28.756      0.000       2.269       2.601\n",
      "x1            -1.3637      0.381     -3.575      0.000      -2.111      -0.616\n",
      "x2             1.3570      0.282      4.815      0.000       0.805       1.909\n",
      "x3             0.7756      0.529      1.467      0.143      -0.261       1.812\n",
      "x4            -4.4709      0.325    -13.750      0.000      -5.108      -3.833\n",
      "x5             8.8910      0.220     40.491      0.000       8.461       9.321\n",
      "x6            -0.4491      0.198     -2.271      0.023      -0.837      -0.061\n",
      "x7           -94.2261     61.325     -1.537      0.124    -214.443      25.990\n",
      "x8             0.3994      0.096      4.166      0.000       0.211       0.587\n",
      "x9            55.9917     36.357      1.540      0.124     -15.280     127.263\n",
      "x10            0.6709      0.466      1.439      0.150      -0.243       1.585\n",
      "x11           75.7966     49.547      1.530      0.126     -21.333     172.926\n",
      "x12           -0.1025      0.084     -1.219      0.223      -0.267       0.062\n",
      "x13           -0.0835      0.095     -0.878      0.380      -0.270       0.103\n",
      "x14            0.1543      0.265      0.582      0.561      -0.366       0.674\n",
      "x15           -0.4355      0.175     -2.489      0.013      -0.779      -0.092\n",
      "x16           -0.0970      0.183     -0.529      0.596      -0.456       0.262\n",
      "x17           -3.3517      0.257    -13.061      0.000      -3.855      -2.849\n",
      "x18            0.2043      0.119      1.716      0.086      -0.029       0.438\n",
      "x19           -0.1953      0.107     -1.830      0.067      -0.404       0.014\n",
      "x20           -0.1722      0.090     -1.912      0.056      -0.349       0.004\n",
      "x21           -1.3415      2.941     -0.456      0.648      -7.107       4.424\n",
      "x22           -1.3177      2.162     -0.609      0.542      -5.556       2.921\n",
      "x23            0.5627      0.141      4.001      0.000       0.287       0.838\n",
      "x24           -0.1082      0.418     -0.259      0.796      -0.928       0.712\n",
      "x25           -0.8998      1.983     -0.454      0.650      -4.788       2.988\n",
      "x26            0.1341      0.113      1.189      0.234      -0.087       0.355\n",
      "x27           -0.0766      0.111     -0.692      0.489      -0.294       0.140\n",
      "x28            0.2534      0.112      2.270      0.023       0.035       0.472\n",
      "x29           -0.0265      0.120     -0.221      0.825      -0.261       0.208\n",
      "x30            0.5645      0.140      4.043      0.000       0.291       0.838\n",
      "x31            3.8660      0.241     16.027      0.000       3.393       4.339\n",
      "==============================================================================\n",
      "Omnibus:                     6236.172   Durbin-Watson:                   1.987\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           485268.309\n",
      "Skew:                           4.514   Prob(JB):                         0.00\n",
      "Kurtosis:                      44.496   Cond. No.                     2.30e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.3e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "----- Test  ------\n",
      "Mean absolute error: 1.85\n",
      "Mean squared error: 33.89\n",
      "Root mean squared error: 5.82\n",
      "Max error: 89.22\n",
      "Average Error: -0.16\n",
      "---- Training -----\n",
      "Mean absolute error: 1.56\n",
      "Mean squared error: 19.32\n",
      "Root mean squared error: 4.40\n",
      "Max error: 71.85\n",
      "Average Error: -0.03\n",
      "Training score coefficient of determination for XGboost R^2: 0.775 \n",
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.460\n",
      "Model:                            OLS   Adj. R-squared:                  0.457\n",
      "Method:                 Least Squares   F-statistic:                     176.5\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:30:39   Log-Likelihood:                -21527.\n",
      "No. Observations:                6458   AIC:                         4.312e+04\n",
      "Df Residuals:                    6426   BIC:                         4.333e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4552      0.085     29.007      0.000       2.289       2.621\n",
      "x1            -1.5635      0.387     -4.037      0.000      -2.323      -0.804\n",
      "x2             1.5153      0.286      5.305      0.000       0.955       2.075\n",
      "x3             0.9586      0.535      1.792      0.073      -0.090       2.007\n",
      "x4            -4.6748      0.326    -14.327      0.000      -5.315      -4.035\n",
      "x5             8.9815      0.224     40.063      0.000       8.542       9.421\n",
      "x6            -0.4897      0.196     -2.500      0.012      -0.874      -0.106\n",
      "x7           -89.1469     60.877     -1.464      0.143    -208.486      30.192\n",
      "x8             0.4293      0.097      4.420      0.000       0.239       0.620\n",
      "x9            52.9604     36.091      1.467      0.142     -17.790     123.710\n",
      "x10            0.7147      0.462      1.548      0.122      -0.190       1.619\n",
      "x11           71.6578     49.187      1.457      0.145     -24.765     168.080\n",
      "x12           -0.0932      0.086     -1.079      0.281      -0.262       0.076\n",
      "x13           -0.0779      0.095     -0.817      0.414      -0.265       0.109\n",
      "x14           -0.1740      0.267     -0.652      0.514      -0.697       0.349\n",
      "x15           -0.3623      0.175     -2.066      0.039      -0.706      -0.019\n",
      "x16            0.0834      0.183      0.455      0.649      -0.276       0.443\n",
      "x17           -4.1086      0.257    -15.998      0.000      -4.612      -3.605\n",
      "x18            0.1932      0.118      1.633      0.103      -0.039       0.425\n",
      "x19           -0.0798      0.105     -0.762      0.446      -0.285       0.125\n",
      "x20           -0.2523      0.093     -2.716      0.007      -0.434      -0.070\n",
      "x21           -2.7556      2.808     -0.981      0.326      -8.260       2.749\n",
      "x22           -2.3640      2.065     -1.145      0.252      -6.412       1.684\n",
      "x23            0.4682      0.140      3.353      0.001       0.194       0.742\n",
      "x24           -0.3274      0.405     -0.809      0.418      -1.121       0.466\n",
      "x25           -1.9400      1.892     -1.026      0.305      -5.648       1.768\n",
      "x26            0.0734      0.116      0.634      0.526      -0.153       0.300\n",
      "x27           -0.0747      0.101     -0.740      0.459      -0.272       0.123\n",
      "x28            0.3805      0.126      3.012      0.003       0.133       0.628\n",
      "x29           -0.0080      0.121     -0.066      0.947      -0.246       0.230\n",
      "x30            0.6797      0.141      4.830      0.000       0.404       0.956\n",
      "x31            4.6810      0.240     19.494      0.000       4.210       5.152\n",
      "==============================================================================\n",
      "Omnibus:                     6145.365   Durbin-Watson:                   2.025\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           479650.287\n",
      "Skew:                           4.398   Prob(JB):                         0.00\n",
      "Kurtosis:                      44.293   Cond. No.                     2.29e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.29e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "----- Test  ------\n",
      "Mean absolute error: 1.91\n",
      "Mean squared error: 34.06\n",
      "Root mean squared error: 5.84\n",
      "Max error: 63.92\n",
      "Average Error: -0.06\n",
      "---- Training -----\n",
      "Mean absolute error: 1.57\n",
      "Mean squared error: 19.30\n",
      "Root mean squared error: 4.39\n",
      "Max error: 80.30\n",
      "Average Error: -0.02\n",
      "Training score coefficient of determination for XGboost R^2: 0.773 \n",
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.454\n",
      "Model:                            OLS   Adj. R-squared:                  0.452\n",
      "Method:                 Least Squares   F-statistic:                     172.7\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:30:40   Log-Likelihood:                -21557.\n",
      "No. Observations:                6458   AIC:                         4.318e+04\n",
      "Df Residuals:                    6426   BIC:                         4.339e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4458      0.085     28.759      0.000       2.279       2.613\n",
      "x1            -1.4243      0.389     -3.660      0.000      -2.187      -0.661\n",
      "x2             1.5052      0.282      5.330      0.000       0.952       2.059\n",
      "x3             0.8084      0.530      1.524      0.128      -0.232       1.848\n",
      "x4            -4.6124      0.326    -14.130      0.000      -5.252      -3.972\n",
      "x5             8.9218      0.222     40.128      0.000       8.486       9.358\n",
      "x6            -0.5147      0.199     -2.591      0.010      -0.904      -0.125\n",
      "x7           -88.3446     60.092     -1.470      0.142    -206.145      29.456\n",
      "x8             0.4903      0.095      5.157      0.000       0.304       0.677\n",
      "x9            52.5070     35.626      1.474      0.141     -17.331     122.345\n",
      "x10            0.6675      0.459      1.454      0.146      -0.233       1.568\n",
      "x11           71.0997     48.551      1.464      0.143     -24.077     166.277\n",
      "x12           -0.1102      0.092     -1.193      0.233      -0.291       0.071\n",
      "x13           -0.1681      0.096     -1.748      0.080      -0.357       0.020\n",
      "x14           -0.0016      0.266     -0.006      0.995      -0.523       0.519\n",
      "x15           -0.2975      0.174     -1.708      0.088      -0.639       0.044\n",
      "x16           -0.1434      0.183     -0.782      0.434      -0.503       0.216\n",
      "x17           -2.8913      0.267    -10.836      0.000      -3.414      -2.368\n",
      "x18            0.1969      0.119      1.659      0.097      -0.036       0.430\n",
      "x19           -0.1263      0.105     -1.201      0.230      -0.332       0.080\n",
      "x20           -0.2174      0.091     -2.383      0.017      -0.396      -0.039\n",
      "x21           -0.1764      2.905     -0.061      0.952      -5.870       5.517\n",
      "x22           -0.3634      2.135     -0.170      0.865      -4.549       3.823\n",
      "x23            0.5100      0.139      3.669      0.000       0.237       0.783\n",
      "x24            0.1099      0.418      0.263      0.792      -0.709       0.929\n",
      "x25           -0.2010      1.955     -0.103      0.918      -4.034       3.632\n",
      "x26            0.1661      0.115      1.443      0.149      -0.060       0.392\n",
      "x27           -0.1374      0.101     -1.359      0.174      -0.336       0.061\n",
      "x28            0.2054      0.114      1.798      0.072      -0.019       0.429\n",
      "x29            0.1381      0.124      1.110      0.267      -0.106       0.382\n",
      "x30            0.7306      0.143      5.118      0.000       0.451       1.010\n",
      "x31            3.3742      0.254     13.304      0.000       2.877       3.871\n",
      "==============================================================================\n",
      "Omnibus:                     6372.456   Durbin-Watson:                   1.983\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           524108.935\n",
      "Skew:                           4.664   Prob(JB):                         0.00\n",
      "Kurtosis:                      46.136   Cond. No.                     2.25e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.25e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "----- Test  ------\n",
      "Mean absolute error: 1.89\n",
      "Mean squared error: 29.65\n",
      "Root mean squared error: 5.45\n",
      "Max error: 64.21\n",
      "Average Error: -0.19\n",
      "---- Training -----\n",
      "Mean absolute error: 1.66\n",
      "Mean squared error: 24.44\n",
      "Root mean squared error: 4.94\n",
      "Max error: 88.05\n",
      "Average Error: -0.10\n",
      "Training score coefficient of determination for XGboost R^2: 0.713 \n",
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.469\n",
      "Model:                            OLS   Adj. R-squared:                  0.467\n",
      "Method:                 Least Squares   F-statistic:                     183.2\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:30:41   Log-Likelihood:                -21564.\n",
      "No. Observations:                6458   AIC:                         4.319e+04\n",
      "Df Residuals:                    6426   BIC:                         4.341e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4787      0.085     29.112      0.000       2.312       2.646\n",
      "x1            -1.2958      0.381     -3.405      0.001      -2.042      -0.550\n",
      "x2             1.4731      0.285      5.161      0.000       0.914       2.033\n",
      "x3             0.6458      0.527      1.226      0.220      -0.387       1.679\n",
      "x4            -4.6248      0.326    -14.198      0.000      -5.263      -3.986\n",
      "x5             9.0263      0.221     40.795      0.000       8.593       9.460\n",
      "x6            -0.4631      0.199     -2.331      0.020      -0.853      -0.074\n",
      "x7          -127.2859     60.963     -2.088      0.037    -246.794      -7.778\n",
      "x8             0.4384      0.095      4.596      0.000       0.251       0.625\n",
      "x9            75.5832     36.142      2.091      0.037       4.732     146.434\n",
      "x10            0.9730      0.465      2.093      0.036       0.062       1.884\n",
      "x11          102.4485     49.256      2.080      0.038       5.889     199.008\n",
      "x12           -0.1106      0.091     -1.221      0.222      -0.288       0.067\n",
      "x13           -0.0833      0.096     -0.870      0.384      -0.271       0.104\n",
      "x14            0.1472      0.267      0.551      0.582      -0.377       0.671\n",
      "x15           -0.5081      0.177     -2.868      0.004      -0.855      -0.161\n",
      "x16           -0.0672      0.183     -0.366      0.714      -0.427       0.292\n",
      "x17           -4.1619      0.263    -15.839      0.000      -4.677      -3.647\n",
      "x18            0.2305      0.119      1.931      0.054      -0.004       0.465\n",
      "x19           -0.1935      0.105     -1.835      0.067      -0.400       0.013\n",
      "x20           -0.2261      0.089     -2.540      0.011      -0.401      -0.052\n",
      "x21           -0.1944      2.910     -0.067      0.947      -5.899       5.510\n",
      "x22           -0.3913      2.139     -0.183      0.855      -4.585       3.803\n",
      "x23            0.5905      0.143      4.115      0.000       0.309       0.872\n",
      "x24            0.1630      0.418      0.390      0.697      -0.656       0.982\n",
      "x25           -0.2284      1.959     -0.117      0.907      -4.069       3.612\n",
      "x26            0.2249      0.114      1.973      0.049       0.001       0.448\n",
      "x27           -0.1406      0.111     -1.268      0.205      -0.358       0.077\n",
      "x28            0.4541      0.129      3.529      0.000       0.202       0.706\n",
      "x29            0.0088      0.121      0.073      0.942      -0.228       0.245\n",
      "x30            0.4926      0.142      3.465      0.001       0.214       0.771\n",
      "x31            4.7285      0.245     19.285      0.000       4.248       5.209\n",
      "==============================================================================\n",
      "Omnibus:                     6025.213   Durbin-Watson:                   1.988\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           426013.305\n",
      "Skew:                           4.291   Prob(JB):                         0.00\n",
      "Kurtosis:                      41.853   Cond. No.                     2.27e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.27e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "----- Test  ------\n",
      "Mean absolute error: 1.88\n",
      "Mean squared error: 32.97\n",
      "Root mean squared error: 5.74\n",
      "Max error: 78.55\n",
      "Average Error: -0.18\n",
      "---- Training -----\n",
      "Mean absolute error: 1.77\n",
      "Mean squared error: 27.81\n",
      "Root mean squared error: 5.27\n",
      "Max error: 90.47\n",
      "Average Error: -0.22\n",
      "Training score coefficient of determination for XGboost R^2: 0.683 \n",
      "[5.52276170680194, 5.354709739356551, 5.830319664659594, 5.50391600275745, 6.525342389494321, 6.421281183791364, 6.112759229222091, 5.553393429597215, 6.3533409875908715, 5.498365613453579, 5.988631230644568, 5.829762446328754, 5.997884616819545, 5.2893562309888145, 6.046739649766213, 5.3597241853627535, 5.82182312865035, 5.836127819634993, 5.445293783691487, 5.741601509753883]\n",
      "[4.91125765223444, 4.904257257118906, 5.360418089686869, 4.3080885397238955, 4.646612945417973, 5.411840246570944, 4.578658308896622, 4.588185427830352, 4.8432213127919175, 4.451620112794085, 5.29034837382644, 4.832171583019945, 4.972911951870441, 4.366775425637222, 4.964971991017466, 4.652538353354358, 4.39545215249925, 4.3928166756774525, 4.9434793810387445, 5.273581904555825]\n",
      "[30.50089687011787, 28.6729163927599, 33.99262739211637, 30.293091365409538, 42.58009330013146, 41.23285204131302, 37.365825394439845, 30.840178583893522, 40.36494170460215, 30.232024419208756, 35.863704016651475, 33.98613018062502, 35.974619876680535, 27.977289338300192, 36.56306039205482, 28.72664334316243, 33.89362454128815, 34.0603879271175, 29.651224390709157, 32.965987896808066]\n",
      "[24.120451726631337, 24.051739244003453, 28.734082096242222, 18.55962686610037, 21.591011864525893, 29.288014854405052, 20.964111909628077, 21.051445520154786, 23.456792684681865, 19.816921628632826, 27.987785916448058, 23.349882207745477, 24.729853281055878, 19.06872761794914, 24.650946871587934, 21.646113129433278, 19.319999624910295, 19.296838346109908, 24.437988390755212, 27.81066610405864]\n",
      "[1.9182844464179787, 1.8496831697258314, 1.970031479456097, 1.89674545727425, 2.098737463107733, 2.031499684755438, 1.8666786750183197, 1.8513431098523265, 2.0032835834655156, 1.8845608710830322, 1.945754580269817, 1.9303129403113721, 2.0307531084375423, 1.8681750812241336, 1.952268252754674, 1.9179829992429993, 1.8494114934285992, 1.9095828441630252, 1.8938952680735113, 1.879183025615157]\n",
      "[1.6826531862477243, 1.6424059279806478, 1.7796230961557655, 1.5188807532214073, 1.600119995035807, 1.7972501693253646, 1.5949392128007072, 1.6055572086978984, 1.639016081460319, 1.5635538651660825, 1.7377952977389648, 1.6363031478567152, 1.6679747266809146, 1.5334104595454856, 1.6947384535625307, 1.6074057811000266, 1.5551999049797023, 1.5746059652367332, 1.6627370497608205, 1.774714996409645]\n"
     ]
    }
   ],
   "source": [
    "# Split X and y from dataframe features\n",
    "X = df[features]\n",
    "display(X)\n",
    "y = df[\"DAM_perc_dmg\"]\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "train_RMSE_list=[]\n",
    "test_RMSE_list=[]\n",
    "\n",
    "train_MSE_list=[]\n",
    "test_MSE_list=[]\n",
    "\n",
    "train_MAE_list=[]\n",
    "test_MAE_list=[]\n",
    "\n",
    "train_AVE_list=[]\n",
    "test_AVE_list=[]\n",
    "\n",
    "for i in range(20):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled,df['DAM_perc_dmg'], stratify=y_input_strat, test_size=0.2)\n",
    "\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_test.shape, y_test.shape)\n",
    "    \n",
    "    #XGBoost\n",
    "    #xgb = XGBRegressor(n_estimators=100, max_depth=4, learning_rate=0.1, gamma=1, reg_lambda=0.1, colsample_bytree=0.8)\n",
    "    #xgb_model=xgb.fit(X_train, y_train)\n",
    "    \n",
    "     \n",
    "    #XGBoost Reduced Overfitting \n",
    "    xgb = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.8,\n",
    "                       colsample_bynode=0.8, colsample_bytree=0.8, gamma=3, eta=0.01,\n",
    "                       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
    "                       max_depth=4, min_child_weight=1, missing=1, n_estimators=100, early_stopping_rounds=10,\n",
    "                       n_jobs=1, nthread=None, objective='reg:squarederror', random_state=0,\n",
    "                       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "                       silent=None, subsample=0.8, verbosity=1, eval_metric=[\"rmse\", \"logloss\"]\n",
    "                      )\n",
    "\n",
    "    eval_set = [(X_test, y_test)]\n",
    "    xgb_model=xgb.fit(X_train, y_train, eval_set=eval_set, verbose=False)\n",
    "    \n",
    "    \n",
    "    X2 = sm.add_constant(X_train)\n",
    "    est = sm.OLS(y_train, X2)\n",
    "    est2 = est.fit()\n",
    "    print(est2.summary())\n",
    "    \n",
    "    \n",
    "    y_pred_train = xgb.predict(X_train)\n",
    "    mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    mx_train = max_error(y_train, y_pred_train)\n",
    "    me_train = (y_pred_train - y_train).sum()/len(y_train)\n",
    "\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mx = max_error(y_test, y_pred)\n",
    "    me = (y_pred - y_test).sum()/len(y_test)\n",
    "\n",
    "    print('----- Test  ------')\n",
    "    print(f'Mean absolute error: {mae:.2f}')\n",
    "    print(f'Mean squared error: {mse:.2f}')\n",
    "    print(f'Root mean squared error: {rmse:.2f}')\n",
    "    print(f'Max error: {mx:.2f}')\n",
    "    print(f\"Average Error: {me:.2f}\")\n",
    "\n",
    "    print('---- Training -----')\n",
    "    print(f'Mean absolute error: {mae_train:.2f}')\n",
    "    print(f'Mean squared error: {mse_train:.2f}')\n",
    "    print(f'Root mean squared error: {rmse_train:.2f}')\n",
    "    print(f'Max error: {mx_train:.2f}')\n",
    "    print(f\"Average Error: {me_train:.2f}\")\n",
    "   \n",
    "     \n",
    "    score = xgb.score(X_train, y_train)  \n",
    "    print(\"Training score coefficient of determination for XGboost R^2: %.3f \" % (score))\n",
    "    \n",
    "    \n",
    "    test_RMSE_list.append(rmse)\n",
    "    train_RMSE_list.append(rmse_train)\n",
    "    \n",
    "    test_MSE_list.append(mse)\n",
    "    train_MSE_list.append(mse_train)\n",
    "    \n",
    "    test_MAE_list.append(mae)\n",
    "    train_MAE_list.append(mae_train)\n",
    "    \n",
    "    test_AVE_list.append(me)\n",
    "    train_AVE_list.append(me_train)\n",
    "    \n",
    "print(test_RMSE_list)    \n",
    "print(train_RMSE_list) \n",
    "\n",
    "print(test_MSE_list)    \n",
    "print(train_MSE_list)\n",
    "\n",
    "print(test_MAE_list)    \n",
    "print(train_MAE_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b6044205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date and time : \n",
      "2022-11-10 02:30:41\n"
     ]
    }
   ],
   "source": [
    "#the End time of running the model 20 times\n",
    "now = datetime.datetime.now()\n",
    "print (\"Current date and time : \")\n",
    "print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "52322be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stdev_AVERAGE_test: 0.17\n",
      "stdev_AVERAGE_train: 0.09\n",
      "mean_AVERAGE_test: -0.11\n",
      "mean_AVERAGE_train: -0.11\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAuTklEQVR4nO3deXhU5fn/8fdtRNmsKAFlNZYqliJGBAXEFuoKRVuVqrRSccOltnr9inWpqHWrS7V8rXVrtSgWBFGqWGwBCy5FRcSIiICoUWJUIAqyKuD9++Oc4DCcSSbJzJxJ8nld11w5y3Oe554zk3PP2Z5j7o6IiEiyneIOQERE8pMShIiIRFKCEBGRSEoQIiISSQlCREQiKUGIiEgkJYg8ZmalZnZUinlHmNmSXMeUTyzwdzP73MzmprnMWDO7IduxNQaJ308zu9LM/pbButeZ2bfD4Yx+ZmZ2r5mNzlR9DZkSRD3l7i+4e9fqypnZtWb2SC5iikF/4Gigo7sfmjzTzEaY2YvZDiLcgG0xs/bheIdwvEtE2Slm9sdw2M1sfbgxrHz9Npx3rZltDqetNrM5Zta3uraT5h1tZrPMbK2ZVZhZiZldZmZNI9qofK2uzTpw95vc/ZzqypnZbDOrtpy7t3T392oTS1J7O3wH3P18d7++rnU3BkoQUmtmtnPMIewDlLr7+rgCMLMWwMnAGuDnAO7+EfAsMDyp7J7AYOChhMkHhRvDytetCfMmuntLoBCYBTxWXdsJ834KTAbGA/u4e2vgVKAj0Cm5jYRXq1qshozJg++UJHJ3vfL0BZQCo4AFBBuBiUDTcN4AoCyh7GXAR8BaYAlwJHAc8BWwGVgHvBGWbQ88BXwGLAPOTainGcEG7HPgbeC3Se2Uhm0tAL4EdgYuB94N214EnJhQfgTwP+BPwGrgPaBfOH05sAI4o4p1EBkrcDawCdgavrffJy333aT5q8PpY4G/AP8K430F6JKw3AHAjLC9JcAp1XxGvwjfx8XAwoTpPwPeTSp7ITA/YdyB76So91rgkYTxbmH5Nmm0beH031QT+3ZtpPF9HA58AFQAvwu/C0cl1wU0BR4Jy60GXgX2Am4MP49N4WdyV8J6+CXwDvB+8roJP7N7w89lLfAcQdIDKArL7pwQ52zgnGq+AzcklD83/G59Fn7X2id9RueHsX0efncs7m1Drl6xB6BXFR9O8A84l2AjuSfBBvv8cN4Awg030DXcILQPx4sIN3pRG4HwH+zu8B+5GFgJHBnOuzmcvwfBr80F7JggSgh+hTYLp/00jHEngl+p64F24bwRwBbgTKAAuAH4MPxH2xU4Jvynb5liHVQV6wjgxSrW3w7zw43DZ8ChBMntH8Cj4bwW4Xo8M5zXE1gFfK+KNp4FbiXYAG4BeobTmxEk9f4JZV8CLkkYTytBALuEn8sqtt8Qpmr7gLDuomq+Xzt8N6oo241gI/v98HO7I2wzKkGcB0wFmoef+SHAt8J5s4Fzkup2go3/ngnfqeQEsTah7f+r/FypIkFU8x24IRz+Ybhee4Z1/xl4Pim2p4FWQGeC799xcW8bcvXSIab8d6e7l7v7ZwT/dMURZbYSfLm7mVkTdy9193ejKjOzTgTH7i9z903uXgL8jW8Oh5wC3OTun7t7GXBnipiWu/tGAHd/LIzxa3efSPBrK/GcwPvu/nd330qwF9QJuM7dv3T36QR7Od+pRay19YS7z3X3LQQJojicPoTgkNXf3X2Lu88HHgeGRlViZp2BgcB4d/+UYIN9BkC4bh4j+JWPme1HsKEcn1TN/PAcQ+Xr2IR5p4TnBDYS/ModGsZcZdsEh6QAPkmI9dGw/g1mlrj+Tklqf1aKdTYUeNrdn3f3L4HRwNcpym4GWhNs4Le6+2vu/kWKspX+4O6fVX6nIvwroe3fAX3D70dd/Rx40N3nh3VfEdZdlFDmZndf7e4fEhzqK85Au/WCEkT++yRheAPQMrmAuy8DLiH4Fbci3BjscNIy1B74zN3XJkz7AOiQMH95wrzE4chpZvaL8ATo6nCD1p1vNlIAnyYMVyaV5Gk7vK80Yq2tVOt0H+CwxA0mwQZk7xT1DAfeDhMXBMnmZ2bWJBx/iGAD3DQs+293X5FUR093b5Xw+k/CvEkenBPYC1hIkGDSabsinNausrC7nxbWNZ/gV/12bSS8BqZ4r9t9Lzw471ORouw44D/Ao2ZWbma3JqyTVKK+Z5Hz3X0dwV5gqu94TbQn+E4l1l3B9t+xav8HGyoliAbC3ce7e3+CjZwDt1TOSipaDuxpZrslTOtMcP4C4GOCQ0uVon6lbavTzPYB/gpcBLQON0ILCY6D11V1sVanpl0VLweeS9pgtnT3C1KU/wXwbTP7xMw+ITjsUggMguBKM4KNzY+B04GHaxgPYT2rCA7bXGtmlRv9qtpeTLCOTqpNeyl8TMJ3wcyaE+wlRMW72d1/7+7dCM43DQnjhdSfSXWfVWLbLQkOR5UTHM6E4HBWpcSEXl295QT/M5V1tyB4X+l+xxo0JYgGwMy6mtkPzWxXgpNyGwkOO0Hw673IzHYCcPflwBzgD2bW1Mx6EJzw/UdYfhJwhZntYWYdCDb8VWlB8E+4MozlTII9iDpLI9bqfAp0NLNd0iz/NLC/mQ03sybhq7eZfTe5YHjJaReCQ2nF4as7wSGkMxKKPkyQrFsRHCKsFXdfTPCr/LfVte3uDvwGuMbMzg0/SwsPc+1VyxAmA0PMrH+4Pq8jxfbDzAaa2YFmVgB8QXDIKfH7+O1atD84oe3rgVfCw5wrCTbmp5tZgZmdRbBuKlX3HRgPnGlmxeH/z01h3aW1iLHBUYJoGHblm5OYnwBtgSvDeZWXRlaY2fxweBjByb1yYApwjbvPCOddB5QB7wMzCTYMX6Zq2N0XAbcTnID9FDiQ4KqlTKkq1ur8F3gL+MTMVlVXODyUdQxwWtjeJwQb910jip8BPOnub7r7J5UvghOoQ8JLWiFIEJ0JLieNWo9vJN2HMKaKEG8DRhKcj6iy7fBc0CkEey7LCb4bk4D72f5y2VOT2l9nZm0j1s1bBFcajSfYm/ic4HsSZW+C780XBBdWPEdwVRNhjEMtuLkx6vxWKuOBawgOLR3C9pf1ngtcSrC39j2CHxWVqvwOuPuzBOdTHg/fVxeCz18IL9cSScXMLgBOc/cfxB2LiOSW9iBkO2bWzswON7OdzKwrwaGKKXHHJSK5p7sWJdkuwH3AvgQ3OT1KcB+CiDQyOsQkIiKRdIhJREQiNahDTIWFhV5UVBR3GLW3ZAlLNnaCZs3pWm0/rSIidffaa6+tcvc2UfMaVIIoKipi3rx5cYdRewMGMKBkDBQXM3t23MGISGNgZh+kmqdDTCIiEqlB7UHUe1ddxVXzvw76lRQRiZkSRD456iiOinzAqIhI7ilB5JOSEkqWNIOuXSkujjsYkdzYvHkzZWVlbNq0Ke5QGrSmTZvSsWNHmjSprmPdbyhB5JNLLuGSkjFQjE5SS6NRVlbGbrvtRlFREWaZ6ARYkrk7FRUVlJWVse+++6a9nE5Si0isNm3aROvWrZUcssjMaN26dY330pQgRCR2Sg7ZV5t1rAQhIiKRlCBERCSSTlLnk5tu4qY3C4JH7jQiZw8/iRXlpRmpq237Ih4Y90RG6pLGw8w4/fTTGTduHABbtmyhXbt2HHbYYTz99NNZb3/MmDGMHDmS5s2bV184yT//+U/2339/unXrlvG4lCDySb9+9OsXdxC5t6K8lKmjO1RfMA3HX1+akXqkcWnRogULFy5k48aNNGvWjBkzZtChQ2a+k+kYM2YMp59+eq0TxJAhQ7KSIHSIKZ/MmcOc+95kzpzqi4o0WAMG7Pi6O3wkyYYN0fPHjg3mr1q147w0DRo0iH/9618ATJgwgWHDhm2bt379es466yx69+7NwQcfzJNPPglAaWkpRxxxBD179qRnz57MCf95Z8+ezYABAxg6dCgHHHAAP//5z0n1aIU777yT8vJyBg4cyMCBAwGYPn06ffv2pWfPnvz0pz9l3bp1AFx++eV069aNHj16MGrUKObMmcNTTz3FpZdeSnFxMe+++27a7zcdShD55MorufKyrVx5ZfVFRSSzTjvtNB599FE2bdrEggULOOyww7bNu/HGG/nhD3/Iq6++yqxZs7j00ktZv349bdu2ZcaMGcyfP5+JEyfy61//etsyr7/+OmPGjGHRokW89957/O9/0Y9q//Wvf0379u2ZNWsWs2bNYtWqVdxwww3MnDmT+fPn06tXL+644w4+++wzpkyZwltvvcWCBQu46qqr6NevHyeccAK33XYbJSUldOnSJaPrJGuHmMzsQWAIsMLdu4fTJgKVHVm3Ala7e3HEsqXAWmArsMXde2UrThHJM1XdJdq8edXzCwtrfZdpjx49KC0tZcKECQwePHi7edOnT+epp57ij3/8IxDcu/Hhhx/Svn17LrroIkpKSigoKGDp0qXbljn00EPp2LEjAMXFxZSWltK/f/9q43j55ZdZtGgRhx9+OABfffUVffv25Vvf+hZNmzblnHPO4Uc/+hFDhgyp1fusiWyegxgL3AU8XDnB3U+tHDaz24E1VSw/0N1XZS06EZEkJ5xwAqNGjWL27NlUVFRsm+7uPP7443RNelDLtddey1577cUbb7zB119/TdOmTbfN23XXXbcNFxQUsGXLlrRicHeOPvpoJkyYsMO8uXPn8uyzz/Loo49y11138d///remb7FGsnaIyd2fBz6LmmfBHRunADuuARGRmJx11llcffXVHHjg9pcSHnvssfz5z3/edh7h9ddfB2DNmjW0a9eOnXbaiXHjxrF169Zatbvbbruxdu1aAPr06cP//vc/li1bBsCGDRtYunQp69atY82aNQwePJgxY8ZQUlKyw7KZFtc5iCOAT939nRTzHZhuZq+Z2ciqKjKzkWY2z8zmrVy5MuOBikjj0bFjRy6++OIdpo8ePZrNmzfTo0cPunfvzujRowG48MILeeihh+jTpw9Lly6lRYsWtWp35MiRDBo0iIEDB9KmTRvGjh3LsGHD6NGjB3369GHx4sWsXbuWIUOG0KNHD37wgx/wpz/9CQjOndx2220cfPDBGT9JbanOrGekcrMi4OnKcxAJ0+8Blrn77SmWa+/u5WbWFpgB/CrcI6lSr169vF4/Ua6R9uZ6/JE9M3iZ60dMfXZ+RuqS3Hj77bf57ne/G3cYjULUujaz11Kd5835fRBmtjNwEnBIqjLuXh7+XWFmU4BDgWoTRL1XXNyoEoOI5Lc4bpQ7Cljs7mVRM82sBbCTu68Nh48BrstlgLGZOZOZ8/eEnj314CCRBujEE0/k/fff327aLbfcwrHHHhtTRFXL5mWuE4ABQKGZlQHXuPsDwGkknZw2s/bA39x9MLAXMCXseXBnYLy7/ztbceaVG27ghvB5EEoQIg3PlClT4g6hRrKWINx9WIrpIyKmlQODw+H3gIOyFZeIiKRHd1KLiEgkJQgREYmkBCEiIpGUIPLJffdx34Rvcd99cQci0riYGcOHD982vmXLFtq0aZOT/o4g6O57w4YNNV7u6quvZubMmVmIKKDnQeSTrl1J6upFRHIgn58HsXXrVgoKCiKXu+667N4BoD2IfDJ1KlNHz2Xq1LgDEYlPTI+DyKvnQbRs2ZKrr76aww47jJdeeonrrruO3r170717d0aOHLmtrhEjRjB58mQAioqKuOaaa+jZsycHHnggixcvTv/Np6AEkU9uv53b/7wLt0d2QCIi2ZQvz4OAICF1796dV155hf79+3PRRRfx6quvbtvLSfUY1MLCQubPn88FF1ywrWvyutAhJhHJKzE9DiJvngcBQffgJ5988rbxWbNmceutt7JhwwY+++wzvve973H88cfvsNxJJ50EwCGHHMITT9T92exKECIioXx4HgRA06ZNt5132LRpExdeeCHz5s2jU6dOXHvttWzatClyuco2a9peKjrEJCISyofnQSSrTAaFhYWsW7du2zmHXFCCEBEJ5cPzIJK1atWKc889lwMPPJCf/OQn9O7du1Zt1EZWnweRa/X+eRDLl7O8vADat6dTp7iDyR09D6Jx0/MgcifvnwchVejUqVElBhHJb0oQ+WTiRCbO6QT9+nHqqXEHIyKZpudBSO3dcw/3lIyBN1CCEGmA6tvzIHSSWkREIilBiIhIJCUIERGJpAQhInmlXcfOmFnGXu06dq6yvdWrV3N3ZW+ANVTbbrrrC52kzieTJzO5wqB13IGIxOeTj5azz2XRndHVxge3VP1Mh8oEceGFF9a47qq66W4IspYgzOxBYAiwwt27h9OuBc4FVobFrnT3aRHLHgf8H1AA/M3db85WnHmlsJDCwriDEGlcLr/8ct59912Ki4s5+uijadu2LZMmTeLLL7/kxBNP5Pe//z3r16/nlFNOoaysjK1btzJ69Gg+/fTTbd10FxYWbuuJtSHJ5h7EWOAu4OGk6X9y95T90JpZAfAX4GigDHjVzJ5y90XZCjRvjB3L2Be/A/37M2JE3MGINA4333wzCxcupKSkhOnTpzN58mTmzp2Lu3PCCSfw/PPPs3LlStq3b7/teRFr1qxh991354477mDWrFkUNtBfdlk7B+HuzwOf1WLRQ4Fl7v6eu38FPAr8OKPB5auxYxk7ueW2h5+ISG5Nnz6d6dOnc/DBB9OzZ08WL17MO++8w4EHHsjMmTO57LLLeOGFF9h9993jDjUn4jgHcZGZ/QKYB/zG3T9Pmt8BWJ4wXgYcRgpmNhIYCdC5c9Uno0REquLuXHHFFZx33nk7zHvttdeYNm0aV1xxBccccwxXX311DBHmVq6vYroH6AIUAx8DUc9Os4hpKXsUdPf73b2Xu/dq06ZNRoIUkcYjsavtY489lgcffJB169YB8NFHH7FixQrKy8tp3rw5p59+OqNGjWL+/Pk7LNsQ5XQPwt0/rRw2s78CUZcqlAGJXdZ1BMqzHJqI5Im9O3Sq9sqjmtZXldatW3P44YfTvXt3Bg0axM9+9jP69u0LBM+GfuSRR1i2bBmXXnopO+20E02aNOGee+4Bvummu127djpJXVdm1s7dPw5HTwQWRhR7FdjPzPYFPgJOA36WoxBFJGYfl32Y8zbHjx+/3XjyMyG6dOkS2aHer371K371q19lNbY4ZfMy1wnAAKDQzMqAa4ABZlZMcMioFDgvLNue4HLWwe6+xcwuAv5DcJnrg+7+VrbizCvTpjFtA9AwL6kWkXomawnC3YdFTH4gRdlyYHDC+DRgh/sjGrzmzWmg99uISD2krjbyyd13c/dpz1HLu/5FRDJKCSKfTJrEpH/vzqRJcQciIqIEISIiKShBiIhIJPXmKiJ55ezhJ7GivDRj9bVtX8QD455IOX/16tWMHz++xr25Dh48mPHjx9OqVas6Rpi/lCBEJK+sKC9l6ugOGavv+OtLq5yfqrvvrVu3UlBQkHK5adMa/oWWShD5ZPZsZscdg0gjk9jdd5MmTWjZsiXt2rWjpKSERYsW8ZOf/ITly5ezadMmLr74YkaOHAlAUVER8+bNY926dQwaNIj+/fszZ84cOnTowJNPPkmzZs1ifmd1p3MQItKo3XzzzXTp0oWSkhJuu+025s6dy4033siiRcETBh588EFee+015s2bx5133klFRcUOdbzzzjv88pe/5K233qJVq1Y8/vjjuX4bWaEEkU/++Ef+OGQ2f0z5tAwRybZDDz2Ufffdd9v4nXfeyUEHHUSfPn1Yvnw577zzzg7L7LvvvhQXFwNwyCGHUFpamqNos0sJIp88/TRPv9iKpzP3tEURqaEWLVpsG549ezYzZ87kpZde4o033uDggw9m06ZNOyyz6667bhsuKChgy5YtOYk125QgRKRRq6rL7jVr1rDHHnvQvHlzFi9ezMsvv5zj6OKlk9Qiklfati+q9sqjmtZXlcTuvps1a8Zee+21bd5xxx3HvffeS48ePejatSt9+vTJWFz1gRKEiOSVqu5ZyJbk7r4r7brrrjzzzDOR8yrPMxQWFrJw4TdPLhg1alTG44uLEkQ+adaMZk02Q/2/Ok5EGgAliHzyzDNE/1YREck9naQWkdi5p3zsvGRIbdaxEkQ+uf56rj9yNtdfH3cgIrnTtGlTKioqlCSyyN2pqKigadOmNVpOh5jyybPP8mzJ8bAVRo+OOxiR3OjYsSNlZWWsXLky7lAatKZNm9KxY8caLaMEISKxatKkyXZ3Lkv+yNohJjN70MxWmNnChGm3mdliM1tgZlPMrFWKZUvN7E0zKzGzedmKUUREUsvmOYixwHFJ02YA3d29B7AUuKKK5Qe6e7G798pSfCIiUoWsJQh3fx74LGnadHev7KTkZaBmB8Qautatad1iE61bxx2IiEi85yDOAiammOfAdDNz4D53vz9VJWY2EhgJ0Llz54wHmVOPP07D6CRYRBqCWC5zNbPfAVuAf6Qocri79wQGAb80s++nqsvd73f3Xu7eq02bNlmIVkSkccp5gjCzM4AhwM89xYXP7l4e/l0BTAEOzV2EMbriCq7oO5srqjozIyKSIzlNEGZ2HHAZcIK7b0hRpoWZ7VY5DBwDLIwq2+C89BIvvd2Kl16KOxARkexe5joBeAnoamZlZnY2cBewGzAjvIT13rBsezOrfAL4XsCLZvYGMBf4l7v/O1txiohItKydpHb3YRGTH0hRthwYHA6/BxyUrbhERCQ96otJREQiqauNfNKxIx0/WK+7Q0QkLyhB5JNHHuGRuGMQEQnpEJOIiERSgsgnl1zCJQc/xyWXxB2IiEiaCcLMumc7EAFKSih5f3dKSuIOREQk/T2Ie81srpldmKqLbhERaVjSOknt7v3NbD+CDvbmmdlc4O/uPiOr0Umj8ObChUx9+vWM1PV6iWFmGalr7w6d+Ljsw4zUJVIfpX0Vk7u/Y2ZXAfOAO4GDLfhPvNLdn8hWgNLwbd68mWbf6Z2RutxfZZ/Lns5IXR/cMiQj9YjUV2klCDPrAZwJ/IjgoT/Hu/t8M2tP0J2GEkQm7L8/+3/6BewfdyAiIunvQdwF/JVgb2Fj5UR3Lw/3KiQT7r+flA++EBHJsXQTxGBgo7tvBTCznYCm7r7B3cdlLToREYlNulcxzQSaJYw3D6dJJo0cycjvPs/IkXEHIiKS/h5EU3dfVzni7uvMrHmWYmq8li5l6cffgqVxByIikv4exHoz61k5YmaHABurKC8iIvVcunsQlwCPmVl5ON4OODUrEYmISF5I90a5V83sAKArYMBid9+c1chERCRWNenuuzdQFC5zsJnh7g9nJarGqriY4jVroDjuQERE0r9RbhzQBSgBtoaTHVCCyKQxYxgTdwwiIqF09yB6Ad3c3bMZjIiI5I90r2JaCOxdk4rN7EEzW2FmCxOm7WlmM8zsnfDvHimWPc7MlpjZMjO7vCbt1munn87p+/6P00+POxARkfQTRCGwyMz+Y2ZPVb6qWWYscFzStMuBZ919P+DZcHw7ZlYA/AUYBHQDhplZtzTjrN/Kyij7vAVlZXEHIiKS/iGma2tasbs/b2ZFSZN/DAwIhx8CZgOXJZU5FFjm7u8BmNmj4XKLahqDiIjUXlp7EO7+HFAKNAmHXwXm16K9vdz947DOj4G2EWU6AMsTxsvCaZHMbKSZzTOzeStXrqxFSCIiEiXdR46eC0wG7gsndQD+maWYop72kvLkuLvf7+693L1XmzZtshSSiEjjk+4hpl8SHPp5BbY9PCjq1391PjWzdu7+sZm1A1ZElCkDOiWMdwTKI8o1PH370vfL1dA37kBERNJPEF+6+1eVj3I0s52p4ld9FZ4CzgBuDv8+GVHmVWA/M9sX+Ag4DfhZLdqqf/7wB/4QdwwiIqF0r2J6zsyuBJqZ2dHAY8DUqhYwswkET5vramZlZnY2QWI42szeAY4OxzGz9mY2DcDdtwAXAf8B3gYmuftbNX9rIiJSF+nuQVwOnA28CZwHTAP+VtUC7j4sxawjI8qWEzyUqHJ8WthG43LyyZz88qXQpw+PPx53MCLS2KXbWd/XBI8c/Wt2w2nkKiqoWN8UKuIOREQk/b6Y3ifinIO7fzvjEYmISF6oSV9MlZoCPwX2zHw4IiKSL9K9Ua4i4fWRu48Bfpjd0EREJE7pHmLqmTC6E8EexW5ZiagxO/JIjixY/U1nJMDZw09iRXlpRqovK/+Eju1r1OdiSm3bF/HAuCcyUpeI5Kd0DzHdnjC8haDbjVMyHk1jN3o0o0dvP2lFeSlTR6fsaaRGuv1iMVNHH5KRuo6/vjQj9YhI/kr3KqaB2Q5ERETyS7qHmP5fVfPd/Y7MhNPIDRrEoHnXQa/ePPNM3MGISGNXk6uYehN0lQFwPPA82/e6KnW1cSMbNzeBjXEHIiKSfoIoBHq6+1oAM7sWeMzdz8lWYCIiEq90+2LqDHyVMP4VUJTxaEREJG+kuwcxDphrZlMI7qg+EXg4a1GJiEjs0r2K6UYzewY4Ipx0pru/nr2wGqkhQxjScvV290GIiMQl3T0IgObAF+7+dzNrY2b7uvv72QqsURo1ilGj4g5CRCSQ7iNHrwEuA64IJzUBHslWUCIiEr90T1KfCJwArIdtz29QVxuZNmAAA1qVMGBA3IGIiKSfIL5ydyfs8tvMWmQvJBERyQfpJohJZnYf0MrMzgVmoocHiYg0aNWepDYzAyYCBwBfAF2Bq919RpZjExGRGFWbINzdzeyf7n4IUOekYGZdCRJOpW8TJJwxCWUGAE8ClVdJPeHu19W1bRERSV+6l7m+bGa93f3Vujbo7kuAYgAzKwA+AqZEFH3B3YfUtb165ZRTOGXvNfD9uAMREUk/QQwEzjezUoIrmYxg56JHHds/EnjX3T+oYz0Nw4UXcuGFcQchIhKoMkGYWWd3/xAYlKX2TwMmpJjX18zeAMqBUe7+VooYRwIjATp37pyVIHNmwwY2bACaN6d587iDEZHGrrqrmP4JEP7Cv8PdP0h81aVhM9uF4N6KxyJmzwf2cfeDgD9XxhHF3e93917u3qtNmzZ1CSl+gwcz+DtLGTw47kBERKpPEJYw/O0Mtz0ImO/unybPcPcv3H1dODwNaGJmhRluX0REqlBdgvAUw5kwjBSHl8xs7/DyWszsUII4KzLcvoiIVKG6k9QHmdkXBHsSzcJh+OYk9bdq06iZNQeOBs5LmHY+QaX3AkOBC8xsC8Hz1U4L7+QWEZEcqTJBuHtBNhp19w1A66Rp9yYM3wXclY22RUQkPTXp7luybcQIRry4DvrHHYiIiBJEfhkxghEj4g5CRCSQbmd9kgurVrFqSQWrVsUdiIiIEkR+GTqUoYctZ+jQuAMREVGCEBGRFJQgREQkkhKEiIhEUoIQEZFIusw1n1xwARfM2QD94g5EREQJIr+ceiqnnhp3ECIiAR1iyifLl7P8lXKWL487EBER7UFsc/bwk1hRXpqRutq2L+KBcU/UfMHhwxleMgaK2zN7dkZCERGpNSWI0IryUqaO7pCRuo6/vjQj9YiIxEmHmEREJJIShIiIRFKCkFp5c+FCzCwjr8agXcfOGVtfO+/aLC/ratexc9yrWTJM5yDyyW9+w2/mfgWHxh1I9TZv3sw+lz2dmbruH5KRevLZJx8tz9j6+uCWIXlblzQsShD55PjjOf74uIMQEQnoEFM+WbKEJc+8x5IlcQciIqIEkV/OO4/zhn3BeefFHYiISEwJwsxKzexNMysxs3kR883M7jSzZWa2wMx6xhGniEhjFuc5iIHunurhmoOA/cLXYcA94V8REcmRfD3E9GPgYQ+8DLQys3ZxByUi0pjElSAcmG5mr5nZyIj5HYDELuvKwmk7MLORZjbPzOatXLkyC6GKiDROcR1iOtzdy82sLTDDzBa7+/MJ86PunvKoitz9fuB+gF69ekWWqTeuuoqr5n8NOuMiInkglgTh7uXh3xVmNoXg1rDEBFEGdEoY7wiU5y7CmBx1FEcdFXcQIiKBnB9iMrMWZrZb5TBwDLAwqdhTwC/Cq5n6AGvc/eMch5p7JSWUTFxCSUncgYiIxLMHsRcwJeyDZ2dgvLv/28zOB3D3e4FpwGBgGbABODOGOHPvkku4pGQMFKPnQYhI7HKeINz9PeCgiOn3Jgw78MtcxiUiItvL18tcRUQkZkoQIiISSQlCREQiqbvvfHLTTdz0ZgEcGHcgIiJKEPmlXz/69Ys7CBGRgA4x5ZM5c5hz35vMmRN3ICIi2oPIL1deyZW6D0JE8oT2IEREJJIShIiIRFKCEBGRSEoQIiISSSep88mYMYxZ0gy6xh2IiIgSRH4pLqa4OO4gREQCOsSUT2bOZOat85k5M+5ARES0B5FfbriBG8L7IPRkORGJm/YgREQkkvYgpEFxB3vy1xmpq1WLjFQjUm8pQUiDssvO8NeLW2ekrjOufC8j9YjUVzrEJCIikXK+B2FmnYCHgb2Br4H73f3/ksoMAJ4E3g8nPeHu1+UwzHjcdx/3vdcEvh13ICIi8Rxi2gL8xt3nm9luwGtmNsPdFyWVe8Hdh8QQX3y6dqWrbpITkTyR80NM7v6xu88Ph9cCbwMdch1HXpo6lamj5zJ1atyBiIjEfA7CzIqAg4FXImb3NbM3zOwZM/teFXWMNLN5ZjZv5cqV2Qo1N26/ndv/vAu33x53ICIiMSYIM2sJPA5c4u5fJM2eD+zj7gcBfwb+maoed7/f3Xu5e682bdpkLV4RkcYmlgRhZk0IksM/3P2J5Pnu/oW7rwuHpwFNzKwwx2GKiDRqOU8QZmbAA8Db7n5HijJ7h+Uws0MJ4qzIXZQiIhLHVUyHA8OBN82sJJx2JdAZwN3vBYYCF5jZFmAjcJq7ewyxiog0WjlPEO7+ImDVlLkLuCs3EeWRceMYV14A7eMOREREXW3kl06d6NQp7iBERALqaiOfTJzIxIvnMHFi3IGIiChB5Jd77uGeh5pzzz1xByIiogQhIiIpKEGIiEgkJQgREYmkBCEiIpF0mWs+mTyZyRUGmXkgmohInShB5JPCQgrV45SI5AkdYsonY8cy9pwXGTs27kBERJQg8svYsYyd3FIJQkTyghKEiIhEUoIQEZFIShAiIhJJCUJERCLpMtd8Mm0a0zYAzeMORERECSK/NG9OcyUHEckTOsSUT+6+m7tPe4677447EBERJYj8MmkSk/69O5MmxR2IiIgShIiIpBBLgjCz48xsiZktM7PLI+abmd0Zzl9gZj3jiFNEpDHLeYIwswLgL8AgoBswzMy6JRUbBOwXvkYCeginiEiOxbEHcSiwzN3fc/evgEeBHyeV+THwsAdeBlqZWbtcByoi0piZu+e2QbOhwHHufk44Phw4zN0vSijzNHCzu78Yjj8LXObu8yLqG0mwlwHQFVhSy9AKgVW1XDbXFGt21KdYoX7Fq1izIxOx7uPubaJmxHEfhEVMS85S6ZQJJrrfD9xf56DM5rl7r7rWkwuKNTvqU6xQv+JVrNmR7VjjOMRUBnRKGO8IlNeijIiIZFEcCeJVYD8z29fMdgFOA55KKvMU8IvwaqY+wBp3/zjXgYqINGY5P8Tk7lvM7CLgP0AB8KC7v2Vm54fz7wWmAYOBZcAG4MwchFbnw1Q5pFizoz7FCvUrXsWaHVmNNecnqUVEpH7QndQiIhJJCUJERCI1qgRhZnua2Qwzeyf8u0eKcg+a2QozW5g0/Voz+8jMSsLX4DyONa3lcxxrZBcruVivdenepbpl8yzWUjN7M1yPO9w3FEOsB5jZS2b2pZmNqsmyeRhvvq3bn4ef/wIzm2NmB6W7bNrcvdG8gFuBy8Phy4FbUpT7PtATWJg0/VpgVD2JNa3lcxUrwQUJ7wLfBnYB3gC65WK9VtV2QpnBwDME9+D0AV5Jd9l8iTWcVwoU5ug7mk6sbYHewI2Jn3Gu12td483TddsP2CMcHpSN72yj2oMg6MLjoXD4IeAnUYXc/XngsxzFlEpdY01r+QxJp610uljJlrp075LruOtTVzTVxuruK9z9VWBzTZfNs3hzLZ1Y57j75+HoywT3i6W1bLoaW4LYy8P7KcK/bWtRx0XhLt2D2TxsQ91jzcR7zWRbHYDlCeNl4bRK2Vyv1bVdVZl0ls2kusQKQY8D083sNQu6ocmmuqybXK/XTLSZz+v2bIK9ytosm1KDe+Somc0E9o6Y9bsMVH8PcD3BF+V64HbgrNpWluVYMyoDsVbVfUpG12sN266uTNrdvmRIXbuiOdzdy82sLTDDzBaHe5nZUJd1k+v1mok283LdmtlAggTRv6bLVqfBJQh3PyrVPDP71MzaufvH4S75ihrW/WlCXX8Fnq59pNmNFajr8pmONWX3KZlerzVpO40yu6SxbCbVqSsad6/8u8LMphAcbsjWRqwuXeLE0Z1OndrMx3VrZj2AvwGD3L2iJsumo7EdYnoKOCMcPgN4siYLJx3nPRFYmKpsBtQp1gwsn+m2UnaxkoP1WpfuXdJZNi9iNbMWZrYbgJm1AI4hu9/RuqybXK/XOrWZj+vWzDoDTwDD3X1pTZZNWy7OyOfLC2gNPAu8E/7dM5zeHpiWUG4C8DHBiaoy4Oxw+jjgTWBBuMLb5XGskcvHHOtgYCnBFRa/S5ie9fUa1TZwPnB+OGwED7J6N4ylV3VxZ3F91ipWgqtW3ghfb+VJrHuH38svgNXh8LfiWK91iTdP1+3fgM+BkvA1L9PfWXW1ISIikRrbISYREUmTEoSIiERSghARkUhKECIiEkkJQkREIilBSL1gZq3tm95eP7Fven9dbWaLMlD/k2b2UsL4+2bWNanMGDP7rZkNMLM1CfGUmNlRYZmt4fhCM5tqZq2S6njDzCYkTdvZzG6yoDfcyvp+lzB/a1JbOen5VEQJQuoFd69w92J3LwbuBf4UDhcDX9el7nAj3pOg07t9w8mPEtxgVFlmJ2AoMDGc9EJlPOFrZjh9YzjenaATxV8m1PFdgv+574c3W1W6geCekQPD93QE0CRh/saktm6u5fvcuarxdJeTxkMJQhqCAjP7q5m9ZWbTzawZgJl1MbN/h52rvWBmB6RY/mRgKtsnhQkJwxB0q17q7h/UIK6X2L6TtJ8R3BQ4HTghjLE5cC7wK3ffBODua9392hq0k/K9mtlYM7vDzGYBt0SMF5vZyxZ0lDjFwo4SzWx2uFfzHHBxTWKRhkMJQhqC/YC/uPv3CO5+PTmcfj/BhvcQYBRwd4rlhxEkhAnhMO6+APjavnkIy2nh/EpHJB326ZJYoZkVAEeyfRcHpxLsgWxrB/gO8KG7r63i/TVLauvUiDJVvdf9gaPc/TcR4w8Dl7l7D4K7sq9JWK6Vu//A3W+vIjZpwLTrKA3B++5eEg6/BhSZWUuCB6o8Zratc8tdkxc0s70INtIvurub2RYz6+7uCwn3IszsLYL+9K9OWPQFdx8SEUszMysBisJYZoTt9AZWuvsHZlYGRHZrbmZnEvxibw30c/flhIeYUr35NN7rY+6+NXnczHYnSALPhdMfAh5LKDcRadS0ByENwZcJw1sJfvjsBKxOOnb/3YhlTwX2AN43s1KCDXviYaZTgKOABe6eTo+4lRvzfQh6gq08BzEMOCBs412C/n1OBpYBnSs7gnP3v4fLryF4Mlg6qnuv65PKJ4+nkm45aaCUIKRBcvcvCDb6P4Vtz3E+KKLoMOA4dy9y9yLgEMIE4e7vAhXAzWx/eCmd9tcAvwZGmdmuwE+BHgnt/BgY5u4bgAeAu8ysaRhrAUFyyfR7jYrxczM7Ipw0HHiuikWkkVGCkIbs58DZZlbZA+d2j100syKgM8HjGgFw9/eBL8zssHDSBOAAYEpS3cnnIIYmN+7urxP0/nkK8JG7f5Qw+3mgmwVdnf+OoEfehWb2OvACweGeyj78k89BRF3FVOV7rcIZwG1mtoDgirDr0lxOGgH15ioiIpG0ByEiIpGUIEREJJIShIiIRFKCEBGRSEoQIiISSQlCREQiKUGIiEik/w+/qsP2/5XaMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Average Error\n",
    "\n",
    "m_test_ave = statistics.mean(test_AVE_list)\n",
    "plt.axvline(m_test_ave, color='red', linestyle='dashed')\n",
    "plt.hist(test_AVE_list, bins=np.arange(-0.15,0.22,0.022), edgecolor='k', histtype ='bar', density=True)\n",
    "sd_test_ave = statistics.stdev(test_AVE_list)\n",
    "\n",
    "m_train_ave = statistics.mean(train_AVE_list)\n",
    "plt.axvline(m_train_ave, color='b', linestyle='dashed')\n",
    "plt.hist(train_AVE_list, color='orange', edgecolor='k', bins=np.arange(-0.15,0.22,0.022), histtype ='bar', density=True, alpha=0.7)\n",
    "sd_train_ave = statistics.stdev(train_AVE_list)\n",
    "\n",
    "print(f'stdev_AVERAGE_test: {sd_test_ave:.2f}')\n",
    "print(f'stdev_AVERAGE_train: {sd_train_ave:.2f}')\n",
    "\n",
    "print(f'mean_AVERAGE_test: {m_test_ave:.2f}')\n",
    "print(f'mean_AVERAGE_train: {m_train_ave:.2f}')\n",
    "\n",
    "#create legend\n",
    "labels= [\"Mean_test\",\"Mean_train\",\"test\",\"train\"]\n",
    "plt.legend(labels)\n",
    "\n",
    "plt.xlabel('The AVERAGE error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('histogram of the AVERAGE distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d87ad216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stdev_MAE_test: 0.07\n",
      "stdev_MAE_train: 0.08\n",
      "mean_MAE_test: 1.93\n",
      "mean_MAE_train: 1.64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#MAE\n",
    "\n",
    "m_test_mae = statistics.mean(test_MAE_list)\n",
    "plt.axvline(m_test_mae, color='red', linestyle='dashed')\n",
    "plt.hist(test_MAE_list, bins=np.arange(1.37,2.1,0.04), edgecolor='k', histtype ='bar', density=True)\n",
    "sd_test_mae = statistics.stdev(test_MAE_list)\n",
    "#plt.axvline(m+sd, color='b', linestyle='dashed')\n",
    "#plt.axvline(m-sd, color='b', linestyle='dashed')\n",
    "\n",
    "\n",
    "m_train_mae = statistics.mean(train_MAE_list)\n",
    "plt.axvline(m_train_mae, color='b', linestyle='dashed')\n",
    "plt.hist(train_MAE_list, color='orange', edgecolor='k', bins=np.arange(1.37,2.1,0.04), histtype ='bar', density=True, alpha=0.7)\n",
    "\n",
    "sd_train_mae = statistics.stdev(train_MAE_list)\n",
    "#plt.axvline(m+sd, color='y', linestyle='dashed')\n",
    "#plt.axvline(m-sd, color='y', linestyle='dashed')\n",
    "\n",
    "print(f'stdev_MAE_test: {sd_test_mae:.2f}')\n",
    "print(f'stdev_MAE_train: {sd_train_mae:.2f}')\n",
    "\n",
    "print(f'mean_MAE_test: {m_test_mae:.2f}')\n",
    "print(f'mean_MAE_train: {m_train_mae:.2f}')\n",
    "\n",
    "\n",
    "#create legend\n",
    "labels= [\"Mean_test\",\"Mean_train\",\"test\",\"train\"]\n",
    "plt.legend(labels)\n",
    "\n",
    "plt.xlabel('The MAE error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('histogram of the MAE distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d8b23042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stdev_RMSE_test: 0.37\n",
      "stdev_RMSE_train: 0.35\n",
      "mean_RMSE_test: 5.80\n",
      "mean_RMSE_train: 4.80\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAt1UlEQVR4nO3deZgU1dXH8e9xJA64YRhUYEDQuCEiIouoiSgxCOIa4hLRkKjEBZe8r4ryCqJRo9EoUaMGjeISwCVikKAiRqIRlU1URFSEUQZUFgUFHBE87x9Vg03TM90z0zU13f37PE8/011169aprp4+Xbeq7jV3R0RECttWcQcgIiLxUzIQERElAxERUTIQERGUDEREBCUDERFBySCnmFmZmf20ink/NrP36jumhsQCD5jZF2Y2PcNlRpvZdVHH1lCYWVszczPbOnz9jJn9Kkt1b/YZrO7zWsv63zGzntmqTzanZJAn3P1ld987XTkzG2Fmj9RHTDE4DDgKKHX3bskzzWygmf03qpWb2VQzqzCzNWa2wsyeNLMWCfNHhF/EFyUtd0k4fUTCtKFmtiisq9zMHq1iPZWPp2sTs7v3cfcHM9g2N7Mfpakro89gJlIlaXffz92nZqN+2ZKSgWRN5a/NGO0GlLn72hhjGOzu2wE/ArYDbkma/z6Q/Ev8zHA6AOEv9TOAn4Z1dQFeSLWehMex2dyImmoA+17qSMkg93Qys7fMbLWZPWpmxQBm1tPMyisLmdkQM1tiZl+Z2Xtm1svMjgaGAqeEvybfDMu2NLMJZva5mS0ws3MS6mlsZg+GTS/vmtnlSespC9f1FrDWzLY2syvM7MNw3fPM7MSE8gPN7BUzu83MVpnZQjM7JJy+2MyWVddsUVWsZnYWcB/QI9y2a5KW2xe4J2H+qoTZO5nZv8J4XzezPRKW28fMng/X956ZnZzJTnL3VcBTQKekWTOAJma2X1j/fkDjcHqlrsBz7v5hWNen7j4qk/UmM7MiM7slPFJZCByTNH+qmZ0dPv+Rmf0n/GytqDwaMbOXwuJvhu/dKZWft3Dffwo8kPwZrNyW8DPwhQVNeJWf1y2O0iqPPsxsEHA6cHniUY8lNDuZ2TZmNtLMloaPkWa2TTivMrb/DT9Pn5jZr2vz/hUSJYPcczJwNNAO6AgMTC5gZnsDg4Gu7r490JvgF/OzwA3Ao+GvyQPCRcYC5UBLoD9wg5n1CuddDbQFdidoghmQIqbTCL5kmrr7BuBD4MfAjsA1wCOW0FwCdAfeApoBY4BxBF+APwrrv9PMtqti+1PG6u5/A84FXg237erEhdz93aT5TZPivwbYCVgAXB++j9sCz4cx7hyWu6vyi7w6ZtYMOCmsL9nDBEcDEBwlPJQ0/zXgTDO7zMy6mFlRuvVV4xygH3AgwRFG/2rK/h6YTPA+lAJ3ALj7T8L5B4TvXWWT1a7ADwmOyAZVUefpBJ+/PYC9gKvSBRwmvr8Df6zmqOf/gIMJku0BQLekuncl+Py1As4C/mJmO6VbdyFTMsg9t7v7Unf/HHiaLX95AmwEtgHam1kjdy+r/JWZzMxaE7S1D3H3CnefQ/AL+4ywyMnADe7+hbuXA7dXEdNid/8awN0fD2P8Lvzi+IDgn7XSInd/wN03Ao8CrYFr3f0bd58MrCdIDDWNtbaedPfpYSL7O9+/p/0IkugD7r7B3WcD/6D6L9TbzWw1sAIoAS5MUeYR4DQzawScGr7exN0fCZfrDfwHWGZmV6RYz6qEx++riOdkYGS4fz4H/lBN7N8SfLG3DN/fdOdXvgOuDvfb11WUuTNh3dcTJNRsOJ3gM7PM3ZcTJPPEz8G34fxv3X0SsAbIyvmMfKVkkHs+TXi+jqBdejPuvgC4BBhB8EUyzsxaVlFfS+Bzd/8qYdpHBL+oKucvTpiX+DzlNDM708zmVH5RAR0IvhgrfZbwvDKBJE9LdWSQLtbaquo93Q3onvilS/AltGs1dV3k7jsSHLVV/sLejLt/THDEcAPwgbtv8Z66+9/d/adAU4IjmmvNrHfSepomPIZVEU/y/vuomtgvBwyYbsGVO7+ppizAcnevSFMmed1VfQ5rqiWbb0ty3SvD5F4p5f+KfE/JIE+5+xh3P4zgC82BmypnJRVdCvzQzLZPmNYGWBI+/4TNv9Bap1pd5RMz2w24l6CZqlnYHDOX4EumrtLFmk5Nu+hdDPwn6Ut3O3c/L+2K3N8GriNonki17Q8B/8uWTUTJ9Xzr7o8TNKt1qGH8EOy/xH3Wppp1feru57h7S+C3BE1i1V1BlMn7mbzupeHztUCTyhlmlpxg09W9lOCznapuqQUlgzxkZnub2ZHhCbUKgl/aG8PZnwFtzWwrgPBX6TTgD2ZWbGYdCdpY/x6Wfwy40sx2MrNWBF/y1dmW4B95eRjLr6ndl9gWMog1nc+AUjP7QYblJwJ7mdkZZtYofHQNT0Zn4kGCcw3HpZj3KPAzgvd3M+HJ1WPMbHsz28rM+gD7Aa9nuN5EjwEXmVlp2Gae3NyUuN5fmFll4v+CYD8mfm52r8X6LwjX/UOCixcqzze8CexnZp3Ck8ojkpZLt76xwFVm1tzMSoDhJDW3Sc0oGeSnbYAbCdqtPyX4Qhoazns8/LvSzGaHz08jOEm8FBhP0A78fDjvWoITtouAKcATwDdVrdjd5wF/Al4l+IfeH3glGxuVQazp/Bt4B/jUzFakKxw2R/2MoF1/KcF7eRPB+5uWu68nOMeyRROOu3/t7lOqaGv/kmB/fQysAv4InJfUhn+nbX6fwawqwrgXeI7gy3c28GQ1IXcFXjezNcAE4GJ3XxTOGwE8GDaXZXRFVWgMwUnpheHjOgB3f5/gszWF4JxS8vmJvxGc81plZk+lqPc6YCbBEdPb4bYVzM2DUTANbiM1YWbnAae6++FxxyIi2aMjA6mWmbUws0PD5oq9Cdq5x8cdl4hkl+4alHR+APyV4L6GVQT3BNwVZ0Aikn1qJhIRETUTiYhIDjYTlZSUeNu2beMOI+e9F3Y0vLfuycxN2oFSQ7NmzVrh7s2rmp9zyaBt27bMnDkz7jByXs+ewd+pU+OMQmpNO1BqyMyqu/tczUQiIpKDRwaSHVel7TtSGjTtQMkyJYMC9dOsDUYosdAOlCxTMihQc+YEfzt1ijMKqbUc24Hffvst5eXlVFSk6+RU6qq4uJjS0lIaNWpUo+WUDArUJZcEf3X+MUfl2A4sLy9n++23p23btqTuxFWywd1ZuXIl5eXltGvXrkbL6gSyiESuoqKCZs2aKRFEzMxo1qxZrY7AlAxEpF4oEdSP2r7PSgYiIqJkICIiOoFcsG64IbNyZ51xEsuWlmVlnTu3bMvfHq5ubJV4tChtw6dLUg3tXHO7tmrNJ+UfZ6Wu6uLqEf59NcMmgWzGlavMjAEDBvDwww8DsGHDBlq0aEH37t2ZOHFi5OsfOXIkgwYNokmTJukLJ3nqqafYa6+9aN++fQSRBZQMCtQhh2RWbtnSMp4eVtfx5gPH/r4sK/Vk26dLFrPbkOx8GXx0U7+s1APVx1U52O9uKeduKZtx5aptt92WuXPn8vXXX9O4cWOef/55WrXKzmc7EyNHjmTAgAG1Tgb9+vWLNBmomahATZsWPCQ3dS5/l87l78YdRu317Lnl465wmIx161LPHz06mL9ixZbzMtSnTx/+9a9/ATB27FhOO+20TfPWrl3Lb37zG7p27cqBBx7IP//5TwDKysr48Y9/TOfOnencuTPTwn+cqVOn0rNnT/r3788+++zD6aefTlVDAtx+++0sXbqUI444giOOOAKAyZMn06NHDzp37swvfvEL1qxZA8AVV1xB+/bt6dixI5deeinTpk1jwoQJXHbZZXTq1IkPP/ww4+2tCSWDAjV0aPCQ3HT5Sw9y+UsPxh1Gzjn11FMZN24cFRUVvPXWW3Tv3n3TvOuvv54jjzySGTNm8OKLL3LZZZexdu1adt55Z55//nlmz57No48+ykUXXbRpmTfeeIORI0cyb948Fi5cyCuvpB7u+6KLLqJly5a8+OKLvPjii6xYsYLrrruOKVOmMHv2bLp06cKtt97K559/zvjx43nnnXd46623uOqqqzjkkEM47rjjuPnmm5kzZw577LFHJO+NmolEpP5Vd7NckybVzy8pqfXNdh07dqSsrIyxY8fSt2/fzeZNnjyZCRMmcMsttwDBvREff/wxLVu2ZPDgwcyZM4eioiLef//9Tct069aN0tJSADp16kRZWRmHHXZY2jhee+015s2bx6GHHgrA+vXr6dGjBzvssAPFxcWcffbZHHPMMfTrV3/Ne0oGIlJQjjvuOC699FKmTp3KypUrN013d/7xj3+wd9IYESNGjGCXXXbhzTff5LvvvqO4uHjTvG222WbT86KiIjZs2JBRDO7OUUcdxdixY7eYN336dF544QXGjRvHnXfeyb///e+abmKtRNZMZGb3m9kyM5ubplxXM9toZv2jikVEpNJvfvMbhg8fzv7777/Z9N69e3PHHXdsavd/4403AFi9ejUtWrRgq6224uGHH2bjxo21Wu/222/PV199BcDBBx/MK6+8woIFCwBYt24d77//PmvWrGH16tX07duXkSNHMifsgypx2ahEec5gNHB0dQXMrAi4CXguwjhERDYpLS3l4osv3mL6sGHD+Pbbb+nYsSMdOnRg2LBhAJx//vk8+OCDHHzwwbz//vtsu+22tVrvoEGD6NOnD0cccQTNmzdn9OjRnHbaaXTs2JGDDz6Y+fPn89VXX9GvXz86duzI4Ycfzm233QYE5zpuvvlmDjzwwMhOIFtVZ7+zUrlZW2Ciu3eoYv4lwLdA17DcE+nq7NKli2uks7rLtNPLY3t1zuKlpUt4+oXZWakrm8wsq5eWZut/qrq42n+2EIB5u+xe73HVxrvvvsu+++4b2/oLTar328xmuXuXqpaJ7ZyBmbUCTgSOJEgGUo9ypOdjqUKmSUAkU3GeQB4JDHH3jek6VjKzQcAggDZt2kQfWQGYMiX4qzFSctOhZXMAeKVtp1jjkC2deOKJLFq0aLNpN910E717944poszEmQy6AOPCRFAC9DWzDe7+VHJBdx8FjIKgmag+g8xX110X/FUyyE0XThsHKBk0ROPHj487hFqJLRm4+6aRF8xsNME5g6fiikdEpJBFlgzMbCzQEygxs3LgaqARgLvfE9V6RUSk5iJLBu5+WvpSm8oOjCoOERFJT30TiYiIkkGh+utfg4fkpqG9BzO09+C4w8gpZsYZZ5yx6fWGDRto3rx5vfX/M3LkSNatW1fj5YYPH86Uysv/IqS+iQpUUvcrkmMWNiuNO4Sc05DHM9i4cSNFRUUpl7v22mujDg3QkUHBevrp4CG5qdeC1+m14PW4w6i1mIYzaFDjGWy33XYMHz6c7t278+qrr3LttdfStWtXOnTowKBBgzbVNXDgQJ54IuicoW3btlx99dV07tyZ/fffn/nz52e+8WkoGRSoP/0peEhuOmf6eM6ZnpvXs8epoYxnAEHy6dChA6+//jqHHXYYgwcPZsaMGZuOXqoairOkpITZs2dz3nnnbepuOxvUTCQi9S6m4QwazHgGEHR5/fOf/3zT6xdffJE//vGPrFu3js8//5z99tuPY489dovlTjrpJAAOOuggnnwye2OKKxmISEFpCOMZABQXF286T1BRUcH555/PzJkzad26NSNGjKCioiLlcpXrrOn60lEzkYgUlIYwnkGyyi/+kpIS1qxZs+kcQX1SMhCRgtIQxjNI1rRpU8455xz2339/TjjhBLp2rf+OnCMdzyAKGs8gOxYvDv62bl19OY1nUDP1NZ5Biy+XA/DJDs3rPa7a0HgG9SunxjOQeKVLAtKwZZoERDKlZFCgHn00+HvKKfHGIbXT792XAJi4709ijkSSaTwDySl33x38VTLITQPemAQoGTREuTqegU4gi4iIkoGIiCgZiIgISgYiEoMWpW0ws6w9WpS2SbvOVatWcVdlb3g1VNvup3OJTiAXqBhucJQsOu+EK+MOoU4+XbI4a/d2QHAfRTqVyeD888+vcf3VdT+dL5QMClRJSdwRSF180WTHuEPIOVdccQUffvghnTp14qijjmLnnXfmscce45tvvuHEE0/kmmuuYe3atZx88smUl5ezceNGhg0bxmeffbap++mSkpJNvY7mGyWDAlXZN/zAgXFGIbXV/+1g5Ksn9v9pzJHkjhtvvJG5c+cyZ84cJk+ezBNPPMH06dNxd4477jheeuklli9fTsuWLTeNebB69Wp23HFHbr31Vl588UVK8vhXVGTnDMzsfjNbZmZzq5h/upm9FT6mmdkBUcUiWxo9+vuEILmn/9tTNiUEqbnJkyczefJkDjzwQDp37sz8+fP54IMP2H///ZkyZQpDhgzh5ZdfZscdC+cILMojg9HAncBDVcxfBBzu7l+YWR9gFNC9irIiIlnj7lx55ZX89re/3WLerFmzmDRpEldeeSU/+9nPGD58eAwR1r/Ijgzc/SXg82rmT3P3L8KXrwEa1FVEIpPYhXTv3r25//77WbNmDQBLlixh2bJlLF26lCZNmjBgwAAuvfRSZs+evcWy+aqhnDM4C3imqplmNggYBNCmTfpLyESkYdu1VeuMrgCqSX3pNGvWjEMPPZQOHTrQp08ffvnLX9KjRw8gGI/4kUceYcGCBVx22WVstdVWNGrUiLvDflsqu59u0aKFTiBHxcyOIEgGVY4V5+6jCJqR6NKlS271uS0iW/ik/ONY1jtmzJjNXiePa7DHHnuk7FDuwgsv5MILL4w0trjFmgzMrCNwH9DH3VemKy/ZM2lS3BFIXQz8xYi4Q5A8E1syMLM2wJPAGe7+frry+eysM05i2dKyrNS1c8u2/O3h9INk5/G9MwWholFx+kIiNRBZMjCzsUBPoMTMyoGrgUYA7n4PMBxoBtxlZgAbqhuFJ58tW1qWxdHEyjIqV3lXfi1uxpQGYMDs4Dr4RzofE3Mkki8iSwbuflqa+WcDZ0e1fqneY48Ff5UMclO/+S8DSgaSPeqoTkRElAxERKQBXFoqIoUnmxdNQGYXTqxatYoxY8bUuNfSvn37MmbMGJo2bVqHCBs+JQMRqXfZvGgCMrtwoqourDdu3EhRUVGVy00qkOuwlQwK1NSpcUcgdXHqL2+MO4Sck9iFdaNGjdhuu+1o0aIFc+bMYd68eZxwwgksXryYiooKLr74YgYNGgRA27ZtmTlzJmvWrKFPnz4cdthhTJs2jVatWvHPf/6Txo0bx7xl2aFzBiJSEG688Ub22GMP5syZw80338z06dO5/vrrmTdvHgD3338/s2bNYubMmdx+++2sXLnlfbAffPABF1xwAe+88w5NmzblH//4R31vRmR0ZFCgbrkl+HvppfHGIbVzzutB+/i93U+KOZLc1a1bN9q1a7fp9e2338748eMBWLx4MR988AHNmjXbbJl27drRqVMnAA466CDKysrqK9zI6cigQE2cGDwkN/X6cDq9Ppwedxg5bdttt930fOrUqUyZMoVXX32VN998kwMPPJCKiootltlmm202PS8qKmLDhg31Emt9UDIQkYJQXTfUq1evZqeddqJJkybMnz+f1157rZ6ji5+aiUSk3u3csm3GXadkWl86iV1YN27cmF122WXTvKOPPpp77rmHjh07svfee3PwwQdnLbZcoWQgIvUuk84Uo5DchXWlbbbZhmeeST2kSuV5gZKSEubO/X4U30vz7ISbkkGBypOr4QpWxdbbpC8kUgNKBgWqih9BkiMGnnxN3CFIntEJZBGpF+4apLA+1PZ9VjIoUL//ffCQ3HThK2O58JWxcYeRseLiYlauXKmEEDF3Z+XKlRQX13zwIzUTFagXXgj+DhsWbxxSO4d+9CYAdxxa7bAhDUZpaSnl5eUsX7487lDyXnFxMaWlpTVeTslARCLXqFGjze72lYZHzUQiIqJkICIiESYDM7vfzJaZ2dwq5puZ3W5mC8zsLTPrHFUssqVmzYKH5KYvGu/AF413iDsMySNRnjMYDdwJPFTF/D7AnuGjO3B3+FfqQR71vFuQzjtxaNwhSJ6J7MjA3V8CPq+myPHAQx54DWhqZi2iikdERKoW5zmDVsDihNfl4bQtmNkgM5tpZjN1aVp2XHll8JDcdPl/RnP5f0bHHYbkkTgvLbUU01LekeLuo4BRAF26dNFdK1nw6qtxRyB10XnJ/LhDkDwT55FBOdA64XUpsDSmWEREClqcyWACcGZ4VdHBwGp3/yTGeEREClZkzURmNhboCZSYWTlwNdAIwN3vASYBfYEFwDrg11HFIiIi1YssGbh7tZ2meNBj1QVRrV+qV4uuS6QB+WT7krhDkDyjvokK1COPxB2B1MXvjs2vUbYkfuqOQkRElAwK1SWXBA/JTcOnjGL4lFFxhyF5JKNmIjPr4O4p+xiS3DRnTtwRSF20X7Yw7hAkz2R6ZHCPmU03s/PNrGmUAYmISP3LKBm4+2HA6QQ3ic00szFmdlSkkYmISL3J+JyBu38AXAUMAQ4Hbjez+WZ2UlTBiYhI/cj0nEFHgpvCjgGeB45199lm1hJ4FXgyuhAlCnvtFXcEUhcLf5iyT0eRWsv0PoM7gXuBoe7+deVEd19qZldFEplEapQuRMlpQ4++MO4QJM9kmgz6Al+7+0YAM9sKKHb3de7+cGTRiYhIvcj0nMEUoHHC6ybhNMlRgwYFD8lNNzx7Bzc8e0fcYUgeyfTIoNjd11S+cPc1ZtYkophywllnnMSypWVZqeujjxZSxbg+kXn//XpdXda1KGnMVt9VZKWupttmpZp6tfvnS2q2QFEjzFINIVJzu7ZqzSflH2elLmk4Mk0Ga82ss7vPBjCzg4Cv0yyT15YtLePpYdn5Am9/pgYqqamtvqvgwRu6ZqWuXw2dkZV6GrSN37LbkIlZqeqjm/plpR5pWDJNBpcAj5tZ5eAzLYBTIolIRETqXUbJwN1nmNk+wN4Ew1XOd/dvI41MRETqTU26sO4KtA2XOdDMcPeHIolKItepU9wRSF3M23n3uEOQPJPpTWcPA3sAc4CN4WQHlAxy1MiRcUcgdXHtT3UpmGRXpkcGXYD24ehkIiKSZzK9z2AusGuUgUj9GjAgeEhuuu3pW7jt6VviDkPySKZHBiXAPDObDnxTOdHdj6tuITM7GvgzUATc5+43Js3fEXgEaBPGcou7P5B5+FJb5eVxRyB10eKrFXGHIHkm02QwoqYVm1kR8BfgKKAcmGFmE9x9XkKxC4B57n6smTUH3jOzv7v7+pquT0REai/TS0v/Y2a7AXu6+5Tw7uOiNIt1Axa4+0IAMxsHHA8kJgMHtrfg1sjtgM+BDTXcBhERqaOMzhmY2TnAE8Bfw0mtgKfSLNYKWJzwupwt+1y4E9gXWAq8DVzs7t+lWP8gM5tpZjOXL1+eScgiIlIDmTYTXUDwS/91CAa6MbOd0yyTqiOU5KuRehNcrnokwaWrz5vZy+7+5WYLuY8CRgF06dJFVzRlQY8ecUcgdTG71T5xhyB5JtNk8I27r6/s6MrMtmbLL/Zk5QTDZFYqJTgCSPRr4MbwktUFZrYI2AeYnmFcUkt/+EPcEUhd/PHwgXGHIHkm00tL/2NmQ4HG4djHjwNPp1lmBrCnmbUzsx8ApwITksp8DPQCMLNdCLq7WJhp8CIikh2ZJoMrgOUE7fq/BSYRjIdcJXffAAwGngPeBR5z93fM7FwzOzcs9nvgEDN7G3gBGOLuumauHvz858FDctPd42/g7vE3xB2G5JFMryb6jmDYy3trUrm7TyJIHInT7kl4vhT4WU3qlOxYuTLuCKQudvr6y/SFRGog076JFpHiHIG7q7csEZE8UJO+iSoVA78Afpj9cEREJA4ZnTNw95UJjyXuPpLgclAREckDmTYTdU54uRXBkcL2kUQk9aJXr7gjkLp4ZbcD4g5B8kymzUR/Sni+ASgDTs56NFJvhg2LOwKpizsOPS3uECTPZHo10RFRByIiIvHJtJnof6qb7+63ZiccqS99+gR/n3km3jikdkY/djUAA0++JuZIJF/U5Gqirnx/B/GxwEts3hGd5JCvv447AqmL4g3fpC8kUgM1Gdyms7t/BWBmI4DH3f3sqAITEZH6k2l3FG2AxAFn1gNtsx6NiIjEItMjg4eB6WY2nuBO5BOBhyKLSkRE6lWmVxNdb2bPAD8OJ/3a3d+ILiyJWr9+cUcgdfHCHt3iDkHyTKZHBgBNgC/d/QEza25m7dx9UVSBSbQuvTTuCKQu7u1+UtwhSJ7JdNjLq4EhwJXhpEbAI1EFJSIi9SvTE8gnAscBa2FT19PqjiKH9ewZPCQ3jRtzBePGXBF3GJJHMk0G68OhKR3AzLaNLiQREalvmSaDx8zsr0BTMzsHmEINB7oREZGGK+0JZDMz4FGCgeq/JBineLi7Px9xbCIiUk/SJgN3dzN7yt0PApQARETyUKaXlr5mZl3dfUZNKjezo4E/A0XAfe5+Y4oyPYGRBFcorXD3w2uyDqmdk9UBeU6buM+P0xcSqYFMk8ERwLlmVkZwRZERHDR0rGoBMysC/gIcBZQDM8xsgrvPSyjTFLgLONrdPzaznWu1FVJj558fdwRSF490PibuECTPVJsMzKyNu38M9KlF3d2ABe6+MKxrHHA8MC+hzC+BJ8N14O7LarEeqYV164K/TZrEG4fUTvG3FQBUNCqOORLJF+muJnoKwN0/Am51948SH2mWbcXmXVyXh9MS7QXsZGZTzWyWmZ2ZqiIzG2RmM81s5vLly9OsVjLRt2/wkNw0+vERjH58RNxhSB5Jlwws4fnuNazbUkzzpNdbAwcBxwC9gWFmttcWC7mPcvcu7t6lefPmNQxDRETSSXfOwKt4nolyoHXC61JgaYoyK9x9LbDWzF4CDgDer+G6MnLWGSexbGlZVur66KOFbHmgE78PFy7k2F6d05Z7+81RABzba1C15Rrqdooka1Hahk+XZGe8rV1bteaT8o+zUleuSJcMDjCzLwl+5TcOn8P3J5B3qGbZGcCeZtYOWAKcSnCOINE/gTvNbGvgB0B34LYabkPGli0t4+lh2flia3/m/KzUk3Ub12e0jT0v2QYgbdkGu50iST5dspjdhkzMSl0f3VR43fpWmwzcvai2Fbv7BjMbDDxHcGnp/e7+jpmdG86/x93fNbNngbeA7wguP51b23WKiEjt1KQL6xpz90nApKRp9yS9vhm4Oco4ZEsDj34h7hCkDp7Y/6dxhyB5JtJkIA2XkkFuUzKQbMu0ozrJMytW78CK1dWd8pGGbKd1q9lp3eq4w5A8oiODAtX/6qAv/Kkjh8YcidTG3U/9AYBTf7lFDy8itaIjAxERUTIQERElAxERQclARETQCeSCdd5xk9IXkgbrkQPVy6Bkl5JBgTrlyP/GHYLUwcR9fxJ3CJJn1ExUoBYvK2HxspK4w5BaavHlclp8qe7cJXt0ZFCgzrjhfwDdZ5Crbpv4J0D3GUj26MhARESUDERERMlARERQMhAREXQCuWD978nj4w5B6uDebifGHYLkGSWDAnXsITPiDkHq4IUfdY87BMkzaiYqUO993Ir3PtZA97lq95Xl7L6yPO4wJI/oyKBA/fbWCwDdZ5CrbnjuTkD3GUj2RHpkYGZHm9l7ZrbAzK6oplxXM9toZv2jjEdERFKLLBmYWRHwF6AP0B44zczaV1HuJuC5qGIREZHqRXlk0A1Y4O4L3X09MA44PkW5C4F/AMsijEVERKoRZTJoBSxOeF0eTtvEzFoBJwL3VFeRmQ0ys5lmNnP5cnXOJSKSbVGeQLYU0zzp9UhgiLtvNEtVPFzIfRQwCqBLly7JdUgtXHXGo3GHIHVwxyGnxh2C5Jkok0E50DrhdSmwNKlMF2BcmAhKgL5mtsHdn4owLgF+etCbcYcgdfBK205xhyB5JspkMAPY08zaAUuAU4FfJhZw93aVz81sNDBRiaB+zFkQvPWdfrQo5kikNtp/thCAebvsHnMkki8iSwbuvsHMBhNcJVQE3O/u75jZueH8as8TSLQuufMcQPcZ5KrhL4wCdJ+BZE+kN525+yRgUtK0lEnA3QdGGYuIiFRN3VGIiIiSgYiIKBmIiAjqqK5g3XD2Q3GHIHXwx5/8Ku4QJM8oGRSoQzrMjzsEqYPZpfvGHYLkGTUTFahpc/dh2tx94g5Daqlz+bt0Ln837jAkjygZFKih953J0PvOjDsMqaXLX3qQy196MO4wJI8oGYiIiJKBiIjoBLII7mD/vCgrdTXdNivVNGxFjaiul+EaVfWDYjaur8hKXVI3SgZS8H6wNdx7cbOs1PWroQuzUk+DtvFbdhsyMStVfXRTv6zWJbWnZFCgRg6+N+4QpA6u7TUo7hAkzygZFCh1XZ3b1HW1ZJtOIBeoKbMOYMqsA+IOQ2rp0LI5HFo2J+4wJI/oyKBAXffwKYBGPMtVF04bB2jEM8keHRmIiIiSgYiIKBmIiAhKBiIiQsQnkM3saODPQBFwn7vfmDT/dGBI+HINcJ6764xmPfjr//wl7hCkDob2Hhx3CJJnIksGZlYE/AU4CigHZpjZBHefl1BsEXC4u39hZn2AUUD3qGKS7+3dZkncIUgdLGxWGncIkmeibCbqBixw94Xuvh4YBxyfWMDdp7n7F+HL1wB9wuvJ09O68vS0rnGHIbXUa8Hr9FrwetxhSB6JspmoFbA44XU51f/qPwt4JsJ4JMGfHjsRgGMPmRFzJFIb50wfD8ALP9KBtGRHlMkgVbeGnrKg2REEyeCwKuYPAgYBtGnTJlvxiYhIKMpmonKgdcLrUmBpciEz6wjcBxzv7itTVeTuo9y9i7t3ad68eSTBiogUsiiTwQxgTzNrZ2Y/AE4FJiQWMLM2wJPAGe7+foSxiIhINSJrJnL3DWY2GHiO4NLS+939HTM7N5x/DzAcaAbcFQ6WscHdu0QVk4iIpBbpfQbuPgmYlDTtnoTnZwNnRxmDpPbw0FvjDkHq4Hf9/jfuECTPqNfSAtV65xVxhyB18MkOOncm2aXuKArUo/8+jEf/nfLiLckB/d59iX7vvhR3GJJHdGRQoO6e0BeAU478b8yRSG0MeCNofZ24709ijkTyhY4MREREyUBERJQMREQEJQMREUEnkAvWE9fcmL6QNFjnnXBl3CFInlEyKFAlO34ZdwhSB1802THuECTPqJmoQI1+thejn+0VdxhSS/3fnkL/t6fEHYbkESWDAqVkkNuUDCTblAxERETJQERElAxERAQlAxERQZeWFqxJN14TdwhSBwN/MSLuECTPKBkUqCbF38QdgtRBRaPiuEOQPKNmogJ111N9ueupvnGHIbU0YPa/GDD7X3GHIXlEyaBAPTb1MB6bqsFtclW/+S/Tb/7LcYcheUTJQEREok0GZna0mb1nZgvM7IoU883Mbg/nv2VmnaOMR0REUossGZhZEfAXoA/QHjjNzNonFesD7Bk+BgF3RxWPiIhULcojg27AAndf6O7rgXHA8Ulljgce8sBrQFMzaxFhTCIikoK5ezQVm/UHjnb3s8PXZwDd3X1wQpmJwI3u/t/w9QvAEHefmVTXIIIjB4C9gfciCbr+lAAr4g4iQtq+3Kbty21Vbd9u7t68qoWivM/AUkxLzjyZlMHdRwGjshFUQ2BmM929S9xxREXbl9u0fbmtttsXZTNROdA64XUpsLQWZUREJGJRJoMZwJ5m1s7MfgCcCkxIKjMBODO8quhgYLW7fxJhTCIikkJkzUTuvsHMBgPPAUXA/e7+jpmdG86/B5gE9AUWAOuAX0cVTwOTN01eVdD25TZtX26r1fZFdgJZRERyh+5AFhERJQMREVEyiJSZFZnZG+H9FMnzeprZajObEz6GxxFjXZhZmZm9HcY/M8X8nO5uJIPty+l9aGZNzewJM5tvZu+aWY+k+bm+/9JtX87uPzPbOyHuOWb2pZldklSmRvtP4xlE62LgXWCHKua/7O796jGeKBzh7lXdwJPY3Uh3gu5GutdXYFlS3fZBbu/DPwPPunv/8Iq/Jknzc33/pds+yNH95+7vAZ1gU9c/S4DxScVqtP90ZBARMysFjgHuizuWGKm7kQbKzHYAfgL8DcDd17v7qqRiObv/Mty+fNEL+NDdP0qaXqP9p2QQnZHA5cB31ZTpYWZvmtkzZrZf/YSVVQ5MNrNZYZchyVoBixNel4fTckW67YPc3Ye7A8uBB8KmzPvMbNukMrm8/zLZPsjd/ZfoVGBsiuk12n9KBhEws37AMnefVU2x2QR9hRwA3AE8VR+xZdmh7t6Z4HD0AjP7SdL8jLobacDSbV8u78Otgc7A3e5+ILAWSO5mPpf3Xybbl8v7D4Cw+es44PFUs1NMq3L/KRlE41DgODMrI+it9UgzeySxgLt/6e5rwueTgEZmVlLvkdaBuy8N/y4jaK/sllQkp7sbSbd9Ob4Py4Fyd389fP0EwZdncplc3X9pty/H91+lPsBsd/8sxbwa7T8lgwi4+5XuXurubQkO4f7t7gMSy5jZrmZm4fNuBPtiZb0HW0tmtq2ZbV/5HPgZMDepWM52N5LJ9uXyPnT3T4HFZrZ3OKkXMC+pWM7uv0y2L5f3X4LTSN1EBDXcf7qaqB7Z5l1x9AfOM7MNwNfAqZ5bt4PvAowP/5e2Bsa4+7OWP92NZLJ9ub4PLwT+HjY1LAR+nUf7D9JvX07vPzNrAhwF/DZhWq33n7qjEBERNROJiIiSgYiIoGQgIiIoGYiICEoGIiKCkoHkIDNrltBb46dmtiR8vsrMkq+Vr0m9A81seVjXfDP7XcK8EWbmZvajhGm/C6d1CV//xoJeTt8ys7lmdnw4fbSZLUqIeVpdtl8kCrrPQHKOu6/k+x4bRwBr3P0WM2sLbNFdeA096u6DzawZ8J6ZPeHulf27vE1wE+F14ev+hDcyhR0T/h/Q2d1Xm9l2QPOEei9z9yfqEpiZFbn7xqpeV7Pc1u6+oS7rlvynIwPJN0Vmdq+ZvWNmk82sMYCZ7WFmz4adzr1sZvtUV0mYcBYAib08PkXQEyRmtjuwmqAzNICdga+Ayu4N1rj7okyDtmDsi5vNbEZ4ZPHbcHpPM3vRzMYAb6d4XWxmD4RHJG+Y2RHhcgPN7HEzexqYnGkcUriUDCTf7An8xd33A1YBPw+njwIudPeDgEuBu6qrxMzaAMXAWwmTvyTo4qADQTcAjybMexP4DFgUfjkfm1TlzQnNRH9PscqzCLoL6Ap0Bc4xs3bhvG7A/7l7+xSvLwBw9/3DmB40s+KwXA/gV+5+ZHXbKgJqJpL8s8jd54TPZwFtwyabQ4DHw+4lALapYvlTwl/XewPnuHtF0vxxBE1FvQn6u/k1gLtvNLOjCb7IewG3mdlB7j4iXC5dM9HPgI5m1j98vSNBYlsPTE86ykh8fRhBj5u4+3wz+wjYK5z3vLt/Xs06RTZRMpB8803C841AY4Ij4FXu3imD5SvPGfQA/mVmz4SdnlV6GrgZmOnuXyYkF8J+baYD083seeABYESGcRvBkctzm00060nQ/XKixNepuilOVU6kWmomkrzn7l8SNN/8AjaNDXtAmmVeBR4mGLo0cfrXwBDg+sTpZtbSNh9jthOQPPJUdZ4j6DStUVjfXpZ6MJZkLwGnVy4DtAHeq8F6RQAdGUjhOB2428yuAhoRNPe8mWaZm4DZZnZD4kR3H5eibCPgFjNrCVQQnFg+N2H+zeG6K3Vz9/UJr+8D2obrs3D5E9JtFMG5j3vM7G1gAzDQ3b9JPGIRyYR6LRURETUTiYiIkoGIiKBkICIiKBmIiAhKBiIigpKBiIigZCAiIsD/A+rCNuXlsU9bAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#RMSE\n",
    "\n",
    "m_test_rmse = statistics.mean(test_RMSE_list)\n",
    "plt.axvline(m_test_rmse, color='red', linestyle='dashed')\n",
    "plt.hist(test_RMSE_list, bins=np.arange(4.2,7.0,0.17), #color='b',\n",
    "         edgecolor='k', histtype ='bar', density=True, #alpha=0.5\n",
    "        )\n",
    "sd_test_rmse = statistics.stdev(test_RMSE_list)\n",
    "#plt.axvline(m+sd, color='b', linestyle='dashed')\n",
    "#plt.axvline(m-sd, color='b', linestyle='dashed')\n",
    "\n",
    "\n",
    "m_train_rmse = statistics.mean(train_RMSE_list)\n",
    "plt.axvline(m_train_rmse, color='b', linestyle='dashed')\n",
    "plt.hist(train_RMSE_list, bins=np.arange(4.2,7.0,0.17), color='orange', edgecolor='k', histtype ='bar', density=True, alpha=0.7)\n",
    "\n",
    "sd_train_rmse = statistics.stdev(train_RMSE_list)\n",
    "#plt.axvline(m+sd, color='y', linestyle='dashed')\n",
    "#plt.axvline(m-sd, color='y', linestyle='dashed')\n",
    "\n",
    "print(f'stdev_RMSE_test: {sd_test_rmse:.2f}')\n",
    "print(f'stdev_RMSE_train: {sd_train_rmse:.2f}')\n",
    "\n",
    "print(f'mean_RMSE_test: {m_test_rmse:.2f}')\n",
    "print(f'mean_RMSE_train: {m_train_rmse:.2f}')\n",
    "\n",
    "#create legend\n",
    "labels= [\"Mean_test\",\"Mean_train\",\"test\",\"train\"]\n",
    "plt.legend(labels)\n",
    "\n",
    "plt.xlabel('The RMSE error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('histogram of the RMSE distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4af09cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stdev_MSE_test: 4.31\n",
      "stdev_MSE_train: 3.36\n",
      "mean_MSE_test: 33.79\n",
      "mean_MSE_train: 23.20\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#MSE\n",
    "\n",
    "m_test_mse = statistics.mean(test_MSE_list)\n",
    "plt.axvline(m_test_mse, color='red', linestyle='dashed')\n",
    "plt.hist(test_MSE_list, bins=np.arange(13.7,47.0,2.3), #color='b',\n",
    "         edgecolor='k', histtype ='bar', density=True)\n",
    "\n",
    "m_train_mse = statistics.mean(train_MSE_list)\n",
    "plt.axvline(m_train_mse, color='b', linestyle='dashed')\n",
    "plt.hist(train_MSE_list, color='orange', bins=np.arange(13.7,47.0,2.3), edgecolor='k', histtype ='bar', density=True, alpha=0.7)\n",
    "\n",
    "sd_train_mse = statistics.stdev(train_MSE_list)\n",
    "sd_test_mse = statistics.stdev(test_MSE_list)\n",
    "\n",
    "print(f'stdev_MSE_test: {sd_test_mse:.2f}')\n",
    "print(f'stdev_MSE_train: {sd_train_mse:.2f}')\n",
    "\n",
    "print(f'mean_MSE_test: {m_test_mse:.2f}')\n",
    "print(f'mean_MSE_train: {m_train_mse:.2f}')\n",
    "\n",
    "\n",
    "#create legend\n",
    "colors_2 = [\"lime\", \"blue\"]\n",
    "labels_2= [\"test\",\"train\"]\n",
    "#plt.legend(labels_2)\n",
    "\n",
    "\n",
    "#create legend\n",
    "colors = [\"tan\", \"red\"]\n",
    "labels= [\"Mean_test\",\"Mean_train\",\"test\",\"train\"]\n",
    "plt.legend(labels)\n",
    "\n",
    "plt.xlabel('The MSE error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('histogram of the MSE distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be13f453",
   "metadata": {},
   "source": [
    "###Codes in the following cells displays the estimated errors in a single run of Random Forest Regression Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0b343c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6458, 31) (6458,)\n",
      "(1615, 31) (1615,)\n"
     ]
    }
   ],
   "source": [
    "X = df[features]\n",
    "#display(X.columns)\n",
    "y = df[\"DAM_perc_dmg\"]\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled,df['DAM_perc_dmg'], stratify=y_input_strat, \n",
    "                                                    test_size=0.2) \n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b78846e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an xgboost Reduced Overfitting\n",
    "\n",
    "xgb = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.8,\n",
    "                   colsample_bynode=0.8, colsample_bytree=0.8, gamma=3, eta=0.01,\n",
    "                   importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
    "                   max_depth=4, min_child_weight=1, missing=1, n_estimators=100, early_stopping_rounds=10,\n",
    "                   n_jobs=1, nthread=None, objective='reg:squarederror', random_state=0,\n",
    "                   reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "                   silent=None, subsample=0.8, verbosity=1, eval_metric=[\"rmse\", \"logloss\"])\n",
    "\n",
    "    \n",
    "eval_set = [(X_test, y_test)]\n",
    "xgb_model=xgb.fit(X_train, y_train, eval_set=eval_set, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ac49702d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           DAM_perc_dmg   R-squared:                       0.467\n",
      "Model:                            OLS   Adj. R-squared:                  0.464\n",
      "Method:                 Least Squares   F-statistic:                     181.3\n",
      "Date:                Thu, 10 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        02:31:23   Log-Likelihood:                -21484.\n",
      "No. Observations:                6458   AIC:                         4.303e+04\n",
      "Df Residuals:                    6426   BIC:                         4.325e+04\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4444      0.084     29.071      0.000       2.280       2.609\n",
      "x1            -1.3463      0.389     -3.464      0.001      -2.108      -0.584\n",
      "x2             1.4160      0.281      5.043      0.000       0.866       1.967\n",
      "x3             0.7308      0.534      1.368      0.171      -0.316       1.778\n",
      "x4            -4.5970      0.324    -14.169      0.000      -5.233      -3.961\n",
      "x5             8.9941      0.219     40.979      0.000       8.564       9.424\n",
      "x6            -0.4991      0.197     -2.531      0.011      -0.886      -0.112\n",
      "x7           -52.5871     61.573     -0.854      0.393    -173.290      68.116\n",
      "x8             0.3491      0.095      3.666      0.000       0.162       0.536\n",
      "x9            31.2832     36.504      0.857      0.391     -40.276     102.842\n",
      "x10            0.4223      0.469      0.900      0.368      -0.497       1.342\n",
      "x11           42.1151     49.748      0.847      0.397     -55.407     139.638\n",
      "x12           -0.0590      0.090     -0.655      0.512      -0.236       0.118\n",
      "x13           -0.1187      0.096     -1.233      0.218      -0.308       0.070\n",
      "x14           -0.3195      0.264     -1.211      0.226      -0.837       0.198\n",
      "x15           -0.1973      0.175     -1.127      0.260      -0.540       0.146\n",
      "x16            0.0814      0.182      0.447      0.655      -0.275       0.438\n",
      "x17           -3.1573      0.281    -11.250      0.000      -3.707      -2.607\n",
      "x18            0.1892      0.118      1.598      0.110      -0.043       0.421\n",
      "x19           -0.1169      0.105     -1.118      0.264      -0.322       0.088\n",
      "x20           -0.2328      0.090     -2.581      0.010      -0.410      -0.056\n",
      "x21            0.0285      2.831      0.010      0.992      -5.521       5.578\n",
      "x22           -0.3326      2.081     -0.160      0.873      -4.411       3.746\n",
      "x23            0.5559      0.139      4.013      0.000       0.284       0.828\n",
      "x24            0.0933      0.405      0.231      0.818      -0.700       0.886\n",
      "x25           -0.0098      1.907     -0.005      0.996      -3.749       3.729\n",
      "x26            0.0825      0.114      0.724      0.469      -0.141       0.306\n",
      "x27           -0.0629      0.100     -0.631      0.528      -0.258       0.133\n",
      "x28            0.2096      0.100      2.094      0.036       0.013       0.406\n",
      "x29            0.1018      0.122      0.833      0.405      -0.138       0.341\n",
      "x30            0.7313      0.140      5.237      0.000       0.458       1.005\n",
      "x31            3.6862      0.268     13.740      0.000       3.160       4.212\n",
      "==============================================================================\n",
      "Omnibus:                     6394.582   Durbin-Watson:                   2.006\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           569408.375\n",
      "Skew:                           4.658   Prob(JB):                         0.00\n",
      "Kurtosis:                      48.048   Cond. No.                     2.34e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.34e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X2 = sm.add_constant(X_train)\n",
    "est = sm.OLS(y_train, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac20b60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Test  ------\n",
      "Mean absolute error: 1.90\n",
      "Mean squared error: 35.09\n",
      "Root mean squared error: 5.92\n",
      "Max error: 63.09\n",
      "Average Error: -0.10\n",
      "---- Training -----\n",
      "Mean absolute error: 1.53\n",
      "Mean squared error: 18.07\n",
      "Root mean squared error: 4.25\n",
      "Max error: 73.16\n",
      "Average Error: -0.01\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = xgb.predict(X_train)\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "mx_train = max_error(y_train, y_pred_train)\n",
    "me_train = (y_pred_train - y_train).sum()/len(y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mx = max_error(y_test, y_pred)\n",
    "me = (y_pred - y_test).sum()/len(y_test)\n",
    "\n",
    "print('----- Test  ------')\n",
    "print(f'Mean absolute error: {mae:.2f}')\n",
    "print(f'Mean squared error: {mse:.2f}')\n",
    "print(f'Root mean squared error: {rmse:.2f}')\n",
    "print(f'Max error: {mx:.2f}')\n",
    "print(f\"Average Error: {me:.2f}\")\n",
    "\n",
    "print('---- Training -----')\n",
    "print(f'Mean absolute error: {mae_train:.2f}')\n",
    "print(f'Mean squared error: {mse_train:.2f}')\n",
    "print(f'Root mean squared error: {rmse_train:.2f}')\n",
    "print(f'Max error: {mx_train:.2f}')\n",
    "print(f\"Average Error: {me_train:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "247e42cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score coefficient of determination for XGboost R^2: 0.788 \n"
     ]
    }
   ],
   "source": [
    "score = xgb.score(X_train, y_train)  \n",
    "print(\"Training score coefficient of determination for XGboost R^2: %.3f \" % (score))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
