# Baseline Model

The baseline model analysis is based on
[this dataset](https://drive.google.com/drive/u/2/folders/1XCfmkUuxzJayJWh11Qb09pHAfjpoUqZZ)
which has been compiled by 510 Global, from their work
developing a typhoon impact prediction model in the Philippines.
This work can be found
[here](https://github.com/rodekruis/Typhoon-Impact-based-forecasting-model),
with script specific to creating this dataset available
[here](https://github.com/rodekruis/Typhoon-Impact-based-forecasting-model/tree/master/IBF-Typhoon-model/documentation).

## Report of analysis: code and steps

All the codes from number 01 to 09 are related to the analysis of the
input data, features, and even the two regression models.

Code 01 <br />
[Correlation Matrix and VIF](01_Main_Correlation_Matrix.ipynb)

Feature selection was applied by using Correlation and Variance Inflation Factor(VIF)
among all the 38 features including the target.  Value of 80 was considered as the threshold
to express the highly correlated pairs in correlation matrix and 7 was considered as the
threshold for VIF result.

Achievement: Some features belong to the same category and those ones are the highly correlated pairs e.g. HAZ_v_max and HAZ_v_max_3 category of wind-speed.

Code 02 <br />
[Feature Importance LinearRegression](02.1_Feature_Importance-LinearRegression.ipynb), [Feature Importance RandomForest](02.2_Feature_Importance-RandomForest.ipynb), [Feature Importance XGBoost](02.3_Feature_Importance-XGBoost.ipynb)

Applied feature importance to input data using SHAP values and classifier construction
for models based on Random Forest and XGBoost algorithms, and Regression Coefficients estimation
for Linear Regression algorithm. Feature importance was done 1. After removing very highly correlated
features(with 0.99 as thresholds) only for Random Forest and XGBoost and 2. After removing features
based on VIF for Random Forest, XGBoost and Linear Regression

Achievement: output of XGBoost model is more stable than Random Forest and features related to weather data (wind speed,rainfall) are the most important ones.

Code 03 <br />
[Data Stratification LinearRegression](03.1_Stratify_proportion_damage-LinearRegression.ipynb), [Data Stratification RandomForest](03.2_Stratify_proportion_damage-RandomForest.ipynb), [Data Stratification XGBoost](03.3_Stratify_proportion_damage-XGBoost.ipynb)

Although the target values(percentage of damaged houses) have a range from 0 to 100, there are only few cases with high damage.
Therefore, two different bin sets were defined to stratify target values of input data.

Achievement: Stratification removed the risk of missing higher damage from training and test dataset, it slightly improves performance issues
caused by data imbalance

Code 04 <br />
[RMSE bins RandomForest](04.1_RandomForest-bins.ipynb), [RMSE bins XGBoost](04.2_XGBoost-bins.ipynb)

Model performance estimated per bin.

Achievement: The performance of the model seemed better in the first bins.

Code 05 <br />
[damage >10% RandomForest](05.1_RandomForest-percent-damage.ipynb), [damage >10% XGBoost](05.2_XGBoost-percent-damage.ipynb)

A specific classifier was built for cases where the damage >10% and model performance was estimated per bin.
Training with weighted RMSE also used as another experiment to emphasize the higher damage.
The overfitting of models (Random Forest and XGBoost) has been reduced by changing values of hyper parameters and/or adding some new hyper parameters.

Achievement: The model trained only with damage >10%  performed better for cases where the damge>20%.

Code 06 <br />
[RMSE total RandomForest](06.1_RandomForest-wholedataset.ipynb), [RMSE total XGBoost](06.2_XGBoost-wholedataset.ipynb)

The performance of the model estimated in total (not per bin).

Code 07 <br />
[Scatter plot True/Predicted RandomForest](07.1_RandomForest-predicted-and-true.ipynb), [Scatter plot True/Predicted XGBoost](07.2_XGBoost-predicted-and-true.ipynb)

Scatter plots for True values versus Predicted ones.

Code 08 <br />
[Train_test_split Typhoon Severity](08_Typhoon_train-test-split-RandomForest-and-XGBoost-bins.ipynb)

The performance of the model estimated with a train-test-split based on typhoon severity of
the 39 typhoons in the  dataset. Test data consists of 8 typhoons from the total of 39 (4 severe and 4 mild typhoons).

Code 09 <br />
[Train_test_split Typhoon Time RandomForest](09.1_Typhoons_by_time-RandomForest-main.ipynb), [Train_test_split Typhoon Time XGBoost](09.2_Typhoons_by_time-XGBoost-main.ipynb)

The performance of the model estimated while train-test-split was based on typhoon time.
A real time usage was simulated to determine how well the model performs in learning from
older typhoons' characteristics to make predictions on the target value of the most recent ones.
