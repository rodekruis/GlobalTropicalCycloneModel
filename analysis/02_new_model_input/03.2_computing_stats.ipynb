{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyter_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyter_black\n"
     ]
    }
   ],
   "source": [
    "%load_ext jupyter_black\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# input\n",
    "input_dir = (\n",
    "    Path(os.getenv(\"STORM_DATA_DIR\"))\n",
    "    / \"analysis/02_new_model_input/03_rainfall/input\"\n",
    ")\n",
    "\n",
    "# outputs\n",
    "processed_output_dir = os.path.join(\n",
    "    input_dir, \"gpm_data/rainfall_data/output_hhr_processed/\"\n",
    ")\n",
    "\n",
    "output_dir = os.path.join(\n",
    "    Path(os.getenv(\"STORM_DATA_DIR\"))\n",
    "    / \"analysis/02_new_model_input/03_rainfall/output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading csv files\n",
    "typ_list = [\n",
    "    x for x in os.listdir(processed_output_dir) if x.endswith(\"_gridstats.csv\")\n",
    "]\n",
    "# typ_file = pd.read_csv(processed_output_dir + typ_list[0])\n",
    "# typ_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "for typ in typ_list:\n",
    "    typ_file = pd.read_csv(processed_output_dir + typ)\n",
    "    sorted_df = typ_file.sort_values(by=[\"id\", \"date\", \"end\"])\n",
    "    # computing 6hr and 24hr max in mm/hr\n",
    "    six_hr_max_df = (\n",
    "        sorted_df.groupby([\"id\", \"Centroid\"])[[\"mean\", \"max\"]]\n",
    "        .rolling(2)\n",
    "        .sum()\n",
    "        .rolling(6)\n",
    "        .max()\n",
    "        .reset_index()\n",
    "        .drop(\"level_2\", axis=1)\n",
    "        .rename(\n",
    "            {\"max\": \"six_hr_max_of_max\", \"mean\": \"six_hr_max_of_mean\"}, axis=1\n",
    "        )\n",
    "    )\n",
    "    day_max_df = (\n",
    "        sorted_df.groupby([\"id\", \"Centroid\"])[[\"mean\", \"max\"]]\n",
    "        .rolling(2)\n",
    "        .sum()\n",
    "        .rolling(24)\n",
    "        .max()\n",
    "        .reset_index()\n",
    "        .drop(\"level_2\", axis=1)\n",
    "        .rename({\"max\": \"day_max_of_max\", \"mean\": \"day_max_of_mean\"}, axis=1)\n",
    "    )\n",
    "    # joining all output\n",
    "    out_df = six_hr_max_df.reset_index(drop=True).join(\n",
    "        day_max_df.drop([\"id\", \"Centroid\"], axis=1).join(\n",
    "            sorted_df[[\"end\", \"date\"]].reset_index().drop(\"index\", axis=1)\n",
    "        )\n",
    "    )\n",
    "    out_df[\"typhoon_name\"] = typ.split(\"_\")[0]\n",
    "    out_df.to_csv(\n",
    "        output_dir + \"/\" + typ.split(\"_\")[0] + \"_stats.csv\", index=False\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "globaltyphoon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0bf5227c718a54401bc80004b44f7ad33fb80a867a635817764b403a4b4c0f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
