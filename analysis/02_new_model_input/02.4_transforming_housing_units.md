# Transforming Housing Units from Municipality to Grid

```python
%load_ext jupyter_black
import pandas as pd
import numpy as np
import os
from pathlib import Path
```

```python
base_url = (
    Path(os.getenv("STORM_DATA_DIR"))
    / "analysis/02_new_model_input/02_housing_damage/"
)
impact_input_dir = base_url / "input/"
input_dir = base_url / "input/Google Footprint Data/"
output_dir = base_url / "output/"
```

```python
phl_ggl_bld_municip_count = pd.read_csv(
    input_dir / "phl_google_bld_municip_count.csv"
)
phl_ggl_bld_grid_count = pd.read_csv(
    input_dir / "phl_google_bld_grid_count.csv"
)
phl_ggl_bld_intersection_count = pd.read_csv(
    input_dir / "phl_google_bld_intersection_count.csv"
)
```

## Computing weights

```python
## adding a building to the municipality pcode = PH175321000
# and grid id = 101 and Centroid  = 114.3E_11.1N
## there are no buildings in this municipality and is an island in the ocean
# This is done to compute the weights and ensure housing units are not left out.
# It is the only municipality in the grid.
# phl_ggl_bld_municip_count.loc[
# len(phl_ggl_bld_municip_count.index)] = ['Amy', 89, 93]
phl_ggl_bld_municip_count[
    phl_ggl_bld_municip_count["ADM3_PCODE"] == "PH175321000"
]
phl_ggl_bld_grid_count[phl_ggl_bld_grid_count["id"] == 101]
phl_ggl_bld_intersection_count[
    (phl_ggl_bld_intersection_count["ADM3_PCODE"] == "PH175321000")
    & (phl_ggl_bld_intersection_count["id"] == 101)
]
```

```python
phl_ggl_bld_municip_count.loc[
    phl_ggl_bld_municip_count["ADM3_PCODE"] == "PH175321000", "numbuildings"
] = 1
phl_ggl_bld_grid_count.loc[
    phl_ggl_bld_grid_count["id"] == 101, "numbuildings"
] = 1
phl_ggl_bld_intersection_count.loc[
    (phl_ggl_bld_intersection_count["ADM3_PCODE"] == "PH175321000")
    & (phl_ggl_bld_intersection_count["id"] == 101),
    "numbuildings",
] = 1
```

### Municipality to Grid

```python
mun_to_grid = phl_ggl_bld_intersection_count.merge(
    phl_ggl_bld_municip_count, on="ADM3_PCODE", suffixes=("_x", None)
)
mun_to_grid["weight"] = (
    mun_to_grid["numbuildings_x"] / mun_to_grid["numbuildings"]
)
mun_to_grid[mun_to_grid["Centroid"] == "122.1E_17.4N"]
```

```python
mun_to_grid.to_csv(input_dir / "ggl_mun_to_grid_weights.csv", index=False)
```

### Grid to Municipality

```python
grid_to_mun = phl_ggl_bld_intersection_count.merge(
    phl_ggl_bld_grid_count, on="Centroid", suffixes=("_x", None)
)
grid_to_mun["weight"] = (
    grid_to_mun["numbuildings_x"] / grid_to_mun["numbuildings"]
)
grid_to_mun.groupby("Centroid").sum().sort_values(by="weight")
```

```python
grid_to_mun.to_csv(input_dir / "ggl_grid_to_mun_weights.csv", index=False)
```

## Transforming the Housing Units data

The housing units data is from `https://data.humdata.org/dataset/philippines-pre-disaster-indicators`

- File URL `https://data.humdata.org/dataset/f26a0a04-0549-4139-af91-81dfa6e56082/resource/557b601f-e2f5-42ef-8742-e47395427384/download/180814_construction-materials-of-the-outer-walls-and-roof_by-city_municipality.xlsx`

```python
construction_materials_df = pd.read_excel(
    base_url
    / "input/180814_construction-materials-of-the-outer-walls-and-roof_by-city_municipality.xlsx",
    sheet_name="by category",
)
households_df = pd.read_excel(
    base_url / "input/180814_number-of-household_by-city_municipality.xlsx",
    sheet_name="Data",
)
```

```python
# filling in missing housing units with households
housing_units_df = construction_materials_df[
    ["Municipality_City Code", "Housing Units"]
].merge(households_df, on="Municipality_City Code", how="left")
# using right join to preserve all municipalities
hu_grid = housing_units_df.merge(
    mun_to_grid[["ADM3_PCODE", "id", "Centroid", "weight"]],
    how="right",
    left_on="Municipality_City Code",
    right_on="ADM3_PCODE",
)
hu_grid[hu_grid["Housing Units"].isna()]
```

```python
hu_grid["Housing Units"].fillna(hu_grid["Number of Household"], inplace=True)
hu_grid["Housing Units"].fillna(1, inplace=True)
hu_grid[hu_grid["Housing Units"].isna()]
# should not show rows
```

```python
# multiplying by weights
hu_grid["hu_bygrid"] = hu_grid["Housing Units"] * hu_grid["weight"]
hu_grid_df = hu_grid.groupby(["id", "Centroid"]).sum().reset_index()
hu_grid_df.drop(["Housing Units", "weight"], axis=1, inplace=True)
hu_grid_df["hu_bygrid"].sum()
```

```python
transformed_df = phl_ggl_bld_grid_count.merge(
    hu_grid_df, on=["id", "Centroid"]
)
transformed_df.to_csv(
    output_dir / "transformed_housingunits_bygrid.csv", index=False
)
```

```python
# Percentage Damage by Grid Using these Weights
build_dmg_data = pd.read_csv(
    impact_input_dir / "IMpact_data_philipines_SEP_2021.csv"
)
build_dmg_data.drop("Id", axis=1, inplace=True)
build_dmg_data.drop_duplicates(
    subset=["pcode", "typhoon", "Year"], inplace=True
)
```

```python
# Not all municipalities are in the damage data set.
# Not all municipalities in the building damage data can be found
# in the admin 3 shapefile.
# removing those buildings with incorrect pcode in them
build_dmg_data_grouped = build_dmg_data[
    build_dmg_data["pcode"].isin(list(phl_ggl_bld_municip_count["ADM3_PCODE"]))
]
build_dmg_data_grouped["Totally"].sum()
```

```python
build_dmg_data_grouped = build_dmg_data_grouped.merge(
    mun_to_grid,
    left_on="pcode",
    right_on="ADM3_PCODE",
    how="right",
    suffixes=("_x", None),
)
# multiplying by weights
build_dmg_data_grouped["damaged_bygrid"] = (
    build_dmg_data_grouped["Totally"] * build_dmg_data_grouped["weight"]
)
build_dmg_data_grouped
```

```python
build_dmg_data_grouped = build_dmg_data_grouped.groupby(
    ["id", "Centroid", "typhoon", "Year"], as_index=False
).sum()
build_dmg_data_grouped
```

```python
build_dmg_data_grouped["damaged_bygrid"].sum()
```

```python
build_dmg_data_grouped.to_csv(
    output_dir / "building_damage_bygrid_gglfpdata.csv", index=False
)
```
